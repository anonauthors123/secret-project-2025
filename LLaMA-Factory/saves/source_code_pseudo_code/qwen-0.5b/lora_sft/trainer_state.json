{
  "best_metric": 0.055214423686265945,
  "best_model_checkpoint": "saves/source_code_pseudo_code/qwen-0.5b/lora_sft/checkpoint-3180",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 3180,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017222820236813777,
      "grad_norm": 3.1056556701660156,
      "learning_rate": 5.747126436781609e-06,
      "loss": 1.2723,
      "step": 10
    },
    {
      "epoch": 0.03444564047362755,
      "grad_norm": 5.351215362548828,
      "learning_rate": 1.1494252873563218e-05,
      "loss": 1.31,
      "step": 20
    },
    {
      "epoch": 0.05166846071044134,
      "grad_norm": 1.621848225593567,
      "learning_rate": 1.7241379310344828e-05,
      "loss": 1.5385,
      "step": 30
    },
    {
      "epoch": 0.0688912809472551,
      "grad_norm": 2.337481737136841,
      "learning_rate": 2.2988505747126437e-05,
      "loss": 1.0844,
      "step": 40
    },
    {
      "epoch": 0.0861141011840689,
      "grad_norm": 1.1774888038635254,
      "learning_rate": 2.8735632183908045e-05,
      "loss": 1.31,
      "step": 50
    },
    {
      "epoch": 0.10333692142088267,
      "grad_norm": 1.3080999851226807,
      "learning_rate": 3.4482758620689657e-05,
      "loss": 1.005,
      "step": 60
    },
    {
      "epoch": 0.12055974165769645,
      "grad_norm": 1.4858952760696411,
      "learning_rate": 4.0229885057471265e-05,
      "loss": 0.748,
      "step": 70
    },
    {
      "epoch": 0.1377825618945102,
      "grad_norm": 1.1642919778823853,
      "learning_rate": 4.597701149425287e-05,
      "loss": 0.6445,
      "step": 80
    },
    {
      "epoch": 0.155005382131324,
      "grad_norm": 3.2935149669647217,
      "learning_rate": 5.172413793103449e-05,
      "loss": 0.4356,
      "step": 90
    },
    {
      "epoch": 0.1722282023681378,
      "grad_norm": 2.1491599082946777,
      "learning_rate": 5.747126436781609e-05,
      "loss": 0.2486,
      "step": 100
    },
    {
      "epoch": 0.18945102260495156,
      "grad_norm": 0.7932828664779663,
      "learning_rate": 6.32183908045977e-05,
      "loss": 0.2094,
      "step": 110
    },
    {
      "epoch": 0.20667384284176535,
      "grad_norm": 1.594063639640808,
      "learning_rate": 6.896551724137931e-05,
      "loss": 0.1694,
      "step": 120
    },
    {
      "epoch": 0.2238966630785791,
      "grad_norm": 1.1194814443588257,
      "learning_rate": 7.471264367816091e-05,
      "loss": 0.135,
      "step": 130
    },
    {
      "epoch": 0.2411194833153929,
      "grad_norm": 1.7208857536315918,
      "learning_rate": 8.045977011494253e-05,
      "loss": 0.1242,
      "step": 140
    },
    {
      "epoch": 0.25834230355220666,
      "grad_norm": 1.5587573051452637,
      "learning_rate": 8.620689655172413e-05,
      "loss": 0.1062,
      "step": 150
    },
    {
      "epoch": 0.2755651237890204,
      "grad_norm": 2.4459338188171387,
      "learning_rate": 9.195402298850575e-05,
      "loss": 0.1143,
      "step": 160
    },
    {
      "epoch": 0.29278794402583425,
      "grad_norm": 2.9487085342407227,
      "learning_rate": 9.770114942528736e-05,
      "loss": 0.1026,
      "step": 170
    },
    {
      "epoch": 0.310010764262648,
      "grad_norm": 0.9173817038536072,
      "learning_rate": 9.999637795788383e-05,
      "loss": 0.1123,
      "step": 180
    },
    {
      "epoch": 0.32723358449946177,
      "grad_norm": 0.849540114402771,
      "learning_rate": 9.997424515642708e-05,
      "loss": 0.1081,
      "step": 190
    },
    {
      "epoch": 0.3444564047362756,
      "grad_norm": 4.301449298858643,
      "learning_rate": 9.993200069547118e-05,
      "loss": 0.1041,
      "step": 200
    },
    {
      "epoch": 0.36167922497308935,
      "grad_norm": 0.6241777539253235,
      "learning_rate": 9.98696615758975e-05,
      "loss": 0.0843,
      "step": 210
    },
    {
      "epoch": 0.3789020452099031,
      "grad_norm": 0.38767126202583313,
      "learning_rate": 9.978725288549161e-05,
      "loss": 0.1073,
      "step": 220
    },
    {
      "epoch": 0.3961248654467169,
      "grad_norm": 1.1585129499435425,
      "learning_rate": 9.968480778884692e-05,
      "loss": 0.0847,
      "step": 230
    },
    {
      "epoch": 0.4133476856835307,
      "grad_norm": 0.4983104467391968,
      "learning_rate": 9.956236751401791e-05,
      "loss": 0.08,
      "step": 240
    },
    {
      "epoch": 0.43057050592034446,
      "grad_norm": 0.9316254258155823,
      "learning_rate": 9.941998133592825e-05,
      "loss": 0.0845,
      "step": 250
    },
    {
      "epoch": 0.4477933261571582,
      "grad_norm": 1.558752417564392,
      "learning_rate": 9.925770655654061e-05,
      "loss": 0.0903,
      "step": 260
    },
    {
      "epoch": 0.465016146393972,
      "grad_norm": 5.067699432373047,
      "learning_rate": 9.907560848179606e-05,
      "loss": 0.0873,
      "step": 270
    },
    {
      "epoch": 0.4822389666307858,
      "grad_norm": 0.8298524022102356,
      "learning_rate": 9.887376039533226e-05,
      "loss": 0.0726,
      "step": 280
    },
    {
      "epoch": 0.49946178686759957,
      "grad_norm": 5.136799335479736,
      "learning_rate": 9.865224352899119e-05,
      "loss": 0.1143,
      "step": 290
    },
    {
      "epoch": 0.5166846071044133,
      "grad_norm": 2.3219332695007324,
      "learning_rate": 9.841114703012817e-05,
      "loss": 0.0898,
      "step": 300
    },
    {
      "epoch": 0.5339074273412271,
      "grad_norm": 0.4799705147743225,
      "learning_rate": 9.815056792573532e-05,
      "loss": 0.0794,
      "step": 310
    },
    {
      "epoch": 0.5511302475780409,
      "grad_norm": 0.7411648035049438,
      "learning_rate": 9.787061108339399e-05,
      "loss": 0.0625,
      "step": 320
    },
    {
      "epoch": 0.5683530678148547,
      "grad_norm": 1.4721410274505615,
      "learning_rate": 9.757138916907185e-05,
      "loss": 0.1037,
      "step": 330
    },
    {
      "epoch": 0.5855758880516685,
      "grad_norm": 0.6786274909973145,
      "learning_rate": 9.725302260178145e-05,
      "loss": 0.0796,
      "step": 340
    },
    {
      "epoch": 0.6027987082884823,
      "grad_norm": 1.2855640649795532,
      "learning_rate": 9.69156395051188e-05,
      "loss": 0.0788,
      "step": 350
    },
    {
      "epoch": 0.620021528525296,
      "grad_norm": 1.8598363399505615,
      "learning_rate": 9.655937565570123e-05,
      "loss": 0.0877,
      "step": 360
    },
    {
      "epoch": 0.6372443487621098,
      "grad_norm": 1.5630625486373901,
      "learning_rate": 9.618437442852537e-05,
      "loss": 0.0765,
      "step": 370
    },
    {
      "epoch": 0.6544671689989235,
      "grad_norm": 2.1528234481811523,
      "learning_rate": 9.57907867392673e-05,
      "loss": 0.0807,
      "step": 380
    },
    {
      "epoch": 0.6716899892357373,
      "grad_norm": 0.8941097855567932,
      "learning_rate": 9.537877098354786e-05,
      "loss": 0.0938,
      "step": 390
    },
    {
      "epoch": 0.6889128094725512,
      "grad_norm": 0.7036022543907166,
      "learning_rate": 9.494849297318795e-05,
      "loss": 0.0759,
      "step": 400
    },
    {
      "epoch": 0.7061356297093649,
      "grad_norm": 0.5243658423423767,
      "learning_rate": 9.450012586947911e-05,
      "loss": 0.0814,
      "step": 410
    },
    {
      "epoch": 0.7233584499461787,
      "grad_norm": 0.8472099900245667,
      "learning_rate": 9.403385011349639e-05,
      "loss": 0.0651,
      "step": 420
    },
    {
      "epoch": 0.7405812701829925,
      "grad_norm": 1.3887914419174194,
      "learning_rate": 9.354985335348154e-05,
      "loss": 0.0704,
      "step": 430
    },
    {
      "epoch": 0.7578040904198062,
      "grad_norm": 1.3154734373092651,
      "learning_rate": 9.304833036932579e-05,
      "loss": 0.0594,
      "step": 440
    },
    {
      "epoch": 0.77502691065662,
      "grad_norm": 0.6898031830787659,
      "learning_rate": 9.252948299418254e-05,
      "loss": 0.0578,
      "step": 450
    },
    {
      "epoch": 0.7922497308934338,
      "grad_norm": 0.6883658170700073,
      "learning_rate": 9.199352003324151e-05,
      "loss": 0.0706,
      "step": 460
    },
    {
      "epoch": 0.8094725511302476,
      "grad_norm": 0.7000464200973511,
      "learning_rate": 9.144065717969706e-05,
      "loss": 0.0673,
      "step": 470
    },
    {
      "epoch": 0.8266953713670614,
      "grad_norm": 1.008716344833374,
      "learning_rate": 9.087111692794459e-05,
      "loss": 0.0909,
      "step": 480
    },
    {
      "epoch": 0.8439181916038752,
      "grad_norm": 0.36191365122795105,
      "learning_rate": 9.02851284840397e-05,
      "loss": 0.047,
      "step": 490
    },
    {
      "epoch": 0.8611410118406889,
      "grad_norm": 0.7260650396347046,
      "learning_rate": 8.968292767345646e-05,
      "loss": 0.0793,
      "step": 500
    },
    {
      "epoch": 0.8783638320775027,
      "grad_norm": 0.49542590975761414,
      "learning_rate": 8.906475684618158e-05,
      "loss": 0.0649,
      "step": 510
    },
    {
      "epoch": 0.8955866523143164,
      "grad_norm": 0.5797315835952759,
      "learning_rate": 8.843086477918316e-05,
      "loss": 0.0687,
      "step": 520
    },
    {
      "epoch": 0.9128094725511302,
      "grad_norm": 1.2064037322998047,
      "learning_rate": 8.778150657629258e-05,
      "loss": 0.0701,
      "step": 530
    },
    {
      "epoch": 0.930032292787944,
      "grad_norm": 1.898998498916626,
      "learning_rate": 8.71169435655405e-05,
      "loss": 0.0537,
      "step": 540
    },
    {
      "epoch": 0.9472551130247578,
      "grad_norm": 0.6118401288986206,
      "learning_rate": 8.643744319398782e-05,
      "loss": 0.0936,
      "step": 550
    },
    {
      "epoch": 0.9644779332615716,
      "grad_norm": 0.949110209941864,
      "learning_rate": 8.574327892009414e-05,
      "loss": 0.0552,
      "step": 560
    },
    {
      "epoch": 0.9817007534983854,
      "grad_norm": 0.604924738407135,
      "learning_rate": 8.503473010366713e-05,
      "loss": 0.0613,
      "step": 570
    },
    {
      "epoch": 0.9989235737351991,
      "grad_norm": 0.3097652494907379,
      "learning_rate": 8.43120818934367e-05,
      "loss": 0.0519,
      "step": 580
    },
    {
      "epoch": 0.9989235737351991,
      "eval_loss": 0.3328193128108978,
      "eval_runtime": 51.4633,
      "eval_samples_per_second": 24.25,
      "eval_steps_per_second": 6.063,
      "step": 580
    },
    {
      "epoch": 1.0170075349838537,
      "grad_norm": 0.3145778179168701,
      "learning_rate": 8.357562511229961e-05,
      "loss": 0.048,
      "step": 590
    },
    {
      "epoch": 1.0342303552206673,
      "grad_norm": 0.6222670674324036,
      "learning_rate": 8.282565614028067e-05,
      "loss": 0.0611,
      "step": 600
    },
    {
      "epoch": 1.0514531754574812,
      "grad_norm": 1.0310850143432617,
      "learning_rate": 8.206247679525734e-05,
      "loss": 0.0404,
      "step": 610
    },
    {
      "epoch": 1.0686759956942948,
      "grad_norm": 1.8498095273971558,
      "learning_rate": 8.128639421149599e-05,
      "loss": 0.0563,
      "step": 620
    },
    {
      "epoch": 1.0858988159311087,
      "grad_norm": 1.1177681684494019,
      "learning_rate": 8.049772071604865e-05,
      "loss": 0.0697,
      "step": 630
    },
    {
      "epoch": 1.1031216361679226,
      "grad_norm": 0.9640113115310669,
      "learning_rate": 7.969677370306e-05,
      "loss": 0.0655,
      "step": 640
    },
    {
      "epoch": 1.1203444564047362,
      "grad_norm": 1.0884685516357422,
      "learning_rate": 7.888387550603504e-05,
      "loss": 0.0457,
      "step": 650
    },
    {
      "epoch": 1.13756727664155,
      "grad_norm": 0.8298656344413757,
      "learning_rate": 7.805935326811912e-05,
      "loss": 0.0621,
      "step": 660
    },
    {
      "epoch": 1.1547900968783638,
      "grad_norm": 0.7941173911094666,
      "learning_rate": 7.722353881044222e-05,
      "loss": 0.0473,
      "step": 670
    },
    {
      "epoch": 1.1720129171151776,
      "grad_norm": 1.0823670625686646,
      "learning_rate": 7.637676849858077e-05,
      "loss": 0.0536,
      "step": 680
    },
    {
      "epoch": 1.1892357373519915,
      "grad_norm": 0.8125670552253723,
      "learning_rate": 7.551938310719043e-05,
      "loss": 0.0449,
      "step": 690
    },
    {
      "epoch": 1.2064585575888052,
      "grad_norm": 0.5152772068977356,
      "learning_rate": 7.465172768286462e-05,
      "loss": 0.0528,
      "step": 700
    },
    {
      "epoch": 1.223681377825619,
      "grad_norm": 0.9249680042266846,
      "learning_rate": 7.377415140527389e-05,
      "loss": 0.034,
      "step": 710
    },
    {
      "epoch": 1.2409041980624327,
      "grad_norm": 0.9450621008872986,
      "learning_rate": 7.288700744664167e-05,
      "loss": 0.0631,
      "step": 720
    },
    {
      "epoch": 1.2581270182992466,
      "grad_norm": 0.4518033564090729,
      "learning_rate": 7.199065282961371e-05,
      "loss": 0.0597,
      "step": 730
    },
    {
      "epoch": 1.2753498385360602,
      "grad_norm": 2.0346839427948,
      "learning_rate": 7.108544828357755e-05,
      "loss": 0.0524,
      "step": 740
    },
    {
      "epoch": 1.292572658772874,
      "grad_norm": 0.9579627513885498,
      "learning_rate": 7.017175809949044e-05,
      "loss": 0.0541,
      "step": 750
    },
    {
      "epoch": 1.3097954790096877,
      "grad_norm": 0.9172424077987671,
      "learning_rate": 6.924994998327394e-05,
      "loss": 0.0426,
      "step": 760
    },
    {
      "epoch": 1.3270182992465016,
      "grad_norm": 0.677814245223999,
      "learning_rate": 6.832039490783421e-05,
      "loss": 0.0477,
      "step": 770
    },
    {
      "epoch": 1.3442411194833155,
      "grad_norm": 0.4106225371360779,
      "learning_rate": 6.738346696376738e-05,
      "loss": 0.0362,
      "step": 780
    },
    {
      "epoch": 1.3614639397201291,
      "grad_norm": 0.2810482680797577,
      "learning_rate": 6.643954320881044e-05,
      "loss": 0.035,
      "step": 790
    },
    {
      "epoch": 1.378686759956943,
      "grad_norm": 0.8398860692977905,
      "learning_rate": 6.548900351609793e-05,
      "loss": 0.0495,
      "step": 800
    },
    {
      "epoch": 1.3959095801937567,
      "grad_norm": 1.0886105298995972,
      "learning_rate": 6.453223042128555e-05,
      "loss": 0.0531,
      "step": 810
    },
    {
      "epoch": 1.4131324004305705,
      "grad_norm": 1.5062620639801025,
      "learning_rate": 6.35696089686024e-05,
      "loss": 0.0358,
      "step": 820
    },
    {
      "epoch": 1.4303552206673844,
      "grad_norm": 1.0160062313079834,
      "learning_rate": 6.260152655589358e-05,
      "loss": 0.0485,
      "step": 830
    },
    {
      "epoch": 1.447578040904198,
      "grad_norm": 0.7478880882263184,
      "learning_rate": 6.162837277871553e-05,
      "loss": 0.0396,
      "step": 840
    },
    {
      "epoch": 1.4648008611410117,
      "grad_norm": 0.6329115629196167,
      "learning_rate": 6.065053927354715e-05,
      "loss": 0.0454,
      "step": 850
    },
    {
      "epoch": 1.4820236813778256,
      "grad_norm": 1.5604044198989868,
      "learning_rate": 5.966841956017928e-05,
      "loss": 0.0579,
      "step": 860
    },
    {
      "epoch": 1.4992465016146395,
      "grad_norm": 0.6099728345870972,
      "learning_rate": 5.868240888334653e-05,
      "loss": 0.0477,
      "step": 870
    },
    {
      "epoch": 1.5164693218514533,
      "grad_norm": 0.6131590008735657,
      "learning_rate": 5.769290405366469e-05,
      "loss": 0.0516,
      "step": 880
    },
    {
      "epoch": 1.533692142088267,
      "grad_norm": 0.2622407376766205,
      "learning_rate": 5.6700303287938115e-05,
      "loss": 0.0464,
      "step": 890
    },
    {
      "epoch": 1.5509149623250806,
      "grad_norm": 0.8964876532554626,
      "learning_rate": 5.5705006048901244e-05,
      "loss": 0.0396,
      "step": 900
    },
    {
      "epoch": 1.5681377825618945,
      "grad_norm": 0.7520523071289062,
      "learning_rate": 5.4707412884458444e-05,
      "loss": 0.051,
      "step": 910
    },
    {
      "epoch": 1.5853606027987084,
      "grad_norm": 0.4322028160095215,
      "learning_rate": 5.370792526648747e-05,
      "loss": 0.0408,
      "step": 920
    },
    {
      "epoch": 1.602583423035522,
      "grad_norm": 0.7293479442596436,
      "learning_rate": 5.270694542927088e-05,
      "loss": 0.0455,
      "step": 930
    },
    {
      "epoch": 1.6198062432723357,
      "grad_norm": 0.4301149547100067,
      "learning_rate": 5.170487620762066e-05,
      "loss": 0.0322,
      "step": 940
    },
    {
      "epoch": 1.6370290635091496,
      "grad_norm": 0.9640639424324036,
      "learning_rate": 5.070212087476116e-05,
      "loss": 0.0494,
      "step": 950
    },
    {
      "epoch": 1.6542518837459634,
      "grad_norm": 1.3002945184707642,
      "learning_rate": 4.969908298003573e-05,
      "loss": 0.0406,
      "step": 960
    },
    {
      "epoch": 1.6714747039827773,
      "grad_norm": 0.36776188015937805,
      "learning_rate": 4.869616618650201e-05,
      "loss": 0.0388,
      "step": 970
    },
    {
      "epoch": 1.688697524219591,
      "grad_norm": 0.5576216578483582,
      "learning_rate": 4.769377410848161e-05,
      "loss": 0.0364,
      "step": 980
    },
    {
      "epoch": 1.7059203444564046,
      "grad_norm": 1.75308096408844,
      "learning_rate": 4.669231014912943e-05,
      "loss": 0.053,
      "step": 990
    },
    {
      "epoch": 1.7231431646932185,
      "grad_norm": 0.36337846517562866,
      "learning_rate": 4.569217733808774e-05,
      "loss": 0.0271,
      "step": 1000
    },
    {
      "epoch": 1.7403659849300324,
      "grad_norm": 0.5419090986251831,
      "learning_rate": 4.469377816929093e-05,
      "loss": 0.0468,
      "step": 1010
    },
    {
      "epoch": 1.7575888051668462,
      "grad_norm": 1.2007794380187988,
      "learning_rate": 4.3697514438985536e-05,
      "loss": 0.038,
      "step": 1020
    },
    {
      "epoch": 1.7748116254036599,
      "grad_norm": 0.13861775398254395,
      "learning_rate": 4.270378708403118e-05,
      "loss": 0.0338,
      "step": 1030
    },
    {
      "epoch": 1.7920344456404735,
      "grad_norm": 0.9902558922767639,
      "learning_rate": 4.171299602054736e-05,
      "loss": 0.0475,
      "step": 1040
    },
    {
      "epoch": 1.8092572658772874,
      "grad_norm": 0.8138875365257263,
      "learning_rate": 4.072553998297103e-05,
      "loss": 0.0306,
      "step": 1050
    },
    {
      "epoch": 1.8264800861141013,
      "grad_norm": 2.7250020503997803,
      "learning_rate": 3.974181636358963e-05,
      "loss": 0.0486,
      "step": 1060
    },
    {
      "epoch": 1.843702906350915,
      "grad_norm": 1.0417728424072266,
      "learning_rate": 3.876222105261449e-05,
      "loss": 0.0413,
      "step": 1070
    },
    {
      "epoch": 1.8609257265877286,
      "grad_norm": 1.2500768899917603,
      "learning_rate": 3.778714827885845e-05,
      "loss": 0.0515,
      "step": 1080
    },
    {
      "epoch": 1.8781485468245425,
      "grad_norm": 0.9151744842529297,
      "learning_rate": 3.6816990451082296e-05,
      "loss": 0.0288,
      "step": 1090
    },
    {
      "epoch": 1.8953713670613563,
      "grad_norm": 2.0092365741729736,
      "learning_rate": 3.585213800007356e-05,
      "loss": 0.0462,
      "step": 1100
    },
    {
      "epoch": 1.9125941872981702,
      "grad_norm": 0.3054460883140564,
      "learning_rate": 3.489297922152136e-05,
      "loss": 0.0474,
      "step": 1110
    },
    {
      "epoch": 1.9298170075349839,
      "grad_norm": 0.09030085057020187,
      "learning_rate": 3.393990011975054e-05,
      "loss": 0.0346,
      "step": 1120
    },
    {
      "epoch": 1.9470398277717975,
      "grad_norm": 0.6052324175834656,
      "learning_rate": 3.299328425237781e-05,
      "loss": 0.0431,
      "step": 1130
    },
    {
      "epoch": 1.9642626480086114,
      "grad_norm": 1.0505164861679077,
      "learning_rate": 3.205351257595272e-05,
      "loss": 0.0394,
      "step": 1140
    },
    {
      "epoch": 1.9814854682454253,
      "grad_norm": 1.4779870510101318,
      "learning_rate": 3.11209632926453e-05,
      "loss": 0.037,
      "step": 1150
    },
    {
      "epoch": 1.998708288482239,
      "grad_norm": 1.0684435367584229,
      "learning_rate": 3.019601169804216e-05,
      "loss": 0.0414,
      "step": 1160
    },
    {
      "epoch": 1.998708288482239,
      "eval_loss": 0.41232192516326904,
      "eval_runtime": 54.1401,
      "eval_samples_per_second": 23.051,
      "eval_steps_per_second": 5.763,
      "step": 1160
    },
    {
      "epoch": 2.0167922497308934,
      "grad_norm": 0.6720725297927856,
      "learning_rate": 2.9279030030112408e-05,
      "loss": 0.0199,
      "step": 1170
    },
    {
      "epoch": 2.0340150699677073,
      "grad_norm": 0.8601124882698059,
      "learning_rate": 2.8370387319403968e-05,
      "loss": 0.0215,
      "step": 1180
    },
    {
      "epoch": 2.051237890204521,
      "grad_norm": 0.23424522578716278,
      "learning_rate": 2.747044924053078e-05,
      "loss": 0.0212,
      "step": 1190
    },
    {
      "epoch": 2.0684607104413346,
      "grad_norm": 1.0023221969604492,
      "learning_rate": 2.65795779650105e-05,
      "loss": 0.03,
      "step": 1200
    },
    {
      "epoch": 2.0856835306781485,
      "grad_norm": 0.6356755495071411,
      "learning_rate": 2.569813201551205e-05,
      "loss": 0.0243,
      "step": 1210
    },
    {
      "epoch": 2.1029063509149624,
      "grad_norm": 0.11967767775058746,
      "learning_rate": 2.4826466121571573e-05,
      "loss": 0.0285,
      "step": 1220
    },
    {
      "epoch": 2.1201291711517762,
      "grad_norm": 0.6528245210647583,
      "learning_rate": 2.396493107683488e-05,
      "loss": 0.0177,
      "step": 1230
    },
    {
      "epoch": 2.1373519913885897,
      "grad_norm": 1.7940032482147217,
      "learning_rate": 2.311387359788395e-05,
      "loss": 0.0192,
      "step": 1240
    },
    {
      "epoch": 2.1545748116254035,
      "grad_norm": 0.4414513409137726,
      "learning_rate": 2.227363618470407e-05,
      "loss": 0.0174,
      "step": 1250
    },
    {
      "epoch": 2.1717976318622174,
      "grad_norm": 0.8272445201873779,
      "learning_rate": 2.1444556982847997e-05,
      "loss": 0.0258,
      "step": 1260
    },
    {
      "epoch": 2.1890204520990313,
      "grad_norm": 0.8364046216011047,
      "learning_rate": 2.0626969647352502e-05,
      "loss": 0.0236,
      "step": 1270
    },
    {
      "epoch": 2.206243272335845,
      "grad_norm": 0.45199769735336304,
      "learning_rate": 1.982120320846208e-05,
      "loss": 0.0213,
      "step": 1280
    },
    {
      "epoch": 2.2234660925726586,
      "grad_norm": 0.896158754825592,
      "learning_rate": 1.902758193921385e-05,
      "loss": 0.0175,
      "step": 1290
    },
    {
      "epoch": 2.2406889128094725,
      "grad_norm": 0.20419903099536896,
      "learning_rate": 1.8246425224936986e-05,
      "loss": 0.0228,
      "step": 1300
    },
    {
      "epoch": 2.2579117330462863,
      "grad_norm": 1.2011915445327759,
      "learning_rate": 1.747804743471907e-05,
      "loss": 0.0301,
      "step": 1310
    },
    {
      "epoch": 2.2751345532831,
      "grad_norm": 0.24119335412979126,
      "learning_rate": 1.6722757794891287e-05,
      "loss": 0.0194,
      "step": 1320
    },
    {
      "epoch": 2.2923573735199136,
      "grad_norm": 0.3696572780609131,
      "learning_rate": 1.5980860264583218e-05,
      "loss": 0.0143,
      "step": 1330
    },
    {
      "epoch": 2.3095801937567275,
      "grad_norm": 0.5259518623352051,
      "learning_rate": 1.52526534133974e-05,
      "loss": 0.016,
      "step": 1340
    },
    {
      "epoch": 2.3268030139935414,
      "grad_norm": 0.26284030079841614,
      "learning_rate": 1.4538430301252782e-05,
      "loss": 0.0118,
      "step": 1350
    },
    {
      "epoch": 2.3440258342303553,
      "grad_norm": 1.3509689569473267,
      "learning_rate": 1.3838478360445617e-05,
      "loss": 0.0159,
      "step": 1360
    },
    {
      "epoch": 2.361248654467169,
      "grad_norm": 0.3792732059955597,
      "learning_rate": 1.3153079279975011e-05,
      "loss": 0.0122,
      "step": 1370
    },
    {
      "epoch": 2.378471474703983,
      "grad_norm": 1.3292490243911743,
      "learning_rate": 1.2482508892179884e-05,
      "loss": 0.0282,
      "step": 1380
    },
    {
      "epoch": 2.3956942949407964,
      "grad_norm": 0.7557842135429382,
      "learning_rate": 1.1827037061732876e-05,
      "loss": 0.0133,
      "step": 1390
    },
    {
      "epoch": 2.4129171151776103,
      "grad_norm": 1.6580746173858643,
      "learning_rate": 1.1186927577035866e-05,
      "loss": 0.0148,
      "step": 1400
    },
    {
      "epoch": 2.430139935414424,
      "grad_norm": 0.25726577639579773,
      "learning_rate": 1.0562438044060846e-05,
      "loss": 0.0254,
      "step": 1410
    },
    {
      "epoch": 2.447362755651238,
      "grad_norm": 0.34954652190208435,
      "learning_rate": 9.953819782678885e-06,
      "loss": 0.0173,
      "step": 1420
    },
    {
      "epoch": 2.4645855758880515,
      "grad_norm": 0.8239722847938538,
      "learning_rate": 9.361317725518749e-06,
      "loss": 0.0151,
      "step": 1430
    },
    {
      "epoch": 2.4818083961248654,
      "grad_norm": 0.48587024211883545,
      "learning_rate": 8.785170319396175e-06,
      "loss": 0.0057,
      "step": 1440
    },
    {
      "epoch": 2.4990312163616792,
      "grad_norm": 0.5141454339027405,
      "learning_rate": 8.225609429353187e-06,
      "loss": 0.0158,
      "step": 1450
    },
    {
      "epoch": 2.516254036598493,
      "grad_norm": 1.1281633377075195,
      "learning_rate": 7.682860245346213e-06,
      "loss": 0.0187,
      "step": 1460
    },
    {
      "epoch": 2.533476856835307,
      "grad_norm": 0.26253053545951843,
      "learning_rate": 7.157141191620548e-06,
      "loss": 0.0247,
      "step": 1470
    },
    {
      "epoch": 2.5506996770721204,
      "grad_norm": 0.3629915714263916,
      "learning_rate": 6.648663838807562e-06,
      "loss": 0.0114,
      "step": 1480
    },
    {
      "epoch": 2.5679224973089343,
      "grad_norm": 0.5493706464767456,
      "learning_rate": 6.157632818780179e-06,
      "loss": 0.0258,
      "step": 1490
    },
    {
      "epoch": 2.585145317545748,
      "grad_norm": 0.7571175694465637,
      "learning_rate": 5.684245742300625e-06,
      "loss": 0.0244,
      "step": 1500
    },
    {
      "epoch": 2.602368137782562,
      "grad_norm": 0.8593596816062927,
      "learning_rate": 5.228693119493955e-06,
      "loss": 0.0177,
      "step": 1510
    },
    {
      "epoch": 2.6195909580193755,
      "grad_norm": 0.7092161774635315,
      "learning_rate": 4.791158283178998e-06,
      "loss": 0.0221,
      "step": 1520
    },
    {
      "epoch": 2.6368137782561893,
      "grad_norm": 0.7856480479240417,
      "learning_rate": 4.371817315087845e-06,
      "loss": 0.0182,
      "step": 1530
    },
    {
      "epoch": 2.654036598493003,
      "grad_norm": 0.2611364722251892,
      "learning_rate": 3.97083897500341e-06,
      "loss": 0.0309,
      "step": 1540
    },
    {
      "epoch": 2.671259418729817,
      "grad_norm": 0.24090564250946045,
      "learning_rate": 3.5883846328436943e-06,
      "loss": 0.0162,
      "step": 1550
    },
    {
      "epoch": 2.688482238966631,
      "grad_norm": 0.9433664083480835,
      "learning_rate": 3.2246082037199532e-06,
      "loss": 0.0097,
      "step": 1560
    },
    {
      "epoch": 2.705705059203445,
      "grad_norm": 0.30860435962677,
      "learning_rate": 2.8796560859950418e-06,
      "loss": 0.0116,
      "step": 1570
    },
    {
      "epoch": 2.7229278794402583,
      "grad_norm": 1.7633469104766846,
      "learning_rate": 2.55366710236683e-06,
      "loss": 0.0365,
      "step": 1580
    },
    {
      "epoch": 2.740150699677072,
      "grad_norm": 0.9952844977378845,
      "learning_rate": 2.2467724440002336e-06,
      "loss": 0.0172,
      "step": 1590
    },
    {
      "epoch": 2.757373519913886,
      "grad_norm": 0.10492295026779175,
      "learning_rate": 1.9590956177306664e-06,
      "loss": 0.0118,
      "step": 1600
    },
    {
      "epoch": 2.7745963401506994,
      "grad_norm": 0.3807716965675354,
      "learning_rate": 1.690752396359857e-06,
      "loss": 0.0216,
      "step": 1610
    },
    {
      "epoch": 2.7918191603875133,
      "grad_norm": 1.4428822994232178,
      "learning_rate": 1.4418507720641793e-06,
      "loss": 0.0077,
      "step": 1620
    },
    {
      "epoch": 2.809041980624327,
      "grad_norm": 0.2699427306652069,
      "learning_rate": 1.2124909129342332e-06,
      "loss": 0.0141,
      "step": 1630
    },
    {
      "epoch": 2.826264800861141,
      "grad_norm": 0.28633931279182434,
      "learning_rate": 1.0027651226631462e-06,
      "loss": 0.0193,
      "step": 1640
    },
    {
      "epoch": 2.843487621097955,
      "grad_norm": 1.2662489414215088,
      "learning_rate": 8.127578033998662e-07,
      "loss": 0.0096,
      "step": 1650
    },
    {
      "epoch": 2.860710441334769,
      "grad_norm": 0.25666847825050354,
      "learning_rate": 6.425454217822425e-07,
      "loss": 0.0152,
      "step": 1660
    },
    {
      "epoch": 2.8779332615715822,
      "grad_norm": 0.21849583089351654,
      "learning_rate": 4.921964781638367e-07,
      "loss": 0.0218,
      "step": 1670
    },
    {
      "epoch": 2.895156081808396,
      "grad_norm": 1.1365876197814941,
      "learning_rate": 3.617714790465576e-07,
      "loss": 0.0186,
      "step": 1680
    },
    {
      "epoch": 2.91237890204521,
      "grad_norm": 0.5658370852470398,
      "learning_rate": 2.5132291273042285e-07,
      "loss": 0.0194,
      "step": 1690
    },
    {
      "epoch": 2.9296017222820234,
      "grad_norm": 1.8598343133926392,
      "learning_rate": 1.608952281901055e-07,
      "loss": 0.01,
      "step": 1700
    },
    {
      "epoch": 2.9468245425188373,
      "grad_norm": 0.30277392268180847,
      "learning_rate": 9.052481718690997e-08,
      "loss": 0.016,
      "step": 1710
    },
    {
      "epoch": 2.964047362755651,
      "grad_norm": 0.689485490322113,
      "learning_rate": 4.023999962322611e-08,
      "loss": 0.0157,
      "step": 1720
    },
    {
      "epoch": 2.981270182992465,
      "grad_norm": 0.28580042719841003,
      "learning_rate": 1.006101214545696e-08,
      "loss": 0.0149,
      "step": 1730
    },
    {
      "epoch": 2.998493003229279,
      "grad_norm": 1.5223551988601685,
      "learning_rate": 0.0,
      "loss": 0.0164,
      "step": 1740
    },
    {
      "epoch": 2.998493003229279,
      "eval_loss": 0.5208209156990051,
      "eval_runtime": 51.4811,
      "eval_samples_per_second": 24.242,
      "eval_steps_per_second": 6.06,
      "step": 1740
    },
    {
      "epoch": 3.30188679245283,
      "grad_norm": 2.5895349979400635,
      "learning_rate": 4.994511544334919e-05,
      "loss": 0.3499,
      "step": 1750
    },
    {
      "epoch": 3.3207547169811322,
      "grad_norm": 4.523750305175781,
      "learning_rate": 4.9396284425743326e-05,
      "loss": 0.2475,
      "step": 1760
    },
    {
      "epoch": 3.339622641509434,
      "grad_norm": 1.4366838932037354,
      "learning_rate": 4.884752615068481e-05,
      "loss": 0.2243,
      "step": 1770
    },
    {
      "epoch": 3.358490566037736,
      "grad_norm": 1.8269908428192139,
      "learning_rate": 4.829890673883792e-05,
      "loss": 0.1891,
      "step": 1780
    },
    {
      "epoch": 3.3773584905660377,
      "grad_norm": 1.1949448585510254,
      "learning_rate": 4.77504922941351e-05,
      "loss": 0.2048,
      "step": 1790
    },
    {
      "epoch": 3.3962264150943398,
      "grad_norm": 1.0569114685058594,
      "learning_rate": 4.7202348895812035e-05,
      "loss": 0.1996,
      "step": 1800
    },
    {
      "epoch": 3.4150943396226414,
      "grad_norm": 2.018242359161377,
      "learning_rate": 4.665454259044565e-05,
      "loss": 0.1802,
      "step": 1810
    },
    {
      "epoch": 3.4339622641509435,
      "grad_norm": 0.9257389903068542,
      "learning_rate": 4.610713938399601e-05,
      "loss": 0.1714,
      "step": 1820
    },
    {
      "epoch": 3.452830188679245,
      "grad_norm": 2.628207206726074,
      "learning_rate": 4.5560205233853266e-05,
      "loss": 0.1737,
      "step": 1830
    },
    {
      "epoch": 3.4716981132075473,
      "grad_norm": 1.6258714199066162,
      "learning_rate": 4.5013806040890294e-05,
      "loss": 0.1769,
      "step": 1840
    },
    {
      "epoch": 3.490566037735849,
      "grad_norm": 1.1421829462051392,
      "learning_rate": 4.4468007641522243e-05,
      "loss": 0.1566,
      "step": 1850
    },
    {
      "epoch": 3.509433962264151,
      "grad_norm": 1.5976817607879639,
      "learning_rate": 4.392287579977374e-05,
      "loss": 0.1578,
      "step": 1860
    },
    {
      "epoch": 3.5283018867924527,
      "grad_norm": 1.4161467552185059,
      "learning_rate": 4.337847619935497e-05,
      "loss": 0.1429,
      "step": 1870
    },
    {
      "epoch": 3.547169811320755,
      "grad_norm": 2.1707663536071777,
      "learning_rate": 4.2834874435747305e-05,
      "loss": 0.1587,
      "step": 1880
    },
    {
      "epoch": 3.5660377358490565,
      "grad_norm": 1.65029776096344,
      "learning_rate": 4.2292136008299635e-05,
      "loss": 0.1426,
      "step": 1890
    },
    {
      "epoch": 3.5849056603773586,
      "grad_norm": 2.372640371322632,
      "learning_rate": 4.1750326312336254e-05,
      "loss": 0.1317,
      "step": 1900
    },
    {
      "epoch": 3.6037735849056602,
      "grad_norm": 3.1187949180603027,
      "learning_rate": 4.120951063127729e-05,
      "loss": 0.1479,
      "step": 1910
    },
    {
      "epoch": 3.6226415094339623,
      "grad_norm": 1.3472468852996826,
      "learning_rate": 4.066975412877255e-05,
      "loss": 0.1276,
      "step": 1920
    },
    {
      "epoch": 3.641509433962264,
      "grad_norm": 2.0730667114257812,
      "learning_rate": 4.013112184084998e-05,
      "loss": 0.1457,
      "step": 1930
    },
    {
      "epoch": 3.660377358490566,
      "grad_norm": 1.980075478553772,
      "learning_rate": 3.959367866807926e-05,
      "loss": 0.1314,
      "step": 1940
    },
    {
      "epoch": 3.6792452830188678,
      "grad_norm": 1.4890042543411255,
      "learning_rate": 3.905748936775195e-05,
      "loss": 0.1453,
      "step": 1950
    },
    {
      "epoch": 3.69811320754717,
      "grad_norm": 1.3257464170455933,
      "learning_rate": 3.852261854607866e-05,
      "loss": 0.1194,
      "step": 1960
    },
    {
      "epoch": 3.7169811320754715,
      "grad_norm": 1.4694807529449463,
      "learning_rate": 3.798913065040469e-05,
      "loss": 0.1223,
      "step": 1970
    },
    {
      "epoch": 3.7358490566037736,
      "grad_norm": 1.4283145666122437,
      "learning_rate": 3.7457089961444636e-05,
      "loss": 0.1285,
      "step": 1980
    },
    {
      "epoch": 3.7547169811320753,
      "grad_norm": 2.2356791496276855,
      "learning_rate": 3.6926560585537055e-05,
      "loss": 0.1459,
      "step": 1990
    },
    {
      "epoch": 3.7735849056603774,
      "grad_norm": 1.8616364002227783,
      "learning_rate": 3.6397606446920294e-05,
      "loss": 0.1107,
      "step": 2000
    },
    {
      "epoch": 3.7924528301886795,
      "grad_norm": 2.8414831161499023,
      "learning_rate": 3.587029128003006e-05,
      "loss": 0.1358,
      "step": 2010
    },
    {
      "epoch": 3.811320754716981,
      "grad_norm": 1.7999942302703857,
      "learning_rate": 3.534467862182008e-05,
      "loss": 0.0957,
      "step": 2020
    },
    {
      "epoch": 3.830188679245283,
      "grad_norm": 2.1386489868164062,
      "learning_rate": 3.4820831804106356e-05,
      "loss": 0.1382,
      "step": 2030
    },
    {
      "epoch": 3.849056603773585,
      "grad_norm": 2.156860589981079,
      "learning_rate": 3.4298813945936295e-05,
      "loss": 0.1025,
      "step": 2040
    },
    {
      "epoch": 3.867924528301887,
      "grad_norm": 1.8880937099456787,
      "learning_rate": 3.377868794598336e-05,
      "loss": 0.1002,
      "step": 2050
    },
    {
      "epoch": 3.8867924528301887,
      "grad_norm": 2.1585254669189453,
      "learning_rate": 3.3260516474968285e-05,
      "loss": 0.1005,
      "step": 2060
    },
    {
      "epoch": 3.9056603773584904,
      "grad_norm": 3.1689813137054443,
      "learning_rate": 3.274436196810789e-05,
      "loss": 0.1151,
      "step": 2070
    },
    {
      "epoch": 3.9245283018867925,
      "grad_norm": 2.0909841060638428,
      "learning_rate": 3.223028661759211e-05,
      "loss": 0.1266,
      "step": 2080
    },
    {
      "epoch": 3.9433962264150946,
      "grad_norm": 1.9260257482528687,
      "learning_rate": 3.1718352365090357e-05,
      "loss": 0.1152,
      "step": 2090
    },
    {
      "epoch": 3.9622641509433962,
      "grad_norm": 1.4319446086883545,
      "learning_rate": 3.12086208942881e-05,
      "loss": 0.118,
      "step": 2100
    },
    {
      "epoch": 3.981132075471698,
      "grad_norm": 2.5875847339630127,
      "learning_rate": 3.0701153623454537e-05,
      "loss": 0.0963,
      "step": 2110
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.058112859725952,
      "learning_rate": 3.019601169804216e-05,
      "loss": 0.0956,
      "step": 2120
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.11542381346225739,
      "eval_runtime": 51.6099,
      "eval_samples_per_second": 24.181,
      "eval_steps_per_second": 6.045,
      "step": 2120
    },
    {
      "epoch": 4.018867924528302,
      "grad_norm": 2.4401469230651855,
      "learning_rate": 2.9693255983319325e-05,
      "loss": 0.0793,
      "step": 2130
    },
    {
      "epoch": 4.037735849056604,
      "grad_norm": 3.7734174728393555,
      "learning_rate": 2.919294705703647e-05,
      "loss": 0.0734,
      "step": 2140
    },
    {
      "epoch": 4.056603773584905,
      "grad_norm": 2.365676164627075,
      "learning_rate": 2.8695145202126956e-05,
      "loss": 0.0596,
      "step": 2150
    },
    {
      "epoch": 4.0754716981132075,
      "grad_norm": 2.897873878479004,
      "learning_rate": 2.819991039944363e-05,
      "loss": 0.0704,
      "step": 2160
    },
    {
      "epoch": 4.09433962264151,
      "grad_norm": 3.2120182514190674,
      "learning_rate": 2.7707302320531504e-05,
      "loss": 0.0734,
      "step": 2170
    },
    {
      "epoch": 4.113207547169812,
      "grad_norm": 1.7584033012390137,
      "learning_rate": 2.7217380320437978e-05,
      "loss": 0.0708,
      "step": 2180
    },
    {
      "epoch": 4.132075471698113,
      "grad_norm": 2.821427345275879,
      "learning_rate": 2.6730203430560947e-05,
      "loss": 0.0899,
      "step": 2190
    },
    {
      "epoch": 4.150943396226415,
      "grad_norm": 2.7549827098846436,
      "learning_rate": 2.624583035153609e-05,
      "loss": 0.0627,
      "step": 2200
    },
    {
      "epoch": 4.169811320754717,
      "grad_norm": 3.558983325958252,
      "learning_rate": 2.576431944616393e-05,
      "loss": 0.0761,
      "step": 2210
    },
    {
      "epoch": 4.188679245283019,
      "grad_norm": 2.956676959991455,
      "learning_rate": 2.5285728732377613e-05,
      "loss": 0.0706,
      "step": 2220
    },
    {
      "epoch": 4.2075471698113205,
      "grad_norm": 1.7103902101516724,
      "learning_rate": 2.4810115876252303e-05,
      "loss": 0.067,
      "step": 2230
    },
    {
      "epoch": 4.226415094339623,
      "grad_norm": 5.385217666625977,
      "learning_rate": 2.4337538185056762e-05,
      "loss": 0.0887,
      "step": 2240
    },
    {
      "epoch": 4.245283018867925,
      "grad_norm": 2.241084575653076,
      "learning_rate": 2.3868052600348528e-05,
      "loss": 0.0584,
      "step": 2250
    },
    {
      "epoch": 4.264150943396227,
      "grad_norm": 2.916395425796509,
      "learning_rate": 2.3401715691112746e-05,
      "loss": 0.0614,
      "step": 2260
    },
    {
      "epoch": 4.283018867924528,
      "grad_norm": 1.41456139087677,
      "learning_rate": 2.2938583646946253e-05,
      "loss": 0.0486,
      "step": 2270
    },
    {
      "epoch": 4.30188679245283,
      "grad_norm": 3.303861141204834,
      "learning_rate": 2.247871227128709e-05,
      "loss": 0.0619,
      "step": 2280
    },
    {
      "epoch": 4.320754716981132,
      "grad_norm": 2.977717638015747,
      "learning_rate": 2.2022156974690723e-05,
      "loss": 0.0558,
      "step": 2290
    },
    {
      "epoch": 4.339622641509434,
      "grad_norm": 3.2562661170959473,
      "learning_rate": 2.1568972768153556e-05,
      "loss": 0.0488,
      "step": 2300
    },
    {
      "epoch": 4.3584905660377355,
      "grad_norm": 4.394615173339844,
      "learning_rate": 2.1119214256484532e-05,
      "loss": 0.0666,
      "step": 2310
    },
    {
      "epoch": 4.377358490566038,
      "grad_norm": 1.17644464969635,
      "learning_rate": 2.067293563172581e-05,
      "loss": 0.0645,
      "step": 2320
    },
    {
      "epoch": 4.39622641509434,
      "grad_norm": 2.4904673099517822,
      "learning_rate": 2.0230190666622974e-05,
      "loss": 0.0444,
      "step": 2330
    },
    {
      "epoch": 4.415094339622642,
      "grad_norm": 2.293632984161377,
      "learning_rate": 1.9791032708145963e-05,
      "loss": 0.0552,
      "step": 2340
    },
    {
      "epoch": 4.433962264150943,
      "grad_norm": 3.5788774490356445,
      "learning_rate": 1.9355514671061154e-05,
      "loss": 0.0741,
      "step": 2350
    },
    {
      "epoch": 4.452830188679245,
      "grad_norm": 1.5377596616744995,
      "learning_rate": 1.8923689031555697e-05,
      "loss": 0.0602,
      "step": 2360
    },
    {
      "epoch": 4.471698113207547,
      "grad_norm": 3.207468032836914,
      "learning_rate": 1.849560782091445e-05,
      "loss": 0.0735,
      "step": 2370
    },
    {
      "epoch": 4.490566037735849,
      "grad_norm": 1.774930477142334,
      "learning_rate": 1.807132261925073e-05,
      "loss": 0.0467,
      "step": 2380
    },
    {
      "epoch": 4.509433962264151,
      "grad_norm": 0.8854224681854248,
      "learning_rate": 1.7650884549291343e-05,
      "loss": 0.0436,
      "step": 2390
    },
    {
      "epoch": 4.528301886792453,
      "grad_norm": 3.6947333812713623,
      "learning_rate": 1.7234344270216713e-05,
      "loss": 0.053,
      "step": 2400
    },
    {
      "epoch": 4.547169811320755,
      "grad_norm": 2.1345760822296143,
      "learning_rate": 1.6821751971556953e-05,
      "loss": 0.049,
      "step": 2410
    },
    {
      "epoch": 4.566037735849057,
      "grad_norm": 2.0520858764648438,
      "learning_rate": 1.6413157367144354e-05,
      "loss": 0.0498,
      "step": 2420
    },
    {
      "epoch": 4.584905660377358,
      "grad_norm": 3.3088839054107666,
      "learning_rate": 1.6008609689123366e-05,
      "loss": 0.0566,
      "step": 2430
    },
    {
      "epoch": 4.60377358490566,
      "grad_norm": 1.7417080402374268,
      "learning_rate": 1.5608157682018505e-05,
      "loss": 0.0479,
      "step": 2440
    },
    {
      "epoch": 4.622641509433962,
      "grad_norm": 5.742934226989746,
      "learning_rate": 1.5211849596861139e-05,
      "loss": 0.0664,
      "step": 2450
    },
    {
      "epoch": 4.6415094339622645,
      "grad_norm": 6.372235298156738,
      "learning_rate": 1.4819733185375534e-05,
      "loss": 0.0506,
      "step": 2460
    },
    {
      "epoch": 4.660377358490566,
      "grad_norm": 1.7613149881362915,
      "learning_rate": 1.4431855694225254e-05,
      "loss": 0.0368,
      "step": 2470
    },
    {
      "epoch": 4.679245283018868,
      "grad_norm": 3.278892993927002,
      "learning_rate": 1.4048263859320344e-05,
      "loss": 0.052,
      "step": 2480
    },
    {
      "epoch": 4.69811320754717,
      "grad_norm": 1.095307469367981,
      "learning_rate": 1.3669003900186012e-05,
      "loss": 0.039,
      "step": 2490
    },
    {
      "epoch": 4.716981132075472,
      "grad_norm": 3.044923782348633,
      "learning_rate": 1.3294121514393637e-05,
      "loss": 0.0536,
      "step": 2500
    },
    {
      "epoch": 4.735849056603773,
      "grad_norm": 1.458532452583313,
      "learning_rate": 1.2923661872054544e-05,
      "loss": 0.0386,
      "step": 2510
    },
    {
      "epoch": 4.754716981132075,
      "grad_norm": 3.0379385948181152,
      "learning_rate": 1.2557669610377399e-05,
      "loss": 0.0351,
      "step": 2520
    },
    {
      "epoch": 4.773584905660377,
      "grad_norm": 1.3577989339828491,
      "learning_rate": 1.219618882828984e-05,
      "loss": 0.0488,
      "step": 2530
    },
    {
      "epoch": 4.7924528301886795,
      "grad_norm": 1.317501425743103,
      "learning_rate": 1.1839263081124946e-05,
      "loss": 0.0413,
      "step": 2540
    },
    {
      "epoch": 4.811320754716981,
      "grad_norm": 1.763659954071045,
      "learning_rate": 1.1486935375373126e-05,
      "loss": 0.0514,
      "step": 2550
    },
    {
      "epoch": 4.830188679245283,
      "grad_norm": 3.2566981315612793,
      "learning_rate": 1.113924816350026e-05,
      "loss": 0.046,
      "step": 2560
    },
    {
      "epoch": 4.849056603773585,
      "grad_norm": 1.0355610847473145,
      "learning_rate": 1.0796243338832523e-05,
      "loss": 0.0259,
      "step": 2570
    },
    {
      "epoch": 4.867924528301887,
      "grad_norm": 4.192140579223633,
      "learning_rate": 1.04579622305086e-05,
      "loss": 0.0366,
      "step": 2580
    },
    {
      "epoch": 4.886792452830189,
      "grad_norm": 3.1732048988342285,
      "learning_rate": 1.0124445598499915e-05,
      "loss": 0.0574,
      "step": 2590
    },
    {
      "epoch": 4.90566037735849,
      "grad_norm": 1.3256559371948242,
      "learning_rate": 9.795733628699333e-06,
      "loss": 0.053,
      "step": 2600
    },
    {
      "epoch": 4.9245283018867925,
      "grad_norm": 2.7711479663848877,
      "learning_rate": 9.47186592807915e-06,
      "loss": 0.0507,
      "step": 2610
    },
    {
      "epoch": 4.943396226415095,
      "grad_norm": 2.3078999519348145,
      "learning_rate": 9.152881519918787e-06,
      "loss": 0.0552,
      "step": 2620
    },
    {
      "epoch": 4.962264150943396,
      "grad_norm": 1.9099466800689697,
      "learning_rate": 8.838818839102813e-06,
      "loss": 0.0587,
      "step": 2630
    },
    {
      "epoch": 4.981132075471698,
      "grad_norm": 2.8586819171905518,
      "learning_rate": 8.529715727489912e-06,
      "loss": 0.0434,
      "step": 2640
    },
    {
      "epoch": 5.0,
      "grad_norm": 3.796604633331299,
      "learning_rate": 8.225609429353187e-06,
      "loss": 0.049,
      "step": 2650
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.05848417058587074,
      "eval_runtime": 52.4595,
      "eval_samples_per_second": 23.79,
      "eval_steps_per_second": 5.947,
      "step": 2650
    },
    {
      "epoch": 5.018867924528302,
      "grad_norm": 2.0257062911987305,
      "learning_rate": 7.926536586892591e-06,
      "loss": 0.0271,
      "step": 2660
    },
    {
      "epoch": 5.037735849056604,
      "grad_norm": 1.414648413658142,
      "learning_rate": 7.63253323581985e-06,
      "loss": 0.0173,
      "step": 2670
    },
    {
      "epoch": 5.056603773584905,
      "grad_norm": 0.892978310585022,
      "learning_rate": 7.3436348010165025e-06,
      "loss": 0.0158,
      "step": 2680
    },
    {
      "epoch": 5.0754716981132075,
      "grad_norm": 1.4306669235229492,
      "learning_rate": 7.059876092265433e-06,
      "loss": 0.0268,
      "step": 2690
    },
    {
      "epoch": 5.09433962264151,
      "grad_norm": 1.8243789672851562,
      "learning_rate": 6.781291300056647e-06,
      "loss": 0.0148,
      "step": 2700
    },
    {
      "epoch": 5.113207547169812,
      "grad_norm": 0.8700891137123108,
      "learning_rate": 6.507913991467596e-06,
      "loss": 0.0179,
      "step": 2710
    },
    {
      "epoch": 5.132075471698113,
      "grad_norm": 0.6138803958892822,
      "learning_rate": 6.239777106118605e-06,
      "loss": 0.0232,
      "step": 2720
    },
    {
      "epoch": 5.150943396226415,
      "grad_norm": 1.4130644798278809,
      "learning_rate": 5.976912952204017e-06,
      "loss": 0.0219,
      "step": 2730
    },
    {
      "epoch": 5.169811320754717,
      "grad_norm": 0.9546433687210083,
      "learning_rate": 5.719353202599209e-06,
      "loss": 0.0137,
      "step": 2740
    },
    {
      "epoch": 5.188679245283019,
      "grad_norm": 2.612288236618042,
      "learning_rate": 5.4671288910443816e-06,
      "loss": 0.0205,
      "step": 2750
    },
    {
      "epoch": 5.2075471698113205,
      "grad_norm": 3.984002113342285,
      "learning_rate": 5.220270408405198e-06,
      "loss": 0.0198,
      "step": 2760
    },
    {
      "epoch": 5.226415094339623,
      "grad_norm": 2.3614842891693115,
      "learning_rate": 4.978807499011007e-06,
      "loss": 0.0231,
      "step": 2770
    },
    {
      "epoch": 5.245283018867925,
      "grad_norm": 2.0582902431488037,
      "learning_rate": 4.7427692570708445e-06,
      "loss": 0.0163,
      "step": 2780
    },
    {
      "epoch": 5.264150943396227,
      "grad_norm": 2.8178622722625732,
      "learning_rate": 4.512184123167867e-06,
      "loss": 0.0149,
      "step": 2790
    },
    {
      "epoch": 5.283018867924528,
      "grad_norm": 2.1924331188201904,
      "learning_rate": 4.287079880832478e-06,
      "loss": 0.0279,
      "step": 2800
    },
    {
      "epoch": 5.30188679245283,
      "grad_norm": 1.384915828704834,
      "learning_rate": 4.067483653194687e-06,
      "loss": 0.0251,
      "step": 2810
    },
    {
      "epoch": 5.320754716981132,
      "grad_norm": 4.476295471191406,
      "learning_rate": 3.853421899715992e-06,
      "loss": 0.0178,
      "step": 2820
    },
    {
      "epoch": 5.339622641509434,
      "grad_norm": 1.659889578819275,
      "learning_rate": 3.6449204130012073e-06,
      "loss": 0.0113,
      "step": 2830
    },
    {
      "epoch": 5.3584905660377355,
      "grad_norm": 3.112685441970825,
      "learning_rate": 3.44200431569075e-06,
      "loss": 0.0245,
      "step": 2840
    },
    {
      "epoch": 5.377358490566038,
      "grad_norm": 2.241353988647461,
      "learning_rate": 3.2446980574334705e-06,
      "loss": 0.025,
      "step": 2850
    },
    {
      "epoch": 5.39622641509434,
      "grad_norm": 3.989398956298828,
      "learning_rate": 3.053025411940802e-06,
      "loss": 0.0212,
      "step": 2860
    },
    {
      "epoch": 5.415094339622642,
      "grad_norm": 3.7615489959716797,
      "learning_rate": 2.867009474122123e-06,
      "loss": 0.0205,
      "step": 2870
    },
    {
      "epoch": 5.433962264150943,
      "grad_norm": 7.042976379394531,
      "learning_rate": 2.6866726573021026e-06,
      "loss": 0.0146,
      "step": 2880
    },
    {
      "epoch": 5.452830188679245,
      "grad_norm": 0.5161448121070862,
      "learning_rate": 2.5120366905200254e-06,
      "loss": 0.013,
      "step": 2890
    },
    {
      "epoch": 5.471698113207547,
      "grad_norm": 1.1484304666519165,
      "learning_rate": 2.3431226159116637e-06,
      "loss": 0.0176,
      "step": 2900
    },
    {
      "epoch": 5.490566037735849,
      "grad_norm": 0.7566860318183899,
      "learning_rate": 2.179950786173879e-06,
      "loss": 0.0133,
      "step": 2910
    },
    {
      "epoch": 5.509433962264151,
      "grad_norm": 1.8738235235214233,
      "learning_rate": 2.022540862112282e-06,
      "loss": 0.016,
      "step": 2920
    },
    {
      "epoch": 5.528301886792453,
      "grad_norm": 0.5096126794815063,
      "learning_rate": 1.870911810272291e-06,
      "loss": 0.0109,
      "step": 2930
    },
    {
      "epoch": 5.547169811320755,
      "grad_norm": 2.872267961502075,
      "learning_rate": 1.725081900653791e-06,
      "loss": 0.0258,
      "step": 2940
    },
    {
      "epoch": 5.566037735849057,
      "grad_norm": 1.2590959072113037,
      "learning_rate": 1.5850687045098178e-06,
      "loss": 0.0203,
      "step": 2950
    },
    {
      "epoch": 5.584905660377358,
      "grad_norm": 2.376469850540161,
      "learning_rate": 1.4508890922293018e-06,
      "loss": 0.0184,
      "step": 2960
    },
    {
      "epoch": 5.60377358490566,
      "grad_norm": 0.6429818272590637,
      "learning_rate": 1.3225592313043822e-06,
      "loss": 0.0086,
      "step": 2970
    },
    {
      "epoch": 5.622641509433962,
      "grad_norm": 0.9160204529762268,
      "learning_rate": 1.2000945843823551e-06,
      "loss": 0.0236,
      "step": 2980
    },
    {
      "epoch": 5.6415094339622645,
      "grad_norm": 1.7655017375946045,
      "learning_rate": 1.0835099074025134e-06,
      "loss": 0.0136,
      "step": 2990
    },
    {
      "epoch": 5.660377358490566,
      "grad_norm": 1.2353525161743164,
      "learning_rate": 9.728192478182574e-07,
      "loss": 0.0139,
      "step": 3000
    },
    {
      "epoch": 5.679245283018868,
      "grad_norm": 0.14669166505336761,
      "learning_rate": 8.680359429044271e-07,
      "loss": 0.0215,
      "step": 3010
    },
    {
      "epoch": 5.69811320754717,
      "grad_norm": 1.6586666107177734,
      "learning_rate": 7.691726181503267e-07,
      "loss": 0.0154,
      "step": 3020
    },
    {
      "epoch": 5.716981132075472,
      "grad_norm": 1.8982332944869995,
      "learning_rate": 6.762411857384187e-07,
      "loss": 0.0187,
      "step": 3030
    },
    {
      "epoch": 5.735849056603773,
      "grad_norm": 3.2556498050689697,
      "learning_rate": 5.892528431090393e-07,
      "loss": 0.0225,
      "step": 3040
    },
    {
      "epoch": 5.754716981132075,
      "grad_norm": 4.55875825881958,
      "learning_rate": 5.08218071611194e-07,
      "loss": 0.0173,
      "step": 3050
    },
    {
      "epoch": 5.773584905660377,
      "grad_norm": 1.7173506021499634,
      "learning_rate": 4.331466352396396e-07,
      "loss": 0.0141,
      "step": 3060
    },
    {
      "epoch": 5.7924528301886795,
      "grad_norm": 2.2875864505767822,
      "learning_rate": 3.6404757945842084e-07,
      "loss": 0.0206,
      "step": 3070
    },
    {
      "epoch": 5.811320754716981,
      "grad_norm": 0.9061328172683716,
      "learning_rate": 3.009292301109412e-07,
      "loss": 0.019,
      "step": 3080
    },
    {
      "epoch": 5.830188679245283,
      "grad_norm": 2.90816068649292,
      "learning_rate": 2.437991924167937e-07,
      "loss": 0.015,
      "step": 3090
    },
    {
      "epoch": 5.849056603773585,
      "grad_norm": 2.2710399627685547,
      "learning_rate": 1.9266435005540483e-07,
      "loss": 0.0203,
      "step": 3100
    },
    {
      "epoch": 5.867924528301887,
      "grad_norm": 1.203890323638916,
      "learning_rate": 1.475308643365758e-07,
      "loss": 0.0132,
      "step": 3110
    },
    {
      "epoch": 5.886792452830189,
      "grad_norm": 1.9163457155227661,
      "learning_rate": 1.0840417345814313e-07,
      "loss": 0.0203,
      "step": 3120
    },
    {
      "epoch": 5.90566037735849,
      "grad_norm": 1.3116164207458496,
      "learning_rate": 7.528899185067495e-08,
      "loss": 0.0164,
      "step": 3130
    },
    {
      "epoch": 5.9245283018867925,
      "grad_norm": 0.3754384219646454,
      "learning_rate": 4.818930960945878e-08,
      "loss": 0.0189,
      "step": 3140
    },
    {
      "epoch": 5.943396226415095,
      "grad_norm": 3.1927788257598877,
      "learning_rate": 2.7108392013708295e-08,
      "loss": 0.0173,
      "step": 3150
    },
    {
      "epoch": 5.962264150943396,
      "grad_norm": 4.645062446594238,
      "learning_rate": 1.2048779133150279e-08,
      "loss": 0.0128,
      "step": 3160
    },
    {
      "epoch": 5.981132075471698,
      "grad_norm": 0.7805009484291077,
      "learning_rate": 3.0122855219305577e-09,
      "loss": 0.0245,
      "step": 3170
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.1503000259399414,
      "learning_rate": 0.0,
      "loss": 0.0228,
      "step": 3180
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.055214423686265945,
      "eval_runtime": 51.5208,
      "eval_samples_per_second": 24.223,
      "eval_steps_per_second": 6.056,
      "step": 3180
    },
    {
      "epoch": 6.0,
      "step": 3180,
      "total_flos": 4.9862606523151155e+17,
      "train_loss": 0.030345131489653256,
      "train_runtime": 6045.6919,
      "train_samples_per_second": 16.829,
      "train_steps_per_second": 0.526
    }
  ],
  "logging_steps": 10,
  "max_steps": 3180,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.9862606523151155e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
