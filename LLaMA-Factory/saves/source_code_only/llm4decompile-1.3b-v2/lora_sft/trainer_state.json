{
  "best_metric": 0.5513536334037781,
  "best_model_checkpoint": "saves/source_code_only/llm4decompile-1.3b-v2/lora_sft/checkpoint-1160",
  "epoch": 2.998493003229279,
  "eval_steps": 500,
  "global_step": 1740,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017222820236813777,
      "grad_norm": 12.59658145904541,
      "learning_rate": 5.747126436781609e-06,
      "loss": 6.0379,
      "step": 10
    },
    {
      "epoch": 0.03444564047362755,
      "grad_norm": 13.722668647766113,
      "learning_rate": 1.1494252873563218e-05,
      "loss": 6.1383,
      "step": 20
    },
    {
      "epoch": 0.05166846071044134,
      "grad_norm": 13.405319213867188,
      "learning_rate": 1.7241379310344828e-05,
      "loss": 5.8234,
      "step": 30
    },
    {
      "epoch": 0.0688912809472551,
      "grad_norm": 7.106286525726318,
      "learning_rate": 2.2988505747126437e-05,
      "loss": 3.762,
      "step": 40
    },
    {
      "epoch": 0.0861141011840689,
      "grad_norm": 2.3106510639190674,
      "learning_rate": 2.8735632183908045e-05,
      "loss": 2.6803,
      "step": 50
    },
    {
      "epoch": 0.10333692142088267,
      "grad_norm": 5.584672451019287,
      "learning_rate": 3.4482758620689657e-05,
      "loss": 2.2083,
      "step": 60
    },
    {
      "epoch": 0.12055974165769645,
      "grad_norm": 3.7795088291168213,
      "learning_rate": 4.0229885057471265e-05,
      "loss": 1.8202,
      "step": 70
    },
    {
      "epoch": 0.1377825618945102,
      "grad_norm": 2.7199807167053223,
      "learning_rate": 4.597701149425287e-05,
      "loss": 1.9287,
      "step": 80
    },
    {
      "epoch": 0.155005382131324,
      "grad_norm": 3.039872407913208,
      "learning_rate": 5.172413793103449e-05,
      "loss": 0.9677,
      "step": 90
    },
    {
      "epoch": 0.1722282023681378,
      "grad_norm": 2.461395740509033,
      "learning_rate": 5.747126436781609e-05,
      "loss": 0.6488,
      "step": 100
    },
    {
      "epoch": 0.18945102260495156,
      "grad_norm": 1.8672651052474976,
      "learning_rate": 6.32183908045977e-05,
      "loss": 0.3165,
      "step": 110
    },
    {
      "epoch": 0.20667384284176535,
      "grad_norm": 4.336451530456543,
      "learning_rate": 6.896551724137931e-05,
      "loss": 0.2213,
      "step": 120
    },
    {
      "epoch": 0.2238966630785791,
      "grad_norm": 6.327053070068359,
      "learning_rate": 7.471264367816091e-05,
      "loss": 0.2236,
      "step": 130
    },
    {
      "epoch": 0.2411194833153929,
      "grad_norm": 2.936582326889038,
      "learning_rate": 8.045977011494253e-05,
      "loss": 0.1958,
      "step": 140
    },
    {
      "epoch": 0.25834230355220666,
      "grad_norm": 2.4482309818267822,
      "learning_rate": 8.620689655172413e-05,
      "loss": 0.175,
      "step": 150
    },
    {
      "epoch": 0.2755651237890204,
      "grad_norm": 3.139265298843384,
      "learning_rate": 9.195402298850575e-05,
      "loss": 0.2027,
      "step": 160
    },
    {
      "epoch": 0.29278794402583425,
      "grad_norm": 1.2461676597595215,
      "learning_rate": 9.770114942528736e-05,
      "loss": 0.1485,
      "step": 170
    },
    {
      "epoch": 0.310010764262648,
      "grad_norm": 4.6641621589660645,
      "learning_rate": 9.999637795788383e-05,
      "loss": 0.2188,
      "step": 180
    },
    {
      "epoch": 0.32723358449946177,
      "grad_norm": 1.220094919204712,
      "learning_rate": 9.997424515642708e-05,
      "loss": 0.1752,
      "step": 190
    },
    {
      "epoch": 0.3444564047362756,
      "grad_norm": 3.377408504486084,
      "learning_rate": 9.993200069547118e-05,
      "loss": 0.1731,
      "step": 200
    },
    {
      "epoch": 0.36167922497308935,
      "grad_norm": 1.963419795036316,
      "learning_rate": 9.98696615758975e-05,
      "loss": 0.1352,
      "step": 210
    },
    {
      "epoch": 0.3789020452099031,
      "grad_norm": 0.6942228078842163,
      "learning_rate": 9.978725288549161e-05,
      "loss": 0.1814,
      "step": 220
    },
    {
      "epoch": 0.3961248654467169,
      "grad_norm": 2.6925954818725586,
      "learning_rate": 9.968480778884692e-05,
      "loss": 0.1368,
      "step": 230
    },
    {
      "epoch": 0.4133476856835307,
      "grad_norm": 0.6084490418434143,
      "learning_rate": 9.956236751401791e-05,
      "loss": 0.1388,
      "step": 240
    },
    {
      "epoch": 0.43057050592034446,
      "grad_norm": 0.8268850445747375,
      "learning_rate": 9.941998133592825e-05,
      "loss": 0.1472,
      "step": 250
    },
    {
      "epoch": 0.4477933261571582,
      "grad_norm": 2.0073697566986084,
      "learning_rate": 9.925770655654061e-05,
      "loss": 0.1548,
      "step": 260
    },
    {
      "epoch": 0.465016146393972,
      "grad_norm": 3.2194855213165283,
      "learning_rate": 9.907560848179606e-05,
      "loss": 0.1449,
      "step": 270
    },
    {
      "epoch": 0.4822389666307858,
      "grad_norm": 0.5680264830589294,
      "learning_rate": 9.887376039533226e-05,
      "loss": 0.1069,
      "step": 280
    },
    {
      "epoch": 0.49946178686759957,
      "grad_norm": 4.373876571655273,
      "learning_rate": 9.865224352899119e-05,
      "loss": 0.1733,
      "step": 290
    },
    {
      "epoch": 0.5166846071044133,
      "grad_norm": 1.4024012088775635,
      "learning_rate": 9.841114703012817e-05,
      "loss": 0.1242,
      "step": 300
    },
    {
      "epoch": 0.5339074273412271,
      "grad_norm": 1.8547089099884033,
      "learning_rate": 9.815056792573532e-05,
      "loss": 0.1251,
      "step": 310
    },
    {
      "epoch": 0.5511302475780409,
      "grad_norm": 1.5783052444458008,
      "learning_rate": 9.787061108339399e-05,
      "loss": 0.1192,
      "step": 320
    },
    {
      "epoch": 0.5683530678148547,
      "grad_norm": 0.9320871233940125,
      "learning_rate": 9.757138916907185e-05,
      "loss": 0.1542,
      "step": 330
    },
    {
      "epoch": 0.5855758880516685,
      "grad_norm": 0.7754186987876892,
      "learning_rate": 9.725302260178145e-05,
      "loss": 0.1283,
      "step": 340
    },
    {
      "epoch": 0.6027987082884823,
      "grad_norm": 0.6641122698783875,
      "learning_rate": 9.69156395051188e-05,
      "loss": 0.1389,
      "step": 350
    },
    {
      "epoch": 0.620021528525296,
      "grad_norm": 1.3306427001953125,
      "learning_rate": 9.655937565570123e-05,
      "loss": 0.1117,
      "step": 360
    },
    {
      "epoch": 0.6372443487621098,
      "grad_norm": 0.9012043476104736,
      "learning_rate": 9.618437442852537e-05,
      "loss": 0.1166,
      "step": 370
    },
    {
      "epoch": 0.6544671689989235,
      "grad_norm": 1.6271581649780273,
      "learning_rate": 9.57907867392673e-05,
      "loss": 0.1247,
      "step": 380
    },
    {
      "epoch": 0.6716899892357373,
      "grad_norm": 1.0346492528915405,
      "learning_rate": 9.537877098354786e-05,
      "loss": 0.1288,
      "step": 390
    },
    {
      "epoch": 0.6889128094725512,
      "grad_norm": 0.4418860971927643,
      "learning_rate": 9.494849297318795e-05,
      "loss": 0.1276,
      "step": 400
    },
    {
      "epoch": 0.7061356297093649,
      "grad_norm": 0.7546597123146057,
      "learning_rate": 9.450012586947911e-05,
      "loss": 0.1324,
      "step": 410
    },
    {
      "epoch": 0.7233584499461787,
      "grad_norm": 2.325303316116333,
      "learning_rate": 9.403385011349639e-05,
      "loss": 0.1182,
      "step": 420
    },
    {
      "epoch": 0.7405812701829925,
      "grad_norm": 0.8295128345489502,
      "learning_rate": 9.354985335348154e-05,
      "loss": 0.1042,
      "step": 430
    },
    {
      "epoch": 0.7578040904198062,
      "grad_norm": 1.5812731981277466,
      "learning_rate": 9.304833036932579e-05,
      "loss": 0.1111,
      "step": 440
    },
    {
      "epoch": 0.77502691065662,
      "grad_norm": 0.546136200428009,
      "learning_rate": 9.252948299418254e-05,
      "loss": 0.1028,
      "step": 450
    },
    {
      "epoch": 0.7922497308934338,
      "grad_norm": 0.9550713300704956,
      "learning_rate": 9.199352003324151e-05,
      "loss": 0.1037,
      "step": 460
    },
    {
      "epoch": 0.8094725511302476,
      "grad_norm": 0.6115440726280212,
      "learning_rate": 9.144065717969706e-05,
      "loss": 0.1296,
      "step": 470
    },
    {
      "epoch": 0.8266953713670614,
      "grad_norm": 0.36516064405441284,
      "learning_rate": 9.087111692794459e-05,
      "loss": 0.1528,
      "step": 480
    },
    {
      "epoch": 0.8439181916038752,
      "grad_norm": 0.3985248804092407,
      "learning_rate": 9.02851284840397e-05,
      "loss": 0.0782,
      "step": 490
    },
    {
      "epoch": 0.8611410118406889,
      "grad_norm": 1.23383367061615,
      "learning_rate": 8.968292767345646e-05,
      "loss": 0.1324,
      "step": 500
    },
    {
      "epoch": 0.8783638320775027,
      "grad_norm": 0.38102638721466064,
      "learning_rate": 8.906475684618158e-05,
      "loss": 0.1097,
      "step": 510
    },
    {
      "epoch": 0.8955866523143164,
      "grad_norm": 0.6978121399879456,
      "learning_rate": 8.843086477918316e-05,
      "loss": 0.1227,
      "step": 520
    },
    {
      "epoch": 0.9128094725511302,
      "grad_norm": 0.6145771145820618,
      "learning_rate": 8.778150657629258e-05,
      "loss": 0.0953,
      "step": 530
    },
    {
      "epoch": 0.930032292787944,
      "grad_norm": 1.5983784198760986,
      "learning_rate": 8.71169435655405e-05,
      "loss": 0.1016,
      "step": 540
    },
    {
      "epoch": 0.9472551130247578,
      "grad_norm": 0.7287421226501465,
      "learning_rate": 8.643744319398782e-05,
      "loss": 0.119,
      "step": 550
    },
    {
      "epoch": 0.9644779332615716,
      "grad_norm": 1.6713850498199463,
      "learning_rate": 8.574327892009414e-05,
      "loss": 0.096,
      "step": 560
    },
    {
      "epoch": 0.9817007534983854,
      "grad_norm": 0.46221619844436646,
      "learning_rate": 8.503473010366713e-05,
      "loss": 0.0921,
      "step": 570
    },
    {
      "epoch": 0.9989235737351991,
      "grad_norm": 0.3331132233142853,
      "learning_rate": 8.43120818934367e-05,
      "loss": 0.0783,
      "step": 580
    },
    {
      "epoch": 0.9989235737351991,
      "eval_loss": 0.5824099779129028,
      "eval_runtime": 81.5089,
      "eval_samples_per_second": 15.311,
      "eval_steps_per_second": 3.828,
      "step": 580
    },
    {
      "epoch": 1.0170075349838537,
      "grad_norm": 0.4427303969860077,
      "learning_rate": 8.357562511229961e-05,
      "loss": 0.1038,
      "step": 590
    },
    {
      "epoch": 1.0342303552206673,
      "grad_norm": 1.0022388696670532,
      "learning_rate": 8.282565614028067e-05,
      "loss": 0.0949,
      "step": 600
    },
    {
      "epoch": 1.0514531754574812,
      "grad_norm": 0.4381020963191986,
      "learning_rate": 8.206247679525734e-05,
      "loss": 0.0778,
      "step": 610
    },
    {
      "epoch": 1.0686759956942948,
      "grad_norm": 1.7727174758911133,
      "learning_rate": 8.128639421149599e-05,
      "loss": 0.1022,
      "step": 620
    },
    {
      "epoch": 1.0858988159311087,
      "grad_norm": 1.5630415678024292,
      "learning_rate": 8.049772071604865e-05,
      "loss": 0.1281,
      "step": 630
    },
    {
      "epoch": 1.1031216361679226,
      "grad_norm": 0.6883869767189026,
      "learning_rate": 7.969677370306e-05,
      "loss": 0.105,
      "step": 640
    },
    {
      "epoch": 1.1203444564047362,
      "grad_norm": 0.8102630376815796,
      "learning_rate": 7.888387550603504e-05,
      "loss": 0.0881,
      "step": 650
    },
    {
      "epoch": 1.13756727664155,
      "grad_norm": 1.0044654607772827,
      "learning_rate": 7.805935326811912e-05,
      "loss": 0.1112,
      "step": 660
    },
    {
      "epoch": 1.1547900968783638,
      "grad_norm": 0.712370753288269,
      "learning_rate": 7.722353881044222e-05,
      "loss": 0.0992,
      "step": 670
    },
    {
      "epoch": 1.1720129171151776,
      "grad_norm": 1.4465279579162598,
      "learning_rate": 7.637676849858077e-05,
      "loss": 0.1091,
      "step": 680
    },
    {
      "epoch": 1.1892357373519915,
      "grad_norm": 2.6308352947235107,
      "learning_rate": 7.551938310719043e-05,
      "loss": 0.0926,
      "step": 690
    },
    {
      "epoch": 1.2064585575888052,
      "grad_norm": 0.2599778175354004,
      "learning_rate": 7.465172768286462e-05,
      "loss": 0.0967,
      "step": 700
    },
    {
      "epoch": 1.223681377825619,
      "grad_norm": 0.6438530087471008,
      "learning_rate": 7.377415140527389e-05,
      "loss": 0.0563,
      "step": 710
    },
    {
      "epoch": 1.2409041980624327,
      "grad_norm": 0.6702718734741211,
      "learning_rate": 7.288700744664167e-05,
      "loss": 0.1094,
      "step": 720
    },
    {
      "epoch": 1.2581270182992466,
      "grad_norm": 0.5561742782592773,
      "learning_rate": 7.199065282961371e-05,
      "loss": 0.1036,
      "step": 730
    },
    {
      "epoch": 1.2753498385360602,
      "grad_norm": 1.4749258756637573,
      "learning_rate": 7.108544828357755e-05,
      "loss": 0.1008,
      "step": 740
    },
    {
      "epoch": 1.292572658772874,
      "grad_norm": 0.6655316948890686,
      "learning_rate": 7.017175809949044e-05,
      "loss": 0.1078,
      "step": 750
    },
    {
      "epoch": 1.3097954790096877,
      "grad_norm": 0.9176864624023438,
      "learning_rate": 6.924994998327394e-05,
      "loss": 0.0839,
      "step": 760
    },
    {
      "epoch": 1.3270182992465016,
      "grad_norm": 0.2862093150615692,
      "learning_rate": 6.832039490783421e-05,
      "loss": 0.0789,
      "step": 770
    },
    {
      "epoch": 1.3442411194833155,
      "grad_norm": 0.5947741866111755,
      "learning_rate": 6.738346696376738e-05,
      "loss": 0.0732,
      "step": 780
    },
    {
      "epoch": 1.3614639397201291,
      "grad_norm": 0.27242010831832886,
      "learning_rate": 6.643954320881044e-05,
      "loss": 0.0713,
      "step": 790
    },
    {
      "epoch": 1.378686759956943,
      "grad_norm": 1.3175694942474365,
      "learning_rate": 6.548900351609793e-05,
      "loss": 0.1417,
      "step": 800
    },
    {
      "epoch": 1.3959095801937567,
      "grad_norm": 0.7951730489730835,
      "learning_rate": 6.453223042128555e-05,
      "loss": 0.1002,
      "step": 810
    },
    {
      "epoch": 1.4131324004305705,
      "grad_norm": 0.9221035838127136,
      "learning_rate": 6.35696089686024e-05,
      "loss": 0.079,
      "step": 820
    },
    {
      "epoch": 1.4303552206673844,
      "grad_norm": 0.7336502075195312,
      "learning_rate": 6.260152655589358e-05,
      "loss": 0.0991,
      "step": 830
    },
    {
      "epoch": 1.447578040904198,
      "grad_norm": 0.801763117313385,
      "learning_rate": 6.162837277871553e-05,
      "loss": 0.0878,
      "step": 840
    },
    {
      "epoch": 1.4648008611410117,
      "grad_norm": 0.6461521983146667,
      "learning_rate": 6.065053927354715e-05,
      "loss": 0.0792,
      "step": 850
    },
    {
      "epoch": 1.4820236813778256,
      "grad_norm": 1.3247617483139038,
      "learning_rate": 5.966841956017928e-05,
      "loss": 0.1164,
      "step": 860
    },
    {
      "epoch": 1.4992465016146395,
      "grad_norm": 0.6241268515586853,
      "learning_rate": 5.868240888334653e-05,
      "loss": 0.0925,
      "step": 870
    },
    {
      "epoch": 1.5164693218514533,
      "grad_norm": 1.0680079460144043,
      "learning_rate": 5.769290405366469e-05,
      "loss": 0.1042,
      "step": 880
    },
    {
      "epoch": 1.533692142088267,
      "grad_norm": 0.4559367001056671,
      "learning_rate": 5.6700303287938115e-05,
      "loss": 0.1076,
      "step": 890
    },
    {
      "epoch": 1.5509149623250806,
      "grad_norm": 1.0359922647476196,
      "learning_rate": 5.5705006048901244e-05,
      "loss": 0.0873,
      "step": 900
    },
    {
      "epoch": 1.5681377825618945,
      "grad_norm": 0.28869038820266724,
      "learning_rate": 5.4707412884458444e-05,
      "loss": 0.0997,
      "step": 910
    },
    {
      "epoch": 1.5853606027987084,
      "grad_norm": 0.39246809482574463,
      "learning_rate": 5.370792526648747e-05,
      "loss": 0.068,
      "step": 920
    },
    {
      "epoch": 1.602583423035522,
      "grad_norm": 1.159114956855774,
      "learning_rate": 5.270694542927088e-05,
      "loss": 0.1028,
      "step": 930
    },
    {
      "epoch": 1.6198062432723357,
      "grad_norm": 0.7058427333831787,
      "learning_rate": 5.170487620762066e-05,
      "loss": 0.0809,
      "step": 940
    },
    {
      "epoch": 1.6370290635091496,
      "grad_norm": 1.359495759010315,
      "learning_rate": 5.070212087476116e-05,
      "loss": 0.0981,
      "step": 950
    },
    {
      "epoch": 1.6542518837459634,
      "grad_norm": 1.0725597143173218,
      "learning_rate": 4.969908298003573e-05,
      "loss": 0.0963,
      "step": 960
    },
    {
      "epoch": 1.6714747039827773,
      "grad_norm": 0.9997619390487671,
      "learning_rate": 4.869616618650201e-05,
      "loss": 0.0898,
      "step": 970
    },
    {
      "epoch": 1.688697524219591,
      "grad_norm": 1.4179500341415405,
      "learning_rate": 4.769377410848161e-05,
      "loss": 0.0757,
      "step": 980
    },
    {
      "epoch": 1.7059203444564046,
      "grad_norm": 1.7079503536224365,
      "learning_rate": 4.669231014912943e-05,
      "loss": 0.1164,
      "step": 990
    },
    {
      "epoch": 1.7231431646932185,
      "grad_norm": 0.4329027831554413,
      "learning_rate": 4.569217733808774e-05,
      "loss": 0.0799,
      "step": 1000
    },
    {
      "epoch": 1.7403659849300324,
      "grad_norm": 0.5803459286689758,
      "learning_rate": 4.469377816929093e-05,
      "loss": 0.0792,
      "step": 1010
    },
    {
      "epoch": 1.7575888051668462,
      "grad_norm": 0.7390697002410889,
      "learning_rate": 4.3697514438985536e-05,
      "loss": 0.0953,
      "step": 1020
    },
    {
      "epoch": 1.7748116254036599,
      "grad_norm": 0.5982705950737,
      "learning_rate": 4.270378708403118e-05,
      "loss": 0.0749,
      "step": 1030
    },
    {
      "epoch": 1.7920344456404735,
      "grad_norm": 1.3608454465866089,
      "learning_rate": 4.171299602054736e-05,
      "loss": 0.0989,
      "step": 1040
    },
    {
      "epoch": 1.8092572658772874,
      "grad_norm": 0.49044710397720337,
      "learning_rate": 4.072553998297103e-05,
      "loss": 0.0711,
      "step": 1050
    },
    {
      "epoch": 1.8264800861141013,
      "grad_norm": 1.7785851955413818,
      "learning_rate": 3.974181636358963e-05,
      "loss": 0.0716,
      "step": 1060
    },
    {
      "epoch": 1.843702906350915,
      "grad_norm": 0.9909327626228333,
      "learning_rate": 3.876222105261449e-05,
      "loss": 0.0571,
      "step": 1070
    },
    {
      "epoch": 1.8609257265877286,
      "grad_norm": 1.0604579448699951,
      "learning_rate": 3.778714827885845e-05,
      "loss": 0.067,
      "step": 1080
    },
    {
      "epoch": 1.8781485468245425,
      "grad_norm": 0.8090992569923401,
      "learning_rate": 3.6816990451082296e-05,
      "loss": 0.0708,
      "step": 1090
    },
    {
      "epoch": 1.8953713670613563,
      "grad_norm": 1.3673243522644043,
      "learning_rate": 3.585213800007356e-05,
      "loss": 0.0792,
      "step": 1100
    },
    {
      "epoch": 1.9125941872981702,
      "grad_norm": 0.4081895351409912,
      "learning_rate": 3.489297922152136e-05,
      "loss": 0.1088,
      "step": 1110
    },
    {
      "epoch": 1.9298170075349839,
      "grad_norm": 0.27107149362564087,
      "learning_rate": 3.393990011975054e-05,
      "loss": 0.0765,
      "step": 1120
    },
    {
      "epoch": 1.9470398277717975,
      "grad_norm": 1.1355892419815063,
      "learning_rate": 3.299328425237781e-05,
      "loss": 0.0869,
      "step": 1130
    },
    {
      "epoch": 1.9642626480086114,
      "grad_norm": 0.9018487334251404,
      "learning_rate": 3.205351257595272e-05,
      "loss": 0.0851,
      "step": 1140
    },
    {
      "epoch": 1.9814854682454253,
      "grad_norm": 0.7111352682113647,
      "learning_rate": 3.11209632926453e-05,
      "loss": 0.0788,
      "step": 1150
    },
    {
      "epoch": 1.998708288482239,
      "grad_norm": 1.119964361190796,
      "learning_rate": 3.019601169804216e-05,
      "loss": 0.0957,
      "step": 1160
    },
    {
      "epoch": 1.998708288482239,
      "eval_loss": 0.5513536334037781,
      "eval_runtime": 82.5418,
      "eval_samples_per_second": 15.12,
      "eval_steps_per_second": 3.78,
      "step": 1160
    },
    {
      "epoch": 2.0167922497308934,
      "grad_norm": 0.9825413823127747,
      "learning_rate": 2.9279030030112408e-05,
      "loss": 0.0632,
      "step": 1170
    },
    {
      "epoch": 2.0340150699677073,
      "grad_norm": 0.4764893651008606,
      "learning_rate": 2.8370387319403968e-05,
      "loss": 0.059,
      "step": 1180
    },
    {
      "epoch": 2.051237890204521,
      "grad_norm": 0.4459002912044525,
      "learning_rate": 2.747044924053078e-05,
      "loss": 0.054,
      "step": 1190
    },
    {
      "epoch": 2.0684607104413346,
      "grad_norm": 1.0233815908432007,
      "learning_rate": 2.65795779650105e-05,
      "loss": 0.0843,
      "step": 1200
    },
    {
      "epoch": 2.0856835306781485,
      "grad_norm": 0.40078210830688477,
      "learning_rate": 2.569813201551205e-05,
      "loss": 0.084,
      "step": 1210
    },
    {
      "epoch": 2.1029063509149624,
      "grad_norm": 0.66447514295578,
      "learning_rate": 2.4826466121571573e-05,
      "loss": 0.0657,
      "step": 1220
    },
    {
      "epoch": 2.1201291711517762,
      "grad_norm": 0.9067434072494507,
      "learning_rate": 2.396493107683488e-05,
      "loss": 0.0526,
      "step": 1230
    },
    {
      "epoch": 2.1373519913885897,
      "grad_norm": 1.8747307062149048,
      "learning_rate": 2.311387359788395e-05,
      "loss": 0.0702,
      "step": 1240
    },
    {
      "epoch": 2.1545748116254035,
      "grad_norm": 0.6279066801071167,
      "learning_rate": 2.227363618470407e-05,
      "loss": 0.047,
      "step": 1250
    },
    {
      "epoch": 2.1717976318622174,
      "grad_norm": 0.850895881652832,
      "learning_rate": 2.1444556982847997e-05,
      "loss": 0.0681,
      "step": 1260
    },
    {
      "epoch": 2.1890204520990313,
      "grad_norm": 1.3878840208053589,
      "learning_rate": 2.0626969647352502e-05,
      "loss": 0.0694,
      "step": 1270
    },
    {
      "epoch": 2.206243272335845,
      "grad_norm": 0.47758060693740845,
      "learning_rate": 1.982120320846208e-05,
      "loss": 0.0666,
      "step": 1280
    },
    {
      "epoch": 2.2234660925726586,
      "grad_norm": 0.6154364347457886,
      "learning_rate": 1.902758193921385e-05,
      "loss": 0.0529,
      "step": 1290
    },
    {
      "epoch": 2.2406889128094725,
      "grad_norm": 1.1567400693893433,
      "learning_rate": 1.8246425224936986e-05,
      "loss": 0.0534,
      "step": 1300
    },
    {
      "epoch": 2.2579117330462863,
      "grad_norm": 1.3573120832443237,
      "learning_rate": 1.747804743471907e-05,
      "loss": 0.0797,
      "step": 1310
    },
    {
      "epoch": 2.2751345532831,
      "grad_norm": 0.7813444137573242,
      "learning_rate": 1.6722757794891287e-05,
      "loss": 0.0796,
      "step": 1320
    },
    {
      "epoch": 2.2923573735199136,
      "grad_norm": 0.5829766988754272,
      "learning_rate": 1.5980860264583218e-05,
      "loss": 0.0443,
      "step": 1330
    },
    {
      "epoch": 2.3095801937567275,
      "grad_norm": 0.4080514907836914,
      "learning_rate": 1.52526534133974e-05,
      "loss": 0.0388,
      "step": 1340
    },
    {
      "epoch": 2.3268030139935414,
      "grad_norm": 0.8241872191429138,
      "learning_rate": 1.4538430301252782e-05,
      "loss": 0.0576,
      "step": 1350
    },
    {
      "epoch": 2.3440258342303553,
      "grad_norm": 1.79474937915802,
      "learning_rate": 1.3838478360445617e-05,
      "loss": 0.0626,
      "step": 1360
    },
    {
      "epoch": 2.361248654467169,
      "grad_norm": 1.1784062385559082,
      "learning_rate": 1.3153079279975011e-05,
      "loss": 0.0649,
      "step": 1370
    },
    {
      "epoch": 2.378471474703983,
      "grad_norm": 1.2833070755004883,
      "learning_rate": 1.2482508892179884e-05,
      "loss": 0.0785,
      "step": 1380
    },
    {
      "epoch": 2.3956942949407964,
      "grad_norm": 1.5617926120758057,
      "learning_rate": 1.1827037061732876e-05,
      "loss": 0.0503,
      "step": 1390
    },
    {
      "epoch": 2.4129171151776103,
      "grad_norm": 1.4345289468765259,
      "learning_rate": 1.1186927577035866e-05,
      "loss": 0.0676,
      "step": 1400
    },
    {
      "epoch": 2.430139935414424,
      "grad_norm": 1.0705958604812622,
      "learning_rate": 1.0562438044060846e-05,
      "loss": 0.0697,
      "step": 1410
    },
    {
      "epoch": 2.447362755651238,
      "grad_norm": 1.3081309795379639,
      "learning_rate": 9.953819782678885e-06,
      "loss": 0.0592,
      "step": 1420
    },
    {
      "epoch": 2.4645855758880515,
      "grad_norm": 1.1834979057312012,
      "learning_rate": 9.361317725518749e-06,
      "loss": 0.0584,
      "step": 1430
    },
    {
      "epoch": 2.4818083961248654,
      "grad_norm": 1.0450471639633179,
      "learning_rate": 8.785170319396175e-06,
      "loss": 0.0306,
      "step": 1440
    },
    {
      "epoch": 2.4990312163616792,
      "grad_norm": 0.5914119482040405,
      "learning_rate": 8.225609429353187e-06,
      "loss": 0.0468,
      "step": 1450
    },
    {
      "epoch": 2.516254036598493,
      "grad_norm": 1.1055039167404175,
      "learning_rate": 7.682860245346213e-06,
      "loss": 0.0601,
      "step": 1460
    },
    {
      "epoch": 2.533476856835307,
      "grad_norm": 0.7869665026664734,
      "learning_rate": 7.157141191620548e-06,
      "loss": 0.0577,
      "step": 1470
    },
    {
      "epoch": 2.5506996770721204,
      "grad_norm": 0.7288186550140381,
      "learning_rate": 6.648663838807562e-06,
      "loss": 0.0661,
      "step": 1480
    },
    {
      "epoch": 2.5679224973089343,
      "grad_norm": 0.5053942799568176,
      "learning_rate": 6.157632818780179e-06,
      "loss": 0.0571,
      "step": 1490
    },
    {
      "epoch": 2.585145317545748,
      "grad_norm": 0.5885733962059021,
      "learning_rate": 5.684245742300625e-06,
      "loss": 0.0696,
      "step": 1500
    },
    {
      "epoch": 2.602368137782562,
      "grad_norm": 1.1370635032653809,
      "learning_rate": 5.228693119493955e-06,
      "loss": 0.0557,
      "step": 1510
    },
    {
      "epoch": 2.6195909580193755,
      "grad_norm": 1.0685396194458008,
      "learning_rate": 4.791158283178998e-06,
      "loss": 0.0673,
      "step": 1520
    },
    {
      "epoch": 2.6368137782561893,
      "grad_norm": 0.48691990971565247,
      "learning_rate": 4.371817315087845e-06,
      "loss": 0.0636,
      "step": 1530
    },
    {
      "epoch": 2.654036598493003,
      "grad_norm": 0.9323813915252686,
      "learning_rate": 3.97083897500341e-06,
      "loss": 0.0701,
      "step": 1540
    },
    {
      "epoch": 2.671259418729817,
      "grad_norm": 0.39294925332069397,
      "learning_rate": 3.5883846328436943e-06,
      "loss": 0.0392,
      "step": 1550
    },
    {
      "epoch": 2.688482238966631,
      "grad_norm": 0.7982839345932007,
      "learning_rate": 3.2246082037199532e-06,
      "loss": 0.0378,
      "step": 1560
    },
    {
      "epoch": 2.705705059203445,
      "grad_norm": 0.577399492263794,
      "learning_rate": 2.8796560859950418e-06,
      "loss": 0.0379,
      "step": 1570
    },
    {
      "epoch": 2.7229278794402583,
      "grad_norm": 1.9857347011566162,
      "learning_rate": 2.55366710236683e-06,
      "loss": 0.0747,
      "step": 1580
    },
    {
      "epoch": 2.740150699677072,
      "grad_norm": 0.574607789516449,
      "learning_rate": 2.2467724440002336e-06,
      "loss": 0.055,
      "step": 1590
    },
    {
      "epoch": 2.757373519913886,
      "grad_norm": 0.5343732833862305,
      "learning_rate": 1.9590956177306664e-06,
      "loss": 0.055,
      "step": 1600
    },
    {
      "epoch": 2.7745963401506994,
      "grad_norm": 0.7847536206245422,
      "learning_rate": 1.690752396359857e-06,
      "loss": 0.0787,
      "step": 1610
    },
    {
      "epoch": 2.7918191603875133,
      "grad_norm": 0.6837530732154846,
      "learning_rate": 1.4418507720641793e-06,
      "loss": 0.0358,
      "step": 1620
    },
    {
      "epoch": 2.809041980624327,
      "grad_norm": 0.8640629649162292,
      "learning_rate": 1.2124909129342332e-06,
      "loss": 0.0495,
      "step": 1630
    },
    {
      "epoch": 2.826264800861141,
      "grad_norm": 0.45086872577667236,
      "learning_rate": 1.0027651226631462e-06,
      "loss": 0.0508,
      "step": 1640
    },
    {
      "epoch": 2.843487621097955,
      "grad_norm": 1.1328530311584473,
      "learning_rate": 8.127578033998662e-07,
      "loss": 0.0444,
      "step": 1650
    },
    {
      "epoch": 2.860710441334769,
      "grad_norm": 0.7335025668144226,
      "learning_rate": 6.425454217822425e-07,
      "loss": 0.0629,
      "step": 1660
    },
    {
      "epoch": 2.8779332615715822,
      "grad_norm": 0.9031110405921936,
      "learning_rate": 4.921964781638367e-07,
      "loss": 0.0822,
      "step": 1670
    },
    {
      "epoch": 2.895156081808396,
      "grad_norm": 0.5886269807815552,
      "learning_rate": 3.617714790465576e-07,
      "loss": 0.0657,
      "step": 1680
    },
    {
      "epoch": 2.91237890204521,
      "grad_norm": 0.9966976642608643,
      "learning_rate": 2.5132291273042285e-07,
      "loss": 0.0559,
      "step": 1690
    },
    {
      "epoch": 2.9296017222820234,
      "grad_norm": 0.8938211798667908,
      "learning_rate": 1.608952281901055e-07,
      "loss": 0.0363,
      "step": 1700
    },
    {
      "epoch": 2.9468245425188373,
      "grad_norm": 0.6113154292106628,
      "learning_rate": 9.052481718690997e-08,
      "loss": 0.0439,
      "step": 1710
    },
    {
      "epoch": 2.964047362755651,
      "grad_norm": 1.0222793817520142,
      "learning_rate": 4.023999962322611e-08,
      "loss": 0.0481,
      "step": 1720
    },
    {
      "epoch": 2.981270182992465,
      "grad_norm": 0.6014469265937805,
      "learning_rate": 1.006101214545696e-08,
      "loss": 0.0679,
      "step": 1730
    },
    {
      "epoch": 2.998493003229279,
      "grad_norm": 1.0557971000671387,
      "learning_rate": 0.0,
      "loss": 0.076,
      "step": 1740
    },
    {
      "epoch": 2.998493003229279,
      "eval_loss": 0.7793025374412537,
      "eval_runtime": 81.4865,
      "eval_samples_per_second": 15.315,
      "eval_steps_per_second": 3.829,
      "step": 1740
    },
    {
      "epoch": 2.998493003229279,
      "step": 1740,
      "total_flos": 1.0050223383888527e+18,
      "train_loss": 0.27300205986047615,
      "train_runtime": 9937.8176,
      "train_samples_per_second": 5.608,
      "train_steps_per_second": 0.175
    }
  ],
  "logging_steps": 10,
  "max_steps": 1740,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0050223383888527e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
