{
  "best_metric": 0.16303065419197083,
  "best_model_checkpoint": "saves/assembly_code/llm4decompile-9b-v2/lora_sft/checkpoint-795",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 795,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03773584905660377,
      "grad_norm": 8.611390113830566,
      "learning_rate": 6.25e-05,
      "loss": 4.0182,
      "step": 10
    },
    {
      "epoch": 0.07547169811320754,
      "grad_norm": 3.4713587760925293,
      "learning_rate": 0.000125,
      "loss": 1.2248,
      "step": 20
    },
    {
      "epoch": 0.11320754716981132,
      "grad_norm": 1.0179787874221802,
      "learning_rate": 0.0001875,
      "loss": 0.4225,
      "step": 30
    },
    {
      "epoch": 0.1509433962264151,
      "grad_norm": 0.5373347401618958,
      "learning_rate": 0.00025,
      "loss": 0.2579,
      "step": 40
    },
    {
      "epoch": 0.18867924528301888,
      "grad_norm": 0.3164556920528412,
      "learning_rate": 0.0003125,
      "loss": 0.2357,
      "step": 50
    },
    {
      "epoch": 0.22641509433962265,
      "grad_norm": 0.22867536544799805,
      "learning_rate": 0.000375,
      "loss": 0.2327,
      "step": 60
    },
    {
      "epoch": 0.2641509433962264,
      "grad_norm": 0.7273489832878113,
      "learning_rate": 0.0004375,
      "loss": 0.2369,
      "step": 70
    },
    {
      "epoch": 0.3018867924528302,
      "grad_norm": 0.21818986535072327,
      "learning_rate": 0.0005,
      "loss": 0.2386,
      "step": 80
    },
    {
      "epoch": 0.33962264150943394,
      "grad_norm": 0.6713471412658691,
      "learning_rate": 0.0004997587164001815,
      "loss": 0.2329,
      "step": 90
    },
    {
      "epoch": 0.37735849056603776,
      "grad_norm": 0.342608243227005,
      "learning_rate": 0.0004990353313429303,
      "loss": 0.2356,
      "step": 100
    },
    {
      "epoch": 0.41509433962264153,
      "grad_norm": 0.25318634510040283,
      "learning_rate": 0.0004978312411558518,
      "loss": 0.2295,
      "step": 110
    },
    {
      "epoch": 0.4528301886792453,
      "grad_norm": 0.1828719675540924,
      "learning_rate": 0.0004961487700566646,
      "loss": 0.2356,
      "step": 120
    },
    {
      "epoch": 0.49056603773584906,
      "grad_norm": 0.4463828504085541,
      "learning_rate": 0.0004939911656668361,
      "loss": 0.2385,
      "step": 130
    },
    {
      "epoch": 0.5283018867924528,
      "grad_norm": 0.2924215793609619,
      "learning_rate": 0.0004913625927427996,
      "loss": 0.2348,
      "step": 140
    },
    {
      "epoch": 0.5660377358490566,
      "grad_norm": 0.4345061182975769,
      "learning_rate": 0.00048826812513685485,
      "loss": 0.2333,
      "step": 150
    },
    {
      "epoch": 0.6037735849056604,
      "grad_norm": 0.20240898430347443,
      "learning_rate": 0.00048471373600326995,
      "loss": 0.2268,
      "step": 160
    },
    {
      "epoch": 0.6415094339622641,
      "grad_norm": 0.5920073390007019,
      "learning_rate": 0.00048070628626848734,
      "loss": 0.2451,
      "step": 170
    },
    {
      "epoch": 0.6792452830188679,
      "grad_norm": 0.6296085715293884,
      "learning_rate": 0.0004762535113876917,
      "loss": 0.2358,
      "step": 180
    },
    {
      "epoch": 0.7169811320754716,
      "grad_norm": 0.29191410541534424,
      "learning_rate": 0.00047136400641330245,
      "loss": 0.2238,
      "step": 190
    },
    {
      "epoch": 0.7547169811320755,
      "grad_norm": 0.1729128360748291,
      "learning_rate": 0.0004660472094042121,
      "loss": 0.2305,
      "step": 200
    },
    {
      "epoch": 0.7924528301886793,
      "grad_norm": 0.31802254915237427,
      "learning_rate": 0.0004603133832077953,
      "loss": 0.2184,
      "step": 210
    },
    {
      "epoch": 0.8301886792452831,
      "grad_norm": 0.8612074255943298,
      "learning_rate": 0.00045417359564985544,
      "loss": 0.2254,
      "step": 220
    },
    {
      "epoch": 0.8679245283018868,
      "grad_norm": 0.11502809822559357,
      "learning_rate": 0.00044763969817074534,
      "loss": 0.2226,
      "step": 230
    },
    {
      "epoch": 0.9056603773584906,
      "grad_norm": 0.16950367391109467,
      "learning_rate": 0.00044072430294890173,
      "loss": 0.2133,
      "step": 240
    },
    {
      "epoch": 0.9433962264150944,
      "grad_norm": 0.26694750785827637,
      "learning_rate": 0.000433440758555951,
      "loss": 0.2214,
      "step": 250
    },
    {
      "epoch": 0.9811320754716981,
      "grad_norm": 0.3466608226299286,
      "learning_rate": 0.00042580312419037775,
      "loss": 0.22,
      "step": 260
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.21909530460834503,
      "eval_runtime": 199.7166,
      "eval_samples_per_second": 6.249,
      "eval_steps_per_second": 0.781,
      "step": 265
    },
    {
      "epoch": 1.0188679245283019,
      "grad_norm": 0.20868641138076782,
      "learning_rate": 0.00041782614253949257,
      "loss": 0.2203,
      "step": 270
    },
    {
      "epoch": 1.0566037735849056,
      "grad_norm": 0.2672467827796936,
      "learning_rate": 0.0004095252113220827,
      "loss": 0.2197,
      "step": 280
    },
    {
      "epoch": 1.0943396226415094,
      "grad_norm": 0.21431468427181244,
      "learning_rate": 0.00040091635356667607,
      "loss": 0.2141,
      "step": 290
    },
    {
      "epoch": 1.1320754716981132,
      "grad_norm": 0.2534657418727875,
      "learning_rate": 0.00039201618668278893,
      "loss": 0.2115,
      "step": 300
    },
    {
      "epoch": 1.169811320754717,
      "grad_norm": 0.30568602681159973,
      "learning_rate": 0.00038284189038485935,
      "loss": 0.2109,
      "step": 310
    },
    {
      "epoch": 1.2075471698113207,
      "grad_norm": 0.4698500633239746,
      "learning_rate": 0.0003734111735307796,
      "loss": 0.2045,
      "step": 320
    },
    {
      "epoch": 1.2452830188679245,
      "grad_norm": 0.2930675745010376,
      "learning_rate": 0.00036374223993904125,
      "loss": 0.2135,
      "step": 330
    },
    {
      "epoch": 1.2830188679245282,
      "grad_norm": 0.2837217450141907,
      "learning_rate": 0.00035385375325047166,
      "loss": 0.208,
      "step": 340
    },
    {
      "epoch": 1.320754716981132,
      "grad_norm": 0.3286384046077728,
      "learning_rate": 0.0003437648009023905,
      "loss": 0.204,
      "step": 350
    },
    {
      "epoch": 1.3584905660377358,
      "grad_norm": 0.9671328067779541,
      "learning_rate": 0.00033349485728472535,
      "loss": 0.2086,
      "step": 360
    },
    {
      "epoch": 1.3962264150943398,
      "grad_norm": 0.6401684284210205,
      "learning_rate": 0.00032306374614920433,
      "loss": 0.2256,
      "step": 370
    },
    {
      "epoch": 1.4339622641509435,
      "grad_norm": 0.49662038683891296,
      "learning_rate": 0.00031249160234418644,
      "loss": 0.2067,
      "step": 380
    },
    {
      "epoch": 1.4716981132075473,
      "grad_norm": 0.24881502985954285,
      "learning_rate": 0.0003017988329489923,
      "loss": 0.2138,
      "step": 390
    },
    {
      "epoch": 1.509433962264151,
      "grad_norm": 0.796840488910675,
      "learning_rate": 0.0002910060778827555,
      "loss": 0.206,
      "step": 400
    },
    {
      "epoch": 1.5471698113207548,
      "grad_norm": 0.48334193229675293,
      "learning_rate": 0.0002801341700638307,
      "loss": 0.2034,
      "step": 410
    },
    {
      "epoch": 1.5849056603773586,
      "grad_norm": 0.40595337748527527,
      "learning_rate": 0.00026920409519666174,
      "loss": 0.2016,
      "step": 420
    },
    {
      "epoch": 1.6226415094339623,
      "grad_norm": 0.31023117899894714,
      "learning_rate": 0.0002582369512637302,
      "loss": 0.2018,
      "step": 430
    },
    {
      "epoch": 1.6603773584905661,
      "grad_norm": 0.36797377467155457,
      "learning_rate": 0.00024725390780077906,
      "loss": 0.1965,
      "step": 440
    },
    {
      "epoch": 1.6981132075471699,
      "grad_norm": 0.3202151656150818,
      "learning_rate": 0.00023627616503391814,
      "loss": 0.1959,
      "step": 450
    },
    {
      "epoch": 1.7358490566037736,
      "grad_norm": 0.4120219349861145,
      "learning_rate": 0.00022532491295748866,
      "loss": 0.1946,
      "step": 460
    },
    {
      "epoch": 1.7735849056603774,
      "grad_norm": 0.4207250773906708,
      "learning_rate": 0.00021442129043167875,
      "loss": 0.2012,
      "step": 470
    },
    {
      "epoch": 1.8113207547169812,
      "grad_norm": 0.3765842616558075,
      "learning_rate": 0.00020358634437884113,
      "loss": 0.1908,
      "step": 480
    },
    {
      "epoch": 1.849056603773585,
      "grad_norm": 0.41069936752319336,
      "learning_rate": 0.00019284098915727568,
      "loss": 0.1907,
      "step": 490
    },
    {
      "epoch": 1.8867924528301887,
      "grad_norm": 0.43931251764297485,
      "learning_rate": 0.00018220596619089574,
      "loss": 0.1876,
      "step": 500
    },
    {
      "epoch": 1.9245283018867925,
      "grad_norm": 0.5150461792945862,
      "learning_rate": 0.0001717018039327053,
      "loss": 0.1834,
      "step": 510
    },
    {
      "epoch": 1.9622641509433962,
      "grad_norm": 0.5295689702033997,
      "learning_rate": 0.00016134877823936609,
      "loss": 0.1839,
      "step": 520
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7758300304412842,
      "learning_rate": 0.00015116687323334465,
      "loss": 0.1787,
      "step": 530
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.19494514167308807,
      "eval_runtime": 200.1961,
      "eval_samples_per_second": 6.234,
      "eval_steps_per_second": 0.779,
      "step": 530
    },
    {
      "epoch": 2.0377358490566038,
      "grad_norm": 0.4759504795074463,
      "learning_rate": 0.00014117574272818386,
      "loss": 0.1784,
      "step": 540
    },
    {
      "epoch": 2.0754716981132075,
      "grad_norm": 0.6586548089981079,
      "learning_rate": 0.00013139467229136,
      "loss": 0.1723,
      "step": 550
    },
    {
      "epoch": 2.1132075471698113,
      "grad_norm": 0.6210841536521912,
      "learning_rate": 0.00012184254201795364,
      "loss": 0.1767,
      "step": 560
    },
    {
      "epoch": 2.150943396226415,
      "grad_norm": 0.5753617286682129,
      "learning_rate": 0.0001125377900869913,
      "loss": 0.1704,
      "step": 570
    },
    {
      "epoch": 2.188679245283019,
      "grad_norm": 0.6062438488006592,
      "learning_rate": 0.00010349837717080349,
      "loss": 0.1612,
      "step": 580
    },
    {
      "epoch": 2.2264150943396226,
      "grad_norm": 0.7438967823982239,
      "learning_rate": 9.474175176609956e-05,
      "loss": 0.1657,
      "step": 590
    },
    {
      "epoch": 2.2641509433962264,
      "grad_norm": 0.6027647256851196,
      "learning_rate": 8.628481651367875e-05,
      "loss": 0.1672,
      "step": 600
    },
    {
      "epoch": 2.30188679245283,
      "grad_norm": 0.6087478399276733,
      "learning_rate": 7.814389557179016e-05,
      "loss": 0.1677,
      "step": 610
    },
    {
      "epoch": 2.339622641509434,
      "grad_norm": 0.5663083791732788,
      "learning_rate": 7.033470310611945e-05,
      "loss": 0.155,
      "step": 620
    },
    {
      "epoch": 2.3773584905660377,
      "grad_norm": 0.5421674847602844,
      "learning_rate": 6.28723129572247e-05,
      "loss": 0.1555,
      "step": 630
    },
    {
      "epoch": 2.4150943396226414,
      "grad_norm": 0.5850822925567627,
      "learning_rate": 5.57711295439732e-05,
      "loss": 0.1577,
      "step": 640
    },
    {
      "epoch": 2.452830188679245,
      "grad_norm": 0.6544470191001892,
      "learning_rate": 4.904486005914027e-05,
      "loss": 0.1592,
      "step": 650
    },
    {
      "epoch": 2.490566037735849,
      "grad_norm": 0.673043429851532,
      "learning_rate": 4.270648801084295e-05,
      "loss": 0.1525,
      "step": 660
    },
    {
      "epoch": 2.5283018867924527,
      "grad_norm": 0.6585044860839844,
      "learning_rate": 3.676824816087978e-05,
      "loss": 0.1495,
      "step": 670
    },
    {
      "epoch": 2.5660377358490565,
      "grad_norm": 0.7303404211997986,
      "learning_rate": 3.1241602908351405e-05,
      "loss": 0.1443,
      "step": 680
    },
    {
      "epoch": 2.6037735849056602,
      "grad_norm": 0.7315026521682739,
      "learning_rate": 2.6137220164149435e-05,
      "loss": 0.1371,
      "step": 690
    },
    {
      "epoch": 2.641509433962264,
      "grad_norm": 0.7568783164024353,
      "learning_rate": 2.1464952759020855e-05,
      "loss": 0.1325,
      "step": 700
    },
    {
      "epoch": 2.6792452830188678,
      "grad_norm": 0.9027807712554932,
      "learning_rate": 1.723381942495625e-05,
      "loss": 0.1314,
      "step": 710
    },
    {
      "epoch": 2.7169811320754715,
      "grad_norm": 1.052422285079956,
      "learning_rate": 1.3451987386612851e-05,
      "loss": 0.1517,
      "step": 720
    },
    {
      "epoch": 2.7547169811320753,
      "grad_norm": 0.8745824694633484,
      "learning_rate": 1.0126756596375685e-05,
      "loss": 0.1278,
      "step": 730
    },
    {
      "epoch": 2.7924528301886795,
      "grad_norm": 0.858771800994873,
      "learning_rate": 7.2645456434869975e-06,
      "loss": 0.1394,
      "step": 740
    },
    {
      "epoch": 2.830188679245283,
      "grad_norm": 1.0103858709335327,
      "learning_rate": 4.870879364444108e-06,
      "loss": 0.1358,
      "step": 750
    },
    {
      "epoch": 2.867924528301887,
      "grad_norm": 0.6137248277664185,
      "learning_rate": 2.9503781785795713e-06,
      "loss": 0.1467,
      "step": 760
    },
    {
      "epoch": 2.9056603773584904,
      "grad_norm": 0.7556130290031433,
      "learning_rate": 1.5067491694100155e-06,
      "loss": 0.1253,
      "step": 770
    },
    {
      "epoch": 2.9433962264150946,
      "grad_norm": 0.9042823910713196,
      "learning_rate": 5.427789289685348e-07,
      "loss": 0.1302,
      "step": 780
    },
    {
      "epoch": 2.981132075471698,
      "grad_norm": 1.221601963043213,
      "learning_rate": 6.032817893297793e-08,
      "loss": 0.1319,
      "step": 790
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.16303065419197083,
      "eval_runtime": 201.7162,
      "eval_samples_per_second": 6.187,
      "eval_steps_per_second": 0.773,
      "step": 795
    },
    {
      "epoch": 3.0,
      "step": 795,
      "total_flos": 5.641587223598989e+18,
      "train_loss": 0.257409857129151,
      "train_runtime": 20954.926,
      "train_samples_per_second": 2.428,
      "train_steps_per_second": 0.038
    }
  ],
  "logging_steps": 10,
  "max_steps": 795,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.641587223598989e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
