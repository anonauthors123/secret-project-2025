{
  "best_metric": 0.3128383755683899,
  "best_model_checkpoint": "saves/assembly_code/magicoder/lora_sft/checkpoint-1059",
  "epoch": 2.9968164131588257,
  "eval_steps": 500,
  "global_step": 1059,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02829854969932791,
      "grad_norm": 4.533228397369385,
      "learning_rate": 9.433962264150944e-06,
      "loss": 7.0711,
      "step": 10
    },
    {
      "epoch": 0.05659709939865582,
      "grad_norm": 6.148685455322266,
      "learning_rate": 1.8867924528301888e-05,
      "loss": 6.8888,
      "step": 20
    },
    {
      "epoch": 0.08489564909798372,
      "grad_norm": 6.352601051330566,
      "learning_rate": 2.830188679245283e-05,
      "loss": 5.5894,
      "step": 30
    },
    {
      "epoch": 0.11319419879731164,
      "grad_norm": 1.6137176752090454,
      "learning_rate": 3.7735849056603776e-05,
      "loss": 2.5733,
      "step": 40
    },
    {
      "epoch": 0.14149274849663954,
      "grad_norm": 2.8973517417907715,
      "learning_rate": 4.716981132075472e-05,
      "loss": 2.2462,
      "step": 50
    },
    {
      "epoch": 0.16979129819596744,
      "grad_norm": 2.3554129600524902,
      "learning_rate": 5.660377358490566e-05,
      "loss": 2.1742,
      "step": 60
    },
    {
      "epoch": 0.19808984789529538,
      "grad_norm": 0.7620772123336792,
      "learning_rate": 6.60377358490566e-05,
      "loss": 0.9734,
      "step": 70
    },
    {
      "epoch": 0.2263883975946233,
      "grad_norm": 1.0484540462493896,
      "learning_rate": 7.547169811320755e-05,
      "loss": 0.4193,
      "step": 80
    },
    {
      "epoch": 0.2546869472939512,
      "grad_norm": 0.6272915601730347,
      "learning_rate": 8.49056603773585e-05,
      "loss": 0.3615,
      "step": 90
    },
    {
      "epoch": 0.2829854969932791,
      "grad_norm": 1.3516514301300049,
      "learning_rate": 9.433962264150944e-05,
      "loss": 0.3682,
      "step": 100
    },
    {
      "epoch": 0.311284046692607,
      "grad_norm": 1.6831437349319458,
      "learning_rate": 9.999565322017444e-05,
      "loss": 0.3519,
      "step": 110
    },
    {
      "epoch": 0.3395825963919349,
      "grad_norm": 1.154647946357727,
      "learning_rate": 9.994676062638023e-05,
      "loss": 0.3491,
      "step": 120
    },
    {
      "epoch": 0.3678811460912628,
      "grad_norm": 0.5608490705490112,
      "learning_rate": 9.984359526844107e-05,
      "loss": 0.3576,
      "step": 130
    },
    {
      "epoch": 0.39617969579059076,
      "grad_norm": 0.7702653408050537,
      "learning_rate": 9.968626924710318e-05,
      "loss": 0.3639,
      "step": 140
    },
    {
      "epoch": 0.42447824548991864,
      "grad_norm": 0.6150177717208862,
      "learning_rate": 9.947495351475553e-05,
      "loss": 0.3567,
      "step": 150
    },
    {
      "epoch": 0.4527767951892466,
      "grad_norm": 0.26461315155029297,
      "learning_rate": 9.920987768967081e-05,
      "loss": 0.353,
      "step": 160
    },
    {
      "epoch": 0.48107534488857445,
      "grad_norm": 0.2676719129085541,
      "learning_rate": 9.889132980649944e-05,
      "loss": 0.3464,
      "step": 170
    },
    {
      "epoch": 0.5093738945879024,
      "grad_norm": 0.2211022675037384,
      "learning_rate": 9.85196560032875e-05,
      "loss": 0.3417,
      "step": 180
    },
    {
      "epoch": 0.5376724442872303,
      "grad_norm": 0.38061121106147766,
      "learning_rate": 9.809526014535895e-05,
      "loss": 0.3442,
      "step": 190
    },
    {
      "epoch": 0.5659709939865581,
      "grad_norm": 0.15519870817661285,
      "learning_rate": 9.761860338647055e-05,
      "loss": 0.3352,
      "step": 200
    },
    {
      "epoch": 0.5942695436858861,
      "grad_norm": 0.562002956867218,
      "learning_rate": 9.709020366771656e-05,
      "loss": 0.3432,
      "step": 210
    },
    {
      "epoch": 0.622568093385214,
      "grad_norm": 0.13668133318424225,
      "learning_rate": 9.651063515472754e-05,
      "loss": 0.3387,
      "step": 220
    },
    {
      "epoch": 0.6508666430845419,
      "grad_norm": 0.1572127789258957,
      "learning_rate": 9.588052761377497e-05,
      "loss": 0.342,
      "step": 230
    },
    {
      "epoch": 0.6791651927838698,
      "grad_norm": 0.23486948013305664,
      "learning_rate": 9.520056572745944e-05,
      "loss": 0.3396,
      "step": 240
    },
    {
      "epoch": 0.7074637424831978,
      "grad_norm": 0.3228279948234558,
      "learning_rate": 9.447148835072608e-05,
      "loss": 0.338,
      "step": 250
    },
    {
      "epoch": 0.7357622921825256,
      "grad_norm": 0.37511909008026123,
      "learning_rate": 9.369408770801578e-05,
      "loss": 0.3488,
      "step": 260
    },
    {
      "epoch": 0.7640608418818535,
      "grad_norm": 0.28304508328437805,
      "learning_rate": 9.286920853242433e-05,
      "loss": 0.3425,
      "step": 270
    },
    {
      "epoch": 0.7923593915811815,
      "grad_norm": 0.1749778389930725,
      "learning_rate": 9.199774714780503e-05,
      "loss": 0.3448,
      "step": 280
    },
    {
      "epoch": 0.8206579412805094,
      "grad_norm": 0.3433438539505005,
      "learning_rate": 9.10806504948122e-05,
      "loss": 0.3355,
      "step": 290
    },
    {
      "epoch": 0.8489564909798373,
      "grad_norm": 0.18760962784290314,
      "learning_rate": 9.011891510194381e-05,
      "loss": 0.3383,
      "step": 300
    },
    {
      "epoch": 0.8772550406791652,
      "grad_norm": 0.23000088334083557,
      "learning_rate": 8.911358600270141e-05,
      "loss": 0.334,
      "step": 310
    },
    {
      "epoch": 0.9055535903784931,
      "grad_norm": 0.4302866756916046,
      "learning_rate": 8.80657556000438e-05,
      "loss": 0.3362,
      "step": 320
    },
    {
      "epoch": 0.933852140077821,
      "grad_norm": 0.534842848777771,
      "learning_rate": 8.697656247936859e-05,
      "loss": 0.3457,
      "step": 330
    },
    {
      "epoch": 0.9621506897771489,
      "grad_norm": 0.3239428400993347,
      "learning_rate": 8.58471901713113e-05,
      "loss": 0.338,
      "step": 340
    },
    {
      "epoch": 0.9904492394764768,
      "grad_norm": 0.1937096118927002,
      "learning_rate": 8.467886586570645e-05,
      "loss": 0.3382,
      "step": 350
    },
    {
      "epoch": 0.9989388043862752,
      "eval_loss": 0.3350544571876526,
      "eval_runtime": 183.6544,
      "eval_samples_per_second": 6.795,
      "eval_steps_per_second": 1.133,
      "step": 353
    },
    {
      "epoch": 1.0187477891758048,
      "grad_norm": 0.504111647605896,
      "learning_rate": 8.347285907810793e-05,
      "loss": 0.358,
      "step": 360
    },
    {
      "epoch": 1.0470463388751325,
      "grad_norm": 0.4630672335624695,
      "learning_rate": 8.22304802703179e-05,
      "loss": 0.3364,
      "step": 370
    },
    {
      "epoch": 1.0753448885744605,
      "grad_norm": 0.4509831368923187,
      "learning_rate": 8.095307942642276e-05,
      "loss": 0.3321,
      "step": 380
    },
    {
      "epoch": 1.1036434382737885,
      "grad_norm": 0.44930917024612427,
      "learning_rate": 7.964204458588393e-05,
      "loss": 0.3337,
      "step": 390
    },
    {
      "epoch": 1.1319419879731163,
      "grad_norm": 0.2333516627550125,
      "learning_rate": 7.829880033527708e-05,
      "loss": 0.3354,
      "step": 400
    },
    {
      "epoch": 1.1602405376724443,
      "grad_norm": 0.3334161937236786,
      "learning_rate": 7.692480626031881e-05,
      "loss": 0.3372,
      "step": 410
    },
    {
      "epoch": 1.1885390873717723,
      "grad_norm": 0.5243675112724304,
      "learning_rate": 7.5521555359863e-05,
      "loss": 0.3296,
      "step": 420
    },
    {
      "epoch": 1.2168376370711,
      "grad_norm": 0.4464392364025116,
      "learning_rate": 7.409057242358967e-05,
      "loss": 0.3313,
      "step": 430
    },
    {
      "epoch": 1.245136186770428,
      "grad_norm": 0.887469470500946,
      "learning_rate": 7.263341237514997e-05,
      "loss": 0.3176,
      "step": 440
    },
    {
      "epoch": 1.2734347364697558,
      "grad_norm": 0.3685031235218048,
      "learning_rate": 7.115165858256698e-05,
      "loss": 0.3289,
      "step": 450
    },
    {
      "epoch": 1.3017332861690838,
      "grad_norm": 0.7299399971961975,
      "learning_rate": 6.964692113772846e-05,
      "loss": 0.3228,
      "step": 460
    },
    {
      "epoch": 1.3300318358684118,
      "grad_norm": 0.6470285654067993,
      "learning_rate": 6.812083510684128e-05,
      "loss": 0.315,
      "step": 470
    },
    {
      "epoch": 1.3583303855677396,
      "grad_norm": 0.5682535171508789,
      "learning_rate": 6.657505875374844e-05,
      "loss": 0.3264,
      "step": 480
    },
    {
      "epoch": 1.3866289352670675,
      "grad_norm": 0.4340733289718628,
      "learning_rate": 6.501127173803904e-05,
      "loss": 0.3229,
      "step": 490
    },
    {
      "epoch": 1.4149274849663955,
      "grad_norm": 0.42482179403305054,
      "learning_rate": 6.343117328990967e-05,
      "loss": 0.3174,
      "step": 500
    },
    {
      "epoch": 1.4432260346657233,
      "grad_norm": 0.6494417786598206,
      "learning_rate": 6.183648036375985e-05,
      "loss": 0.3203,
      "step": 510
    },
    {
      "epoch": 1.4715245843650513,
      "grad_norm": 0.47737693786621094,
      "learning_rate": 6.022892577252838e-05,
      "loss": 0.3231,
      "step": 520
    },
    {
      "epoch": 1.4998231340643793,
      "grad_norm": 1.0736933946609497,
      "learning_rate": 5.86102563047975e-05,
      "loss": 0.3074,
      "step": 530
    },
    {
      "epoch": 1.528121683763707,
      "grad_norm": 0.4327903091907501,
      "learning_rate": 5.6982230826710824e-05,
      "loss": 0.3294,
      "step": 540
    },
    {
      "epoch": 1.556420233463035,
      "grad_norm": 0.3576001524925232,
      "learning_rate": 5.534661837076792e-05,
      "loss": 0.3262,
      "step": 550
    },
    {
      "epoch": 1.584718783162363,
      "grad_norm": 0.37917953729629517,
      "learning_rate": 5.3705196213571685e-05,
      "loss": 0.3245,
      "step": 560
    },
    {
      "epoch": 1.6130173328616908,
      "grad_norm": 0.37056204676628113,
      "learning_rate": 5.2059747944617886e-05,
      "loss": 0.3242,
      "step": 570
    },
    {
      "epoch": 1.6413158825610188,
      "grad_norm": 0.6472113728523254,
      "learning_rate": 5.041206152822482e-05,
      "loss": 0.3184,
      "step": 580
    },
    {
      "epoch": 1.6696144322603468,
      "grad_norm": 0.5159673094749451,
      "learning_rate": 4.876392736070927e-05,
      "loss": 0.3176,
      "step": 590
    },
    {
      "epoch": 1.6979129819596745,
      "grad_norm": 0.9065823554992676,
      "learning_rate": 4.711713632491993e-05,
      "loss": 0.3033,
      "step": 600
    },
    {
      "epoch": 1.7262115316590023,
      "grad_norm": 0.7345501184463501,
      "learning_rate": 4.547347784424201e-05,
      "loss": 0.3203,
      "step": 610
    },
    {
      "epoch": 1.7545100813583305,
      "grad_norm": 0.4066121578216553,
      "learning_rate": 4.3834737938187865e-05,
      "loss": 0.3304,
      "step": 620
    },
    {
      "epoch": 1.7828086310576583,
      "grad_norm": 0.3441218435764313,
      "learning_rate": 4.2202697281686174e-05,
      "loss": 0.3117,
      "step": 630
    },
    {
      "epoch": 1.811107180756986,
      "grad_norm": 0.8647557497024536,
      "learning_rate": 4.057912927017869e-05,
      "loss": 0.2887,
      "step": 640
    },
    {
      "epoch": 1.839405730456314,
      "grad_norm": 0.760176420211792,
      "learning_rate": 3.896579809262696e-05,
      "loss": 0.3034,
      "step": 650
    },
    {
      "epoch": 1.867704280155642,
      "grad_norm": 0.6316034197807312,
      "learning_rate": 3.7364456814522885e-05,
      "loss": 0.3067,
      "step": 660
    },
    {
      "epoch": 1.8960028298549698,
      "grad_norm": 0.48046019673347473,
      "learning_rate": 3.577684547298626e-05,
      "loss": 0.3105,
      "step": 670
    },
    {
      "epoch": 1.9243013795542978,
      "grad_norm": 0.47605404257774353,
      "learning_rate": 3.420468918601896e-05,
      "loss": 0.3008,
      "step": 680
    },
    {
      "epoch": 1.9525999292536258,
      "grad_norm": 0.6764220595359802,
      "learning_rate": 3.26496962779706e-05,
      "loss": 0.3021,
      "step": 690
    },
    {
      "epoch": 1.9808984789529536,
      "grad_norm": 0.5426486730575562,
      "learning_rate": 3.111355642325222e-05,
      "loss": 0.2941,
      "step": 700
    },
    {
      "epoch": 1.9978776087725505,
      "eval_loss": 0.341397225856781,
      "eval_runtime": 183.5764,
      "eval_samples_per_second": 6.798,
      "eval_steps_per_second": 1.133,
      "step": 706
    },
    {
      "epoch": 2.009197028652282,
      "grad_norm": 0.4358508884906769,
      "learning_rate": 2.959793881031536e-05,
      "loss": 0.3337,
      "step": 710
    },
    {
      "epoch": 2.0374955783516095,
      "grad_norm": 0.790834903717041,
      "learning_rate": 2.810449032789134e-05,
      "loss": 0.2853,
      "step": 720
    },
    {
      "epoch": 2.0657941280509373,
      "grad_norm": 0.8421580791473389,
      "learning_rate": 2.663483377546167e-05,
      "loss": 0.2955,
      "step": 730
    },
    {
      "epoch": 2.094092677750265,
      "grad_norm": 0.7293037176132202,
      "learning_rate": 2.51905660999043e-05,
      "loss": 0.286,
      "step": 740
    },
    {
      "epoch": 2.1223912274495933,
      "grad_norm": 0.48342564702033997,
      "learning_rate": 2.377325666023137e-05,
      "loss": 0.2978,
      "step": 750
    },
    {
      "epoch": 2.150689777148921,
      "grad_norm": 0.7991873621940613,
      "learning_rate": 2.2384445522304536e-05,
      "loss": 0.2966,
      "step": 760
    },
    {
      "epoch": 2.178988326848249,
      "grad_norm": 0.49373212456703186,
      "learning_rate": 2.1025641785380373e-05,
      "loss": 0.2962,
      "step": 770
    },
    {
      "epoch": 2.207286876547577,
      "grad_norm": 0.8645545244216919,
      "learning_rate": 1.969832194230466e-05,
      "loss": 0.2886,
      "step": 780
    },
    {
      "epoch": 2.235585426246905,
      "grad_norm": 0.6414018869400024,
      "learning_rate": 1.8403928275136994e-05,
      "loss": 0.2934,
      "step": 790
    },
    {
      "epoch": 2.2638839759462326,
      "grad_norm": 0.8062251806259155,
      "learning_rate": 1.7143867287949487e-05,
      "loss": 0.284,
      "step": 800
    },
    {
      "epoch": 2.292182525645561,
      "grad_norm": 0.8023505806922913,
      "learning_rate": 1.59195081785021e-05,
      "loss": 0.2755,
      "step": 810
    },
    {
      "epoch": 2.3204810753448886,
      "grad_norm": 0.7615747451782227,
      "learning_rate": 1.4732181350455471e-05,
      "loss": 0.2955,
      "step": 820
    },
    {
      "epoch": 2.3487796250442163,
      "grad_norm": 0.8423065543174744,
      "learning_rate": 1.3583176967738042e-05,
      "loss": 0.2763,
      "step": 830
    },
    {
      "epoch": 2.3770781747435445,
      "grad_norm": 0.664786159992218,
      "learning_rate": 1.2473743552637973e-05,
      "loss": 0.2742,
      "step": 840
    },
    {
      "epoch": 2.4053767244428723,
      "grad_norm": 1.0242340564727783,
      "learning_rate": 1.140508662914358e-05,
      "loss": 0.298,
      "step": 850
    },
    {
      "epoch": 2.4336752741422,
      "grad_norm": 0.7427040338516235,
      "learning_rate": 1.0378367413006052e-05,
      "loss": 0.2936,
      "step": 860
    },
    {
      "epoch": 2.4619738238415283,
      "grad_norm": 0.7667266726493835,
      "learning_rate": 9.394701549948165e-06,
      "loss": 0.2762,
      "step": 870
    },
    {
      "epoch": 2.490272373540856,
      "grad_norm": 0.8669785857200623,
      "learning_rate": 8.455157903389994e-06,
      "loss": 0.2755,
      "step": 880
    },
    {
      "epoch": 2.518570923240184,
      "grad_norm": 0.9169108867645264,
      "learning_rate": 7.5607573930086825e-06,
      "loss": 0.2829,
      "step": 890
    },
    {
      "epoch": 2.5468694729395116,
      "grad_norm": 0.9682640433311462,
      "learning_rate": 6.712471885394606e-06,
      "loss": 0.2681,
      "step": 900
    },
    {
      "epoch": 2.57516802263884,
      "grad_norm": 0.8227316737174988,
      "learning_rate": 5.911223138009225e-06,
      "loss": 0.2782,
      "step": 910
    },
    {
      "epoch": 2.6034665723381676,
      "grad_norm": 0.7944127917289734,
      "learning_rate": 5.157881797592057e-06,
      "loss": 0.281,
      "step": 920
    },
    {
      "epoch": 2.6317651220374954,
      "grad_norm": 0.8064286112785339,
      "learning_rate": 4.453266454105198e-06,
      "loss": 0.2764,
      "step": 930
    },
    {
      "epoch": 2.6600636717368236,
      "grad_norm": 0.8063161969184875,
      "learning_rate": 3.798142751243483e-06,
      "loss": 0.274,
      "step": 940
    },
    {
      "epoch": 2.6883622214361513,
      "grad_norm": 1.1080257892608643,
      "learning_rate": 3.1932225544765493e-06,
      "loss": 0.2708,
      "step": 950
    },
    {
      "epoch": 2.716660771135479,
      "grad_norm": 0.9498449563980103,
      "learning_rate": 2.639163177527154e-06,
      "loss": 0.284,
      "step": 960
    },
    {
      "epoch": 2.7449593208348073,
      "grad_norm": 0.9947909712791443,
      "learning_rate": 2.1365666681259e-06,
      "loss": 0.2687,
      "step": 970
    },
    {
      "epoch": 2.773257870534135,
      "grad_norm": 1.081179141998291,
      "learning_rate": 1.685979153818873e-06,
      "loss": 0.2747,
      "step": 980
    },
    {
      "epoch": 2.801556420233463,
      "grad_norm": 0.8918089866638184,
      "learning_rate": 1.2878902485386534e-06,
      "loss": 0.2718,
      "step": 990
    },
    {
      "epoch": 2.829854969932791,
      "grad_norm": 0.7407838106155396,
      "learning_rate": 9.427325205838555e-07,
      "loss": 0.2613,
      "step": 1000
    },
    {
      "epoch": 2.858153519632119,
      "grad_norm": 1.1965230703353882,
      "learning_rate": 6.508810225850703e-07,
      "loss": 0.2929,
      "step": 1010
    },
    {
      "epoch": 2.8864520693314466,
      "grad_norm": 1.0813089609146118,
      "learning_rate": 4.1265288396805104e-07,
      "loss": 0.2653,
      "step": 1020
    },
    {
      "epoch": 2.914750619030775,
      "grad_norm": 0.9540574550628662,
      "learning_rate": 2.2830696635701143e-07,
      "loss": 0.2777,
      "step": 1030
    },
    {
      "epoch": 2.9430491687301026,
      "grad_norm": 0.8780556917190552,
      "learning_rate": 9.804358229238974e-08,
      "loss": 0.2793,
      "step": 1040
    },
    {
      "epoch": 2.9713477184294304,
      "grad_norm": 1.0103505849838257,
      "learning_rate": 2.2004277568776766e-08,
      "loss": 0.2721,
      "step": 1050
    },
    {
      "epoch": 2.9968164131588257,
      "eval_loss": 0.3128383755683899,
      "eval_runtime": 183.5835,
      "eval_samples_per_second": 6.798,
      "eval_steps_per_second": 1.133,
      "step": 1059
    },
    {
      "epoch": 2.9968164131588257,
      "step": 1059,
      "total_flos": 5.126011604487373e+18,
      "train_loss": 0.5534258825357957,
      "train_runtime": 21199.7627,
      "train_samples_per_second": 2.4,
      "train_steps_per_second": 0.05
    }
  ],
  "logging_steps": 10,
  "max_steps": 1059,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.126011604487373e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
