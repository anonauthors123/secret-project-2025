{
  "best_metric": 0.3091636300086975,
  "best_model_checkpoint": "saves/assembly_code/llm4decompile/lora_sft/checkpoint-1059",
  "epoch": 2.9968164131588257,
  "eval_steps": 500,
  "global_step": 1059,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02829854969932791,
      "grad_norm": 2.992595672607422,
      "learning_rate": 9.433962264150944e-06,
      "loss": 4.5821,
      "step": 10
    },
    {
      "epoch": 0.05659709939865582,
      "grad_norm": 3.8496615886688232,
      "learning_rate": 1.8867924528301888e-05,
      "loss": 4.4765,
      "step": 20
    },
    {
      "epoch": 0.08489564909798372,
      "grad_norm": 4.330179214477539,
      "learning_rate": 2.830188679245283e-05,
      "loss": 3.8659,
      "step": 30
    },
    {
      "epoch": 0.11319419879731164,
      "grad_norm": 1.2308775186538696,
      "learning_rate": 3.7735849056603776e-05,
      "loss": 1.9767,
      "step": 40
    },
    {
      "epoch": 0.14149274849663954,
      "grad_norm": 2.7882306575775146,
      "learning_rate": 4.716981132075472e-05,
      "loss": 1.785,
      "step": 50
    },
    {
      "epoch": 0.16979129819596744,
      "grad_norm": 3.2958598136901855,
      "learning_rate": 5.660377358490566e-05,
      "loss": 1.3362,
      "step": 60
    },
    {
      "epoch": 0.19808984789529538,
      "grad_norm": 0.7737514972686768,
      "learning_rate": 6.60377358490566e-05,
      "loss": 0.462,
      "step": 70
    },
    {
      "epoch": 0.2263883975946233,
      "grad_norm": 0.43168699741363525,
      "learning_rate": 7.547169811320755e-05,
      "loss": 0.3564,
      "step": 80
    },
    {
      "epoch": 0.2546869472939512,
      "grad_norm": 0.8059406876564026,
      "learning_rate": 8.49056603773585e-05,
      "loss": 0.3653,
      "step": 90
    },
    {
      "epoch": 0.2829854969932791,
      "grad_norm": 1.1013915538787842,
      "learning_rate": 9.433962264150944e-05,
      "loss": 0.3661,
      "step": 100
    },
    {
      "epoch": 0.311284046692607,
      "grad_norm": 1.0507540702819824,
      "learning_rate": 9.999565322017444e-05,
      "loss": 0.353,
      "step": 110
    },
    {
      "epoch": 0.3395825963919349,
      "grad_norm": 1.046640396118164,
      "learning_rate": 9.994676062638023e-05,
      "loss": 0.3492,
      "step": 120
    },
    {
      "epoch": 0.3678811460912628,
      "grad_norm": 0.38435208797454834,
      "learning_rate": 9.984359526844107e-05,
      "loss": 0.3547,
      "step": 130
    },
    {
      "epoch": 0.39617969579059076,
      "grad_norm": 0.5920140743255615,
      "learning_rate": 9.968626924710318e-05,
      "loss": 0.3622,
      "step": 140
    },
    {
      "epoch": 0.42447824548991864,
      "grad_norm": 0.4827442467212677,
      "learning_rate": 9.947495351475553e-05,
      "loss": 0.354,
      "step": 150
    },
    {
      "epoch": 0.4527767951892466,
      "grad_norm": 0.2018948644399643,
      "learning_rate": 9.920987768967081e-05,
      "loss": 0.3481,
      "step": 160
    },
    {
      "epoch": 0.48107534488857445,
      "grad_norm": 0.282825231552124,
      "learning_rate": 9.889132980649944e-05,
      "loss": 0.3452,
      "step": 170
    },
    {
      "epoch": 0.5093738945879024,
      "grad_norm": 0.3276425004005432,
      "learning_rate": 9.85196560032875e-05,
      "loss": 0.3409,
      "step": 180
    },
    {
      "epoch": 0.5376724442872303,
      "grad_norm": 0.3479469418525696,
      "learning_rate": 9.809526014535895e-05,
      "loss": 0.3445,
      "step": 190
    },
    {
      "epoch": 0.5659709939865581,
      "grad_norm": 0.24862466752529144,
      "learning_rate": 9.761860338647055e-05,
      "loss": 0.3323,
      "step": 200
    },
    {
      "epoch": 0.5942695436858861,
      "grad_norm": 0.45408570766448975,
      "learning_rate": 9.709020366771656e-05,
      "loss": 0.3427,
      "step": 210
    },
    {
      "epoch": 0.622568093385214,
      "grad_norm": 0.19847004115581512,
      "learning_rate": 9.651063515472754e-05,
      "loss": 0.3388,
      "step": 220
    },
    {
      "epoch": 0.6508666430845419,
      "grad_norm": 0.24660873413085938,
      "learning_rate": 9.588052761377497e-05,
      "loss": 0.3419,
      "step": 230
    },
    {
      "epoch": 0.6791651927838698,
      "grad_norm": 0.20775440335273743,
      "learning_rate": 9.520056572745944e-05,
      "loss": 0.3343,
      "step": 240
    },
    {
      "epoch": 0.7074637424831978,
      "grad_norm": 0.5151544809341431,
      "learning_rate": 9.447148835072608e-05,
      "loss": 0.3347,
      "step": 250
    },
    {
      "epoch": 0.7357622921825256,
      "grad_norm": 0.3523748517036438,
      "learning_rate": 9.369408770801578e-05,
      "loss": 0.3438,
      "step": 260
    },
    {
      "epoch": 0.7640608418818535,
      "grad_norm": 0.3310440480709076,
      "learning_rate": 9.286920853242433e-05,
      "loss": 0.338,
      "step": 270
    },
    {
      "epoch": 0.7923593915811815,
      "grad_norm": 0.21737875044345856,
      "learning_rate": 9.199774714780503e-05,
      "loss": 0.3429,
      "step": 280
    },
    {
      "epoch": 0.8206579412805094,
      "grad_norm": 0.4385158121585846,
      "learning_rate": 9.10806504948122e-05,
      "loss": 0.334,
      "step": 290
    },
    {
      "epoch": 0.8489564909798373,
      "grad_norm": 0.22008270025253296,
      "learning_rate": 9.011891510194381e-05,
      "loss": 0.3404,
      "step": 300
    },
    {
      "epoch": 0.8772550406791652,
      "grad_norm": 0.2652759552001953,
      "learning_rate": 8.911358600270141e-05,
      "loss": 0.3354,
      "step": 310
    },
    {
      "epoch": 0.9055535903784931,
      "grad_norm": 0.5432608723640442,
      "learning_rate": 8.80657556000438e-05,
      "loss": 0.3335,
      "step": 320
    },
    {
      "epoch": 0.933852140077821,
      "grad_norm": 0.7705543637275696,
      "learning_rate": 8.697656247936859e-05,
      "loss": 0.3414,
      "step": 330
    },
    {
      "epoch": 0.9621506897771489,
      "grad_norm": 0.36704787611961365,
      "learning_rate": 8.58471901713113e-05,
      "loss": 0.3413,
      "step": 340
    },
    {
      "epoch": 0.9904492394764768,
      "grad_norm": 0.19895079731941223,
      "learning_rate": 8.467886586570645e-05,
      "loss": 0.338,
      "step": 350
    },
    {
      "epoch": 0.9989388043862752,
      "eval_loss": 0.3368365168571472,
      "eval_runtime": 183.7991,
      "eval_samples_per_second": 6.79,
      "eval_steps_per_second": 1.132,
      "step": 353
    },
    {
      "epoch": 1.0187477891758048,
      "grad_norm": 0.33875158429145813,
      "learning_rate": 8.347285907810793e-05,
      "loss": 0.3553,
      "step": 360
    },
    {
      "epoch": 1.0470463388751325,
      "grad_norm": 0.29554322361946106,
      "learning_rate": 8.22304802703179e-05,
      "loss": 0.3326,
      "step": 370
    },
    {
      "epoch": 1.0753448885744605,
      "grad_norm": 0.5770477652549744,
      "learning_rate": 8.095307942642276e-05,
      "loss": 0.3321,
      "step": 380
    },
    {
      "epoch": 1.1036434382737885,
      "grad_norm": 0.44791939854621887,
      "learning_rate": 7.964204458588393e-05,
      "loss": 0.3235,
      "step": 390
    },
    {
      "epoch": 1.1319419879731163,
      "grad_norm": 0.44856512546539307,
      "learning_rate": 7.829880033527708e-05,
      "loss": 0.3201,
      "step": 400
    },
    {
      "epoch": 1.1602405376724443,
      "grad_norm": 0.528388500213623,
      "learning_rate": 7.692480626031881e-05,
      "loss": 0.3304,
      "step": 410
    },
    {
      "epoch": 1.1885390873717723,
      "grad_norm": 0.5019129514694214,
      "learning_rate": 7.5521555359863e-05,
      "loss": 0.315,
      "step": 420
    },
    {
      "epoch": 1.2168376370711,
      "grad_norm": 0.34472742676734924,
      "learning_rate": 7.409057242358967e-05,
      "loss": 0.3235,
      "step": 430
    },
    {
      "epoch": 1.245136186770428,
      "grad_norm": 0.8491606712341309,
      "learning_rate": 7.263341237514997e-05,
      "loss": 0.3148,
      "step": 440
    },
    {
      "epoch": 1.2734347364697558,
      "grad_norm": 0.37107524275779724,
      "learning_rate": 7.115165858256698e-05,
      "loss": 0.3185,
      "step": 450
    },
    {
      "epoch": 1.3017332861690838,
      "grad_norm": 0.467094749212265,
      "learning_rate": 6.964692113772846e-05,
      "loss": 0.3166,
      "step": 460
    },
    {
      "epoch": 1.3300318358684118,
      "grad_norm": 0.5522720813751221,
      "learning_rate": 6.812083510684128e-05,
      "loss": 0.3094,
      "step": 470
    },
    {
      "epoch": 1.3583303855677396,
      "grad_norm": 0.5897539258003235,
      "learning_rate": 6.657505875374844e-05,
      "loss": 0.3211,
      "step": 480
    },
    {
      "epoch": 1.3866289352670675,
      "grad_norm": 0.32853278517723083,
      "learning_rate": 6.501127173803904e-05,
      "loss": 0.3122,
      "step": 490
    },
    {
      "epoch": 1.4149274849663955,
      "grad_norm": 0.4645540714263916,
      "learning_rate": 6.343117328990967e-05,
      "loss": 0.3084,
      "step": 500
    },
    {
      "epoch": 1.4432260346657233,
      "grad_norm": 0.570885181427002,
      "learning_rate": 6.183648036375985e-05,
      "loss": 0.314,
      "step": 510
    },
    {
      "epoch": 1.4715245843650513,
      "grad_norm": 0.3755863308906555,
      "learning_rate": 6.022892577252838e-05,
      "loss": 0.3206,
      "step": 520
    },
    {
      "epoch": 1.4998231340643793,
      "grad_norm": 0.4482213854789734,
      "learning_rate": 5.86102563047975e-05,
      "loss": 0.3001,
      "step": 530
    },
    {
      "epoch": 1.528121683763707,
      "grad_norm": 0.4819523096084595,
      "learning_rate": 5.6982230826710824e-05,
      "loss": 0.3216,
      "step": 540
    },
    {
      "epoch": 1.556420233463035,
      "grad_norm": 0.3825800120830536,
      "learning_rate": 5.534661837076792e-05,
      "loss": 0.3166,
      "step": 550
    },
    {
      "epoch": 1.584718783162363,
      "grad_norm": 0.41767776012420654,
      "learning_rate": 5.3705196213571685e-05,
      "loss": 0.314,
      "step": 560
    },
    {
      "epoch": 1.6130173328616908,
      "grad_norm": 0.39630964398384094,
      "learning_rate": 5.2059747944617886e-05,
      "loss": 0.3137,
      "step": 570
    },
    {
      "epoch": 1.6413158825610188,
      "grad_norm": 0.7343593239784241,
      "learning_rate": 5.041206152822482e-05,
      "loss": 0.3087,
      "step": 580
    },
    {
      "epoch": 1.6696144322603468,
      "grad_norm": 0.6893825531005859,
      "learning_rate": 4.876392736070927e-05,
      "loss": 0.3047,
      "step": 590
    },
    {
      "epoch": 1.6979129819596745,
      "grad_norm": 0.8730220794677734,
      "learning_rate": 4.711713632491993e-05,
      "loss": 0.2973,
      "step": 600
    },
    {
      "epoch": 1.7262115316590023,
      "grad_norm": 0.5971918702125549,
      "learning_rate": 4.547347784424201e-05,
      "loss": 0.3112,
      "step": 610
    },
    {
      "epoch": 1.7545100813583305,
      "grad_norm": 0.39944496750831604,
      "learning_rate": 4.3834737938187865e-05,
      "loss": 0.313,
      "step": 620
    },
    {
      "epoch": 1.7828086310576583,
      "grad_norm": 0.4492381513118744,
      "learning_rate": 4.2202697281686174e-05,
      "loss": 0.3013,
      "step": 630
    },
    {
      "epoch": 1.811107180756986,
      "grad_norm": 0.6335016489028931,
      "learning_rate": 4.057912927017869e-05,
      "loss": 0.2807,
      "step": 640
    },
    {
      "epoch": 1.839405730456314,
      "grad_norm": 1.1676737070083618,
      "learning_rate": 3.896579809262696e-05,
      "loss": 0.2946,
      "step": 650
    },
    {
      "epoch": 1.867704280155642,
      "grad_norm": 0.9494199156761169,
      "learning_rate": 3.7364456814522885e-05,
      "loss": 0.2964,
      "step": 660
    },
    {
      "epoch": 1.8960028298549698,
      "grad_norm": 0.6702913045883179,
      "learning_rate": 3.577684547298626e-05,
      "loss": 0.2856,
      "step": 670
    },
    {
      "epoch": 1.9243013795542978,
      "grad_norm": 0.5127010345458984,
      "learning_rate": 3.420468918601896e-05,
      "loss": 0.2888,
      "step": 680
    },
    {
      "epoch": 1.9525999292536258,
      "grad_norm": 0.7254508137702942,
      "learning_rate": 3.26496962779706e-05,
      "loss": 0.2859,
      "step": 690
    },
    {
      "epoch": 1.9808984789529536,
      "grad_norm": 1.147109031677246,
      "learning_rate": 3.111355642325222e-05,
      "loss": 0.2858,
      "step": 700
    },
    {
      "epoch": 1.9978776087725505,
      "eval_loss": 0.33228743076324463,
      "eval_runtime": 183.36,
      "eval_samples_per_second": 6.806,
      "eval_steps_per_second": 1.134,
      "step": 706
    },
    {
      "epoch": 2.009197028652282,
      "grad_norm": 0.7324720621109009,
      "learning_rate": 2.959793881031536e-05,
      "loss": 0.325,
      "step": 710
    },
    {
      "epoch": 2.0374955783516095,
      "grad_norm": 0.6053256392478943,
      "learning_rate": 2.810449032789134e-05,
      "loss": 0.2782,
      "step": 720
    },
    {
      "epoch": 2.0657941280509373,
      "grad_norm": 0.6922464966773987,
      "learning_rate": 2.663483377546167e-05,
      "loss": 0.2854,
      "step": 730
    },
    {
      "epoch": 2.094092677750265,
      "grad_norm": 0.8210088014602661,
      "learning_rate": 2.51905660999043e-05,
      "loss": 0.2755,
      "step": 740
    },
    {
      "epoch": 2.1223912274495933,
      "grad_norm": 0.5854313373565674,
      "learning_rate": 2.377325666023137e-05,
      "loss": 0.2736,
      "step": 750
    },
    {
      "epoch": 2.150689777148921,
      "grad_norm": 0.6699977517127991,
      "learning_rate": 2.2384445522304536e-05,
      "loss": 0.2799,
      "step": 760
    },
    {
      "epoch": 2.178988326848249,
      "grad_norm": 0.6890280842781067,
      "learning_rate": 2.1025641785380373e-05,
      "loss": 0.2791,
      "step": 770
    },
    {
      "epoch": 2.207286876547577,
      "grad_norm": 1.1307823657989502,
      "learning_rate": 1.969832194230466e-05,
      "loss": 0.2721,
      "step": 780
    },
    {
      "epoch": 2.235585426246905,
      "grad_norm": 0.7291844487190247,
      "learning_rate": 1.8403928275136994e-05,
      "loss": 0.2901,
      "step": 790
    },
    {
      "epoch": 2.2638839759462326,
      "grad_norm": 1.0740745067596436,
      "learning_rate": 1.7143867287949487e-05,
      "loss": 0.2595,
      "step": 800
    },
    {
      "epoch": 2.292182525645561,
      "grad_norm": 0.8310622572898865,
      "learning_rate": 1.59195081785021e-05,
      "loss": 0.2566,
      "step": 810
    },
    {
      "epoch": 2.3204810753448886,
      "grad_norm": 0.8351724743843079,
      "learning_rate": 1.4732181350455471e-05,
      "loss": 0.267,
      "step": 820
    },
    {
      "epoch": 2.3487796250442163,
      "grad_norm": 1.183151125907898,
      "learning_rate": 1.3583176967738042e-05,
      "loss": 0.2711,
      "step": 830
    },
    {
      "epoch": 2.3770781747435445,
      "grad_norm": 0.8666520118713379,
      "learning_rate": 1.2473743552637973e-05,
      "loss": 0.263,
      "step": 840
    },
    {
      "epoch": 2.4053767244428723,
      "grad_norm": 0.7876735329627991,
      "learning_rate": 1.140508662914358e-05,
      "loss": 0.2709,
      "step": 850
    },
    {
      "epoch": 2.4336752741422,
      "grad_norm": 0.9662442803382874,
      "learning_rate": 1.0378367413006052e-05,
      "loss": 0.2711,
      "step": 860
    },
    {
      "epoch": 2.4619738238415283,
      "grad_norm": 0.7636770009994507,
      "learning_rate": 9.394701549948165e-06,
      "loss": 0.262,
      "step": 870
    },
    {
      "epoch": 2.490272373540856,
      "grad_norm": 1.151193380355835,
      "learning_rate": 8.455157903389994e-06,
      "loss": 0.2622,
      "step": 880
    },
    {
      "epoch": 2.518570923240184,
      "grad_norm": 0.9262079000473022,
      "learning_rate": 7.5607573930086825e-06,
      "loss": 0.2683,
      "step": 890
    },
    {
      "epoch": 2.5468694729395116,
      "grad_norm": 0.655184268951416,
      "learning_rate": 6.712471885394606e-06,
      "loss": 0.2481,
      "step": 900
    },
    {
      "epoch": 2.57516802263884,
      "grad_norm": 0.9481186270713806,
      "learning_rate": 5.911223138009225e-06,
      "loss": 0.2615,
      "step": 910
    },
    {
      "epoch": 2.6034665723381676,
      "grad_norm": 0.9564328789710999,
      "learning_rate": 5.157881797592057e-06,
      "loss": 0.2585,
      "step": 920
    },
    {
      "epoch": 2.6317651220374954,
      "grad_norm": 1.045453667640686,
      "learning_rate": 4.453266454105198e-06,
      "loss": 0.2577,
      "step": 930
    },
    {
      "epoch": 2.6600636717368236,
      "grad_norm": 0.8049125075340271,
      "learning_rate": 3.798142751243483e-06,
      "loss": 0.2612,
      "step": 940
    },
    {
      "epoch": 2.6883622214361513,
      "grad_norm": 1.102213740348816,
      "learning_rate": 3.1932225544765493e-06,
      "loss": 0.2525,
      "step": 950
    },
    {
      "epoch": 2.716660771135479,
      "grad_norm": 0.9993113279342651,
      "learning_rate": 2.639163177527154e-06,
      "loss": 0.2674,
      "step": 960
    },
    {
      "epoch": 2.7449593208348073,
      "grad_norm": 1.6975655555725098,
      "learning_rate": 2.1365666681259e-06,
      "loss": 0.2417,
      "step": 970
    },
    {
      "epoch": 2.773257870534135,
      "grad_norm": 1.0397580862045288,
      "learning_rate": 1.685979153818873e-06,
      "loss": 0.2562,
      "step": 980
    },
    {
      "epoch": 2.801556420233463,
      "grad_norm": 1.0718106031417847,
      "learning_rate": 1.2878902485386534e-06,
      "loss": 0.2639,
      "step": 990
    },
    {
      "epoch": 2.829854969932791,
      "grad_norm": 1.0217849016189575,
      "learning_rate": 9.427325205838555e-07,
      "loss": 0.2469,
      "step": 1000
    },
    {
      "epoch": 2.858153519632119,
      "grad_norm": 1.4119259119033813,
      "learning_rate": 6.508810225850703e-07,
      "loss": 0.265,
      "step": 1010
    },
    {
      "epoch": 2.8864520693314466,
      "grad_norm": 0.8535364866256714,
      "learning_rate": 4.1265288396805104e-07,
      "loss": 0.2493,
      "step": 1020
    },
    {
      "epoch": 2.914750619030775,
      "grad_norm": 1.0048820972442627,
      "learning_rate": 2.2830696635701143e-07,
      "loss": 0.2492,
      "step": 1030
    },
    {
      "epoch": 2.9430491687301026,
      "grad_norm": 0.9839707016944885,
      "learning_rate": 9.804358229238974e-08,
      "loss": 0.2524,
      "step": 1040
    },
    {
      "epoch": 2.9713477184294304,
      "grad_norm": 1.0462144613265991,
      "learning_rate": 2.2004277568776766e-08,
      "loss": 0.2463,
      "step": 1050
    },
    {
      "epoch": 2.9968164131588257,
      "eval_loss": 0.3091636300086975,
      "eval_runtime": 183.8551,
      "eval_samples_per_second": 6.788,
      "eval_steps_per_second": 1.131,
      "step": 1059
    },
    {
      "epoch": 2.9968164131588257,
      "step": 1059,
      "total_flos": 5.126011604487373e+18,
      "train_loss": 0.45821518848480425,
      "train_runtime": 21209.2014,
      "train_samples_per_second": 2.399,
      "train_steps_per_second": 0.05
    }
  ],
  "logging_steps": 10,
  "max_steps": 1059,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.126011604487373e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
