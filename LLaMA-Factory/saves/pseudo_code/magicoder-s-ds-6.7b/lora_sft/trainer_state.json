{
  "best_metric": 0.17528307437896729,
  "best_model_checkpoint": "saves/pseudo_code/magicoder/lora_sft/checkpoint-1059",
  "epoch": 2.9968164131588257,
  "eval_steps": 500,
  "global_step": 1059,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02829854969932791,
      "grad_norm": 3.651477575302124,
      "learning_rate": 9.433962264150944e-06,
      "loss": 8.5363,
      "step": 10
    },
    {
      "epoch": 0.05659709939865582,
      "grad_norm": 5.014533042907715,
      "learning_rate": 1.8867924528301888e-05,
      "loss": 8.2958,
      "step": 20
    },
    {
      "epoch": 0.08489564909798372,
      "grad_norm": 5.180666446685791,
      "learning_rate": 2.830188679245283e-05,
      "loss": 7.341,
      "step": 30
    },
    {
      "epoch": 0.11319419879731164,
      "grad_norm": 1.0955042839050293,
      "learning_rate": 3.7735849056603776e-05,
      "loss": 4.2077,
      "step": 40
    },
    {
      "epoch": 0.14149274849663954,
      "grad_norm": 1.9197713136672974,
      "learning_rate": 4.716981132075472e-05,
      "loss": 3.9995,
      "step": 50
    },
    {
      "epoch": 0.16979129819596744,
      "grad_norm": 2.6881020069122314,
      "learning_rate": 5.660377358490566e-05,
      "loss": 3.2482,
      "step": 60
    },
    {
      "epoch": 0.19808984789529538,
      "grad_norm": 1.1101877689361572,
      "learning_rate": 6.60377358490566e-05,
      "loss": 1.8603,
      "step": 70
    },
    {
      "epoch": 0.2263883975946233,
      "grad_norm": 0.6985394358634949,
      "learning_rate": 7.547169811320755e-05,
      "loss": 0.7009,
      "step": 80
    },
    {
      "epoch": 0.2546869472939512,
      "grad_norm": 0.47822144627571106,
      "learning_rate": 8.49056603773585e-05,
      "loss": 0.3943,
      "step": 90
    },
    {
      "epoch": 0.2829854969932791,
      "grad_norm": 2.3175265789031982,
      "learning_rate": 9.433962264150944e-05,
      "loss": 0.3944,
      "step": 100
    },
    {
      "epoch": 0.311284046692607,
      "grad_norm": 2.2673206329345703,
      "learning_rate": 9.999565322017444e-05,
      "loss": 0.3595,
      "step": 110
    },
    {
      "epoch": 0.3395825963919349,
      "grad_norm": 0.9529494047164917,
      "learning_rate": 9.994676062638023e-05,
      "loss": 0.3518,
      "step": 120
    },
    {
      "epoch": 0.3678811460912628,
      "grad_norm": 0.9640030860900879,
      "learning_rate": 9.984359526844107e-05,
      "loss": 0.3555,
      "step": 130
    },
    {
      "epoch": 0.39617969579059076,
      "grad_norm": 0.8325011134147644,
      "learning_rate": 9.968626924710318e-05,
      "loss": 0.3551,
      "step": 140
    },
    {
      "epoch": 0.42447824548991864,
      "grad_norm": 0.1771184355020523,
      "learning_rate": 9.947495351475553e-05,
      "loss": 0.343,
      "step": 150
    },
    {
      "epoch": 0.4527767951892466,
      "grad_norm": 1.5505064725875854,
      "learning_rate": 9.920987768967081e-05,
      "loss": 0.3636,
      "step": 160
    },
    {
      "epoch": 0.48107534488857445,
      "grad_norm": 0.3224291503429413,
      "learning_rate": 9.889132980649944e-05,
      "loss": 0.3564,
      "step": 170
    },
    {
      "epoch": 0.5093738945879024,
      "grad_norm": 0.5432239174842834,
      "learning_rate": 9.85196560032875e-05,
      "loss": 0.3477,
      "step": 180
    },
    {
      "epoch": 0.5376724442872303,
      "grad_norm": 0.48980849981307983,
      "learning_rate": 9.809526014535895e-05,
      "loss": 0.3455,
      "step": 190
    },
    {
      "epoch": 0.5659709939865581,
      "grad_norm": 0.20883417129516602,
      "learning_rate": 9.761860338647055e-05,
      "loss": 0.3396,
      "step": 200
    },
    {
      "epoch": 0.5942695436858861,
      "grad_norm": 1.0855627059936523,
      "learning_rate": 9.709020366771656e-05,
      "loss": 0.337,
      "step": 210
    },
    {
      "epoch": 0.622568093385214,
      "grad_norm": 0.34845563769340515,
      "learning_rate": 9.651063515472754e-05,
      "loss": 0.325,
      "step": 220
    },
    {
      "epoch": 0.6508666430845419,
      "grad_norm": 0.4970788359642029,
      "learning_rate": 9.588052761377497e-05,
      "loss": 0.33,
      "step": 230
    },
    {
      "epoch": 0.6791651927838698,
      "grad_norm": 1.3204903602600098,
      "learning_rate": 9.520056572745944e-05,
      "loss": 0.3119,
      "step": 240
    },
    {
      "epoch": 0.7074637424831978,
      "grad_norm": 1.1513904333114624,
      "learning_rate": 9.447148835072608e-05,
      "loss": 0.31,
      "step": 250
    },
    {
      "epoch": 0.7357622921825256,
      "grad_norm": 0.7797194123268127,
      "learning_rate": 9.369408770801578e-05,
      "loss": 0.3397,
      "step": 260
    },
    {
      "epoch": 0.7640608418818535,
      "grad_norm": 0.34193623065948486,
      "learning_rate": 9.286920853242433e-05,
      "loss": 0.3105,
      "step": 270
    },
    {
      "epoch": 0.7923593915811815,
      "grad_norm": 1.1272953748703003,
      "learning_rate": 9.199774714780503e-05,
      "loss": 0.3037,
      "step": 280
    },
    {
      "epoch": 0.8206579412805094,
      "grad_norm": 0.9003334045410156,
      "learning_rate": 9.10806504948122e-05,
      "loss": 0.3105,
      "step": 290
    },
    {
      "epoch": 0.8489564909798373,
      "grad_norm": 0.3589839041233063,
      "learning_rate": 9.011891510194381e-05,
      "loss": 0.2945,
      "step": 300
    },
    {
      "epoch": 0.8772550406791652,
      "grad_norm": 0.45792949199676514,
      "learning_rate": 8.911358600270141e-05,
      "loss": 0.2985,
      "step": 310
    },
    {
      "epoch": 0.9055535903784931,
      "grad_norm": 1.3846664428710938,
      "learning_rate": 8.80657556000438e-05,
      "loss": 0.2939,
      "step": 320
    },
    {
      "epoch": 0.933852140077821,
      "grad_norm": 1.7879469394683838,
      "learning_rate": 8.697656247936859e-05,
      "loss": 0.303,
      "step": 330
    },
    {
      "epoch": 0.9621506897771489,
      "grad_norm": 0.8609780073165894,
      "learning_rate": 8.58471901713113e-05,
      "loss": 0.304,
      "step": 340
    },
    {
      "epoch": 0.9904492394764768,
      "grad_norm": 0.690287709236145,
      "learning_rate": 8.467886586570645e-05,
      "loss": 0.3136,
      "step": 350
    },
    {
      "epoch": 0.9989388043862752,
      "eval_loss": 0.31437912583351135,
      "eval_runtime": 196.1296,
      "eval_samples_per_second": 6.363,
      "eval_steps_per_second": 1.061,
      "step": 353
    },
    {
      "epoch": 1.0187477891758048,
      "grad_norm": 0.8528181910514832,
      "learning_rate": 8.347285907810793e-05,
      "loss": 0.3138,
      "step": 360
    },
    {
      "epoch": 1.0470463388751325,
      "grad_norm": 0.6238951683044434,
      "learning_rate": 8.22304802703179e-05,
      "loss": 0.2761,
      "step": 370
    },
    {
      "epoch": 1.0753448885744605,
      "grad_norm": 0.9337156414985657,
      "learning_rate": 8.095307942642276e-05,
      "loss": 0.2625,
      "step": 380
    },
    {
      "epoch": 1.1036434382737885,
      "grad_norm": 0.6801090836524963,
      "learning_rate": 7.964204458588393e-05,
      "loss": 0.2844,
      "step": 390
    },
    {
      "epoch": 1.1319419879731163,
      "grad_norm": 0.7235451936721802,
      "learning_rate": 7.829880033527708e-05,
      "loss": 0.2759,
      "step": 400
    },
    {
      "epoch": 1.1602405376724443,
      "grad_norm": 0.48685747385025024,
      "learning_rate": 7.692480626031881e-05,
      "loss": 0.2571,
      "step": 410
    },
    {
      "epoch": 1.1885390873717723,
      "grad_norm": 0.8705442547798157,
      "learning_rate": 7.5521555359863e-05,
      "loss": 0.2395,
      "step": 420
    },
    {
      "epoch": 1.2168376370711,
      "grad_norm": 0.5819183588027954,
      "learning_rate": 7.409057242358967e-05,
      "loss": 0.2402,
      "step": 430
    },
    {
      "epoch": 1.245136186770428,
      "grad_norm": 1.921980381011963,
      "learning_rate": 7.263341237514997e-05,
      "loss": 0.2564,
      "step": 440
    },
    {
      "epoch": 1.2734347364697558,
      "grad_norm": 0.5728982090950012,
      "learning_rate": 7.115165858256698e-05,
      "loss": 0.2583,
      "step": 450
    },
    {
      "epoch": 1.3017332861690838,
      "grad_norm": 0.880181610584259,
      "learning_rate": 6.964692113772846e-05,
      "loss": 0.2566,
      "step": 460
    },
    {
      "epoch": 1.3300318358684118,
      "grad_norm": 0.7466352581977844,
      "learning_rate": 6.812083510684128e-05,
      "loss": 0.2287,
      "step": 470
    },
    {
      "epoch": 1.3583303855677396,
      "grad_norm": 0.9852734208106995,
      "learning_rate": 6.657505875374844e-05,
      "loss": 0.2491,
      "step": 480
    },
    {
      "epoch": 1.3866289352670675,
      "grad_norm": 0.5842647552490234,
      "learning_rate": 6.501127173803904e-05,
      "loss": 0.2403,
      "step": 490
    },
    {
      "epoch": 1.4149274849663955,
      "grad_norm": 0.6991967558860779,
      "learning_rate": 6.343117328990967e-05,
      "loss": 0.2214,
      "step": 500
    },
    {
      "epoch": 1.4432260346657233,
      "grad_norm": 0.9221001267433167,
      "learning_rate": 6.183648036375985e-05,
      "loss": 0.2446,
      "step": 510
    },
    {
      "epoch": 1.4715245843650513,
      "grad_norm": 1.3708477020263672,
      "learning_rate": 6.022892577252838e-05,
      "loss": 0.2234,
      "step": 520
    },
    {
      "epoch": 1.4998231340643793,
      "grad_norm": 1.1218962669372559,
      "learning_rate": 5.86102563047975e-05,
      "loss": 0.2026,
      "step": 530
    },
    {
      "epoch": 1.528121683763707,
      "grad_norm": 1.8256611824035645,
      "learning_rate": 5.6982230826710824e-05,
      "loss": 0.2408,
      "step": 540
    },
    {
      "epoch": 1.556420233463035,
      "grad_norm": 0.8529232144355774,
      "learning_rate": 5.534661837076792e-05,
      "loss": 0.2145,
      "step": 550
    },
    {
      "epoch": 1.584718783162363,
      "grad_norm": 1.0694730281829834,
      "learning_rate": 5.3705196213571685e-05,
      "loss": 0.2211,
      "step": 560
    },
    {
      "epoch": 1.6130173328616908,
      "grad_norm": 0.85430508852005,
      "learning_rate": 5.2059747944617886e-05,
      "loss": 0.2093,
      "step": 570
    },
    {
      "epoch": 1.6413158825610188,
      "grad_norm": 1.6121882200241089,
      "learning_rate": 5.041206152822482e-05,
      "loss": 0.1923,
      "step": 580
    },
    {
      "epoch": 1.6696144322603468,
      "grad_norm": 0.8988152146339417,
      "learning_rate": 4.876392736070927e-05,
      "loss": 0.2225,
      "step": 590
    },
    {
      "epoch": 1.6979129819596745,
      "grad_norm": 1.0280262231826782,
      "learning_rate": 4.711713632491993e-05,
      "loss": 0.2116,
      "step": 600
    },
    {
      "epoch": 1.7262115316590023,
      "grad_norm": 0.9829177856445312,
      "learning_rate": 4.547347784424201e-05,
      "loss": 0.1819,
      "step": 610
    },
    {
      "epoch": 1.7545100813583305,
      "grad_norm": 1.4235583543777466,
      "learning_rate": 4.3834737938187865e-05,
      "loss": 0.2105,
      "step": 620
    },
    {
      "epoch": 1.7828086310576583,
      "grad_norm": 0.900905191898346,
      "learning_rate": 4.2202697281686174e-05,
      "loss": 0.2075,
      "step": 630
    },
    {
      "epoch": 1.811107180756986,
      "grad_norm": 0.821092426776886,
      "learning_rate": 4.057912927017869e-05,
      "loss": 0.1586,
      "step": 640
    },
    {
      "epoch": 1.839405730456314,
      "grad_norm": 1.413165807723999,
      "learning_rate": 3.896579809262696e-05,
      "loss": 0.1805,
      "step": 650
    },
    {
      "epoch": 1.867704280155642,
      "grad_norm": 1.519593358039856,
      "learning_rate": 3.7364456814522885e-05,
      "loss": 0.1846,
      "step": 660
    },
    {
      "epoch": 1.8960028298549698,
      "grad_norm": 0.7596151232719421,
      "learning_rate": 3.577684547298626e-05,
      "loss": 0.1895,
      "step": 670
    },
    {
      "epoch": 1.9243013795542978,
      "grad_norm": 1.6165581941604614,
      "learning_rate": 3.420468918601896e-05,
      "loss": 0.1714,
      "step": 680
    },
    {
      "epoch": 1.9525999292536258,
      "grad_norm": 1.512865662574768,
      "learning_rate": 3.26496962779706e-05,
      "loss": 0.1629,
      "step": 690
    },
    {
      "epoch": 1.9808984789529536,
      "grad_norm": 1.1333624124526978,
      "learning_rate": 3.111355642325222e-05,
      "loss": 0.1892,
      "step": 700
    },
    {
      "epoch": 1.9978776087725505,
      "eval_loss": 0.20682364702224731,
      "eval_runtime": 196.101,
      "eval_samples_per_second": 6.364,
      "eval_steps_per_second": 1.061,
      "step": 706
    },
    {
      "epoch": 2.009197028652282,
      "grad_norm": 1.013806939125061,
      "learning_rate": 2.959793881031536e-05,
      "loss": 0.1849,
      "step": 710
    },
    {
      "epoch": 2.0374955783516095,
      "grad_norm": 1.0529656410217285,
      "learning_rate": 2.810449032789134e-05,
      "loss": 0.1351,
      "step": 720
    },
    {
      "epoch": 2.0657941280509373,
      "grad_norm": 1.3416612148284912,
      "learning_rate": 2.663483377546167e-05,
      "loss": 0.1243,
      "step": 730
    },
    {
      "epoch": 2.094092677750265,
      "grad_norm": 2.433203935623169,
      "learning_rate": 2.51905660999043e-05,
      "loss": 0.1362,
      "step": 740
    },
    {
      "epoch": 2.1223912274495933,
      "grad_norm": 1.034704327583313,
      "learning_rate": 2.377325666023137e-05,
      "loss": 0.1499,
      "step": 750
    },
    {
      "epoch": 2.150689777148921,
      "grad_norm": 0.9695802330970764,
      "learning_rate": 2.2384445522304536e-05,
      "loss": 0.1273,
      "step": 760
    },
    {
      "epoch": 2.178988326848249,
      "grad_norm": 2.995288133621216,
      "learning_rate": 2.1025641785380373e-05,
      "loss": 0.1312,
      "step": 770
    },
    {
      "epoch": 2.207286876547577,
      "grad_norm": 1.5867884159088135,
      "learning_rate": 1.969832194230466e-05,
      "loss": 0.1268,
      "step": 780
    },
    {
      "epoch": 2.235585426246905,
      "grad_norm": 1.197814702987671,
      "learning_rate": 1.8403928275136994e-05,
      "loss": 0.1411,
      "step": 790
    },
    {
      "epoch": 2.2638839759462326,
      "grad_norm": 1.8775532245635986,
      "learning_rate": 1.7143867287949487e-05,
      "loss": 0.121,
      "step": 800
    },
    {
      "epoch": 2.292182525645561,
      "grad_norm": 1.536249041557312,
      "learning_rate": 1.59195081785021e-05,
      "loss": 0.1253,
      "step": 810
    },
    {
      "epoch": 2.3204810753448886,
      "grad_norm": 1.61255943775177,
      "learning_rate": 1.4732181350455471e-05,
      "loss": 0.1161,
      "step": 820
    },
    {
      "epoch": 2.3487796250442163,
      "grad_norm": 3.1218533515930176,
      "learning_rate": 1.3583176967738042e-05,
      "loss": 0.1179,
      "step": 830
    },
    {
      "epoch": 2.3770781747435445,
      "grad_norm": 1.2659958600997925,
      "learning_rate": 1.2473743552637973e-05,
      "loss": 0.1219,
      "step": 840
    },
    {
      "epoch": 2.4053767244428723,
      "grad_norm": 1.4701699018478394,
      "learning_rate": 1.140508662914358e-05,
      "loss": 0.1327,
      "step": 850
    },
    {
      "epoch": 2.4336752741422,
      "grad_norm": 1.565894603729248,
      "learning_rate": 1.0378367413006052e-05,
      "loss": 0.1197,
      "step": 860
    },
    {
      "epoch": 2.4619738238415283,
      "grad_norm": 0.6608052253723145,
      "learning_rate": 9.394701549948165e-06,
      "loss": 0.1043,
      "step": 870
    },
    {
      "epoch": 2.490272373540856,
      "grad_norm": 1.5244741439819336,
      "learning_rate": 8.455157903389994e-06,
      "loss": 0.1035,
      "step": 880
    },
    {
      "epoch": 2.518570923240184,
      "grad_norm": 1.3772274255752563,
      "learning_rate": 7.5607573930086825e-06,
      "loss": 0.1234,
      "step": 890
    },
    {
      "epoch": 2.5468694729395116,
      "grad_norm": 2.4683613777160645,
      "learning_rate": 6.712471885394606e-06,
      "loss": 0.1042,
      "step": 900
    },
    {
      "epoch": 2.57516802263884,
      "grad_norm": 2.038870096206665,
      "learning_rate": 5.911223138009225e-06,
      "loss": 0.1028,
      "step": 910
    },
    {
      "epoch": 2.6034665723381676,
      "grad_norm": 1.3186359405517578,
      "learning_rate": 5.157881797592057e-06,
      "loss": 0.1046,
      "step": 920
    },
    {
      "epoch": 2.6317651220374954,
      "grad_norm": 1.1056925058364868,
      "learning_rate": 4.453266454105198e-06,
      "loss": 0.0933,
      "step": 930
    },
    {
      "epoch": 2.6600636717368236,
      "grad_norm": 2.17781138420105,
      "learning_rate": 3.798142751243483e-06,
      "loss": 0.1058,
      "step": 940
    },
    {
      "epoch": 2.6883622214361513,
      "grad_norm": 2.389557361602783,
      "learning_rate": 3.1932225544765493e-06,
      "loss": 0.1219,
      "step": 950
    },
    {
      "epoch": 2.716660771135479,
      "grad_norm": 2.5610296726226807,
      "learning_rate": 2.639163177527154e-06,
      "loss": 0.1112,
      "step": 960
    },
    {
      "epoch": 2.7449593208348073,
      "grad_norm": 0.867709755897522,
      "learning_rate": 2.1365666681259e-06,
      "loss": 0.1113,
      "step": 970
    },
    {
      "epoch": 2.773257870534135,
      "grad_norm": 1.7083194255828857,
      "learning_rate": 1.685979153818873e-06,
      "loss": 0.1035,
      "step": 980
    },
    {
      "epoch": 2.801556420233463,
      "grad_norm": 1.5054211616516113,
      "learning_rate": 1.2878902485386534e-06,
      "loss": 0.1111,
      "step": 990
    },
    {
      "epoch": 2.829854969932791,
      "grad_norm": 1.4238463640213013,
      "learning_rate": 9.427325205838555e-07,
      "loss": 0.1037,
      "step": 1000
    },
    {
      "epoch": 2.858153519632119,
      "grad_norm": 1.1209520101547241,
      "learning_rate": 6.508810225850703e-07,
      "loss": 0.0953,
      "step": 1010
    },
    {
      "epoch": 2.8864520693314466,
      "grad_norm": 1.6457997560501099,
      "learning_rate": 4.1265288396805104e-07,
      "loss": 0.091,
      "step": 1020
    },
    {
      "epoch": 2.914750619030775,
      "grad_norm": 1.882289171218872,
      "learning_rate": 2.2830696635701143e-07,
      "loss": 0.1046,
      "step": 1030
    },
    {
      "epoch": 2.9430491687301026,
      "grad_norm": 1.4944249391555786,
      "learning_rate": 9.804358229238974e-08,
      "loss": 0.0933,
      "step": 1040
    },
    {
      "epoch": 2.9713477184294304,
      "grad_norm": 1.2381728887557983,
      "learning_rate": 2.2004277568776766e-08,
      "loss": 0.0879,
      "step": 1050
    },
    {
      "epoch": 2.9968164131588257,
      "eval_loss": 0.17528307437896729,
      "eval_runtime": 195.9987,
      "eval_samples_per_second": 6.367,
      "eval_steps_per_second": 1.061,
      "step": 1059
    },
    {
      "epoch": 2.9968164131588257,
      "step": 1059,
      "total_flos": 5.853691383193272e+18,
      "train_loss": 0.5593316645640264,
      "train_runtime": 23744.2578,
      "train_samples_per_second": 2.142,
      "train_steps_per_second": 0.045
    }
  ],
  "logging_steps": 10,
  "max_steps": 1059,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.853691383193272e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
