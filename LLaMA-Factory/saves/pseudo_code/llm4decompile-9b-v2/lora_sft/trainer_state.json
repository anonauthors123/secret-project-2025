{
  "best_metric": 0.02177736721932888,
  "best_model_checkpoint": "saves/pseudo_code/llm4decompile-9b-v2/lora_sft/checkpoint-795",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 795,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03773584905660377,
      "grad_norm": 25.80911636352539,
      "learning_rate": 6.25e-05,
      "loss": 8.6741,
      "step": 10
    },
    {
      "epoch": 0.07547169811320754,
      "grad_norm": 6.038699626922607,
      "learning_rate": 0.000125,
      "loss": 2.3521,
      "step": 20
    },
    {
      "epoch": 0.11320754716981132,
      "grad_norm": 1.9099304676055908,
      "learning_rate": 0.0001875,
      "loss": 0.3705,
      "step": 30
    },
    {
      "epoch": 0.1509433962264151,
      "grad_norm": 0.8040781617164612,
      "learning_rate": 0.00025,
      "loss": 0.242,
      "step": 40
    },
    {
      "epoch": 0.18867924528301888,
      "grad_norm": 0.7664514183998108,
      "learning_rate": 0.0003125,
      "loss": 0.2401,
      "step": 50
    },
    {
      "epoch": 0.22641509433962265,
      "grad_norm": 0.2596377730369568,
      "learning_rate": 0.000375,
      "loss": 0.2272,
      "step": 60
    },
    {
      "epoch": 0.2641509433962264,
      "grad_norm": 0.3711402714252472,
      "learning_rate": 0.0004375,
      "loss": 0.2196,
      "step": 70
    },
    {
      "epoch": 0.3018867924528302,
      "grad_norm": 4.709225177764893,
      "learning_rate": 0.0005,
      "loss": 0.2517,
      "step": 80
    },
    {
      "epoch": 0.33962264150943394,
      "grad_norm": 0.9086974263191223,
      "learning_rate": 0.0004997587164001815,
      "loss": 0.2213,
      "step": 90
    },
    {
      "epoch": 0.37735849056603776,
      "grad_norm": 0.4816174805164337,
      "learning_rate": 0.0004990353313429303,
      "loss": 0.1862,
      "step": 100
    },
    {
      "epoch": 0.41509433962264153,
      "grad_norm": 0.8685837984085083,
      "learning_rate": 0.0004978312411558518,
      "loss": 0.1836,
      "step": 110
    },
    {
      "epoch": 0.4528301886792453,
      "grad_norm": 0.6939550042152405,
      "learning_rate": 0.0004961487700566646,
      "loss": 0.1829,
      "step": 120
    },
    {
      "epoch": 0.49056603773584906,
      "grad_norm": 0.7435864806175232,
      "learning_rate": 0.0004939911656668361,
      "loss": 0.1629,
      "step": 130
    },
    {
      "epoch": 0.5283018867924528,
      "grad_norm": 0.412506103515625,
      "learning_rate": 0.0004913625927427996,
      "loss": 0.162,
      "step": 140
    },
    {
      "epoch": 0.5660377358490566,
      "grad_norm": 0.5143610835075378,
      "learning_rate": 0.00048826812513685485,
      "loss": 0.1666,
      "step": 150
    },
    {
      "epoch": 0.6037735849056604,
      "grad_norm": 1.034487247467041,
      "learning_rate": 0.00048471373600326995,
      "loss": 0.1415,
      "step": 160
    },
    {
      "epoch": 0.6415094339622641,
      "grad_norm": 0.8273681402206421,
      "learning_rate": 0.00048070628626848734,
      "loss": 0.1333,
      "step": 170
    },
    {
      "epoch": 0.6792452830188679,
      "grad_norm": 1.8702739477157593,
      "learning_rate": 0.0004762535113876917,
      "loss": 0.1488,
      "step": 180
    },
    {
      "epoch": 0.7169811320754716,
      "grad_norm": 0.451903760433197,
      "learning_rate": 0.00047136400641330245,
      "loss": 0.1383,
      "step": 190
    },
    {
      "epoch": 0.7547169811320755,
      "grad_norm": 0.8081771731376648,
      "learning_rate": 0.0004660472094042121,
      "loss": 0.1373,
      "step": 200
    },
    {
      "epoch": 0.7924528301886793,
      "grad_norm": 0.5852230787277222,
      "learning_rate": 0.0004603133832077953,
      "loss": 0.1149,
      "step": 210
    },
    {
      "epoch": 0.8301886792452831,
      "grad_norm": 0.5252788662910461,
      "learning_rate": 0.00045417359564985544,
      "loss": 0.106,
      "step": 220
    },
    {
      "epoch": 0.8679245283018868,
      "grad_norm": 0.5869986414909363,
      "learning_rate": 0.00044763969817074534,
      "loss": 0.1044,
      "step": 230
    },
    {
      "epoch": 0.9056603773584906,
      "grad_norm": 0.8775009512901306,
      "learning_rate": 0.00044072430294890173,
      "loss": 0.1115,
      "step": 240
    },
    {
      "epoch": 0.9433962264150944,
      "grad_norm": 0.6250961422920227,
      "learning_rate": 0.000433440758555951,
      "loss": 0.092,
      "step": 250
    },
    {
      "epoch": 0.9811320754716981,
      "grad_norm": 0.699837327003479,
      "learning_rate": 0.00042580312419037775,
      "loss": 0.0895,
      "step": 260
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.0838228091597557,
      "eval_runtime": 220.7242,
      "eval_samples_per_second": 5.654,
      "eval_steps_per_second": 0.707,
      "step": 265
    },
    {
      "epoch": 1.0188679245283019,
      "grad_norm": 1.5746561288833618,
      "learning_rate": 0.00041782614253949257,
      "loss": 0.0915,
      "step": 270
    },
    {
      "epoch": 1.0566037735849056,
      "grad_norm": 0.7485197186470032,
      "learning_rate": 0.0004095252113220827,
      "loss": 0.0518,
      "step": 280
    },
    {
      "epoch": 1.0943396226415094,
      "grad_norm": 0.3889862298965454,
      "learning_rate": 0.00040091635356667607,
      "loss": 0.0651,
      "step": 290
    },
    {
      "epoch": 1.1320754716981132,
      "grad_norm": 0.39029115438461304,
      "learning_rate": 0.00039201618668278893,
      "loss": 0.0382,
      "step": 300
    },
    {
      "epoch": 1.169811320754717,
      "grad_norm": 0.9220863580703735,
      "learning_rate": 0.00038284189038485935,
      "loss": 0.0568,
      "step": 310
    },
    {
      "epoch": 1.2075471698113207,
      "grad_norm": 0.6378018856048584,
      "learning_rate": 0.0003734111735307796,
      "loss": 0.0479,
      "step": 320
    },
    {
      "epoch": 1.2452830188679245,
      "grad_norm": 0.7854880690574646,
      "learning_rate": 0.00036374223993904125,
      "loss": 0.0449,
      "step": 330
    },
    {
      "epoch": 1.2830188679245282,
      "grad_norm": 0.914761483669281,
      "learning_rate": 0.00035385375325047166,
      "loss": 0.0655,
      "step": 340
    },
    {
      "epoch": 1.320754716981132,
      "grad_norm": 0.36892572045326233,
      "learning_rate": 0.0003437648009023905,
      "loss": 0.0487,
      "step": 350
    },
    {
      "epoch": 1.3584905660377358,
      "grad_norm": 1.1905062198638916,
      "learning_rate": 0.00033349485728472535,
      "loss": 0.0572,
      "step": 360
    },
    {
      "epoch": 1.3962264150943398,
      "grad_norm": 1.3806110620498657,
      "learning_rate": 0.00032306374614920433,
      "loss": 0.045,
      "step": 370
    },
    {
      "epoch": 1.4339622641509435,
      "grad_norm": 0.5903620719909668,
      "learning_rate": 0.00031249160234418644,
      "loss": 0.0366,
      "step": 380
    },
    {
      "epoch": 1.4716981132075473,
      "grad_norm": 0.8973467350006104,
      "learning_rate": 0.0003017988329489923,
      "loss": 0.0358,
      "step": 390
    },
    {
      "epoch": 1.509433962264151,
      "grad_norm": 0.6046020984649658,
      "learning_rate": 0.0002910060778827555,
      "loss": 0.0338,
      "step": 400
    },
    {
      "epoch": 1.5471698113207548,
      "grad_norm": 0.43589314818382263,
      "learning_rate": 0.0002801341700638307,
      "loss": 0.0364,
      "step": 410
    },
    {
      "epoch": 1.5849056603773586,
      "grad_norm": 1.3540873527526855,
      "learning_rate": 0.00026920409519666174,
      "loss": 0.042,
      "step": 420
    },
    {
      "epoch": 1.6226415094339623,
      "grad_norm": 0.0941615030169487,
      "learning_rate": 0.0002582369512637302,
      "loss": 0.031,
      "step": 430
    },
    {
      "epoch": 1.6603773584905661,
      "grad_norm": 0.37192031741142273,
      "learning_rate": 0.00024725390780077906,
      "loss": 0.0265,
      "step": 440
    },
    {
      "epoch": 1.6981132075471699,
      "grad_norm": 0.5219358801841736,
      "learning_rate": 0.00023627616503391814,
      "loss": 0.0266,
      "step": 450
    },
    {
      "epoch": 1.7358490566037736,
      "grad_norm": 0.5740303993225098,
      "learning_rate": 0.00022532491295748866,
      "loss": 0.0248,
      "step": 460
    },
    {
      "epoch": 1.7735849056603774,
      "grad_norm": 0.29816824197769165,
      "learning_rate": 0.00021442129043167875,
      "loss": 0.0183,
      "step": 470
    },
    {
      "epoch": 1.8113207547169812,
      "grad_norm": 0.4059809744358063,
      "learning_rate": 0.00020358634437884113,
      "loss": 0.0297,
      "step": 480
    },
    {
      "epoch": 1.849056603773585,
      "grad_norm": 0.2033555507659912,
      "learning_rate": 0.00019284098915727568,
      "loss": 0.024,
      "step": 490
    },
    {
      "epoch": 1.8867924528301887,
      "grad_norm": 0.17560537159442902,
      "learning_rate": 0.00018220596619089574,
      "loss": 0.0149,
      "step": 500
    },
    {
      "epoch": 1.9245283018867925,
      "grad_norm": 0.2499149739742279,
      "learning_rate": 0.0001717018039327053,
      "loss": 0.0144,
      "step": 510
    },
    {
      "epoch": 1.9622641509433962,
      "grad_norm": 1.0142033100128174,
      "learning_rate": 0.00016134877823936609,
      "loss": 0.0153,
      "step": 520
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0884847491979599,
      "learning_rate": 0.00015116687323334465,
      "loss": 0.0132,
      "step": 530
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.028318796306848526,
      "eval_runtime": 220.9703,
      "eval_samples_per_second": 5.648,
      "eval_steps_per_second": 0.706,
      "step": 530
    },
    {
      "epoch": 2.0377358490566038,
      "grad_norm": 0.0587875135242939,
      "learning_rate": 0.00014117574272818386,
      "loss": 0.0075,
      "step": 540
    },
    {
      "epoch": 2.0754716981132075,
      "grad_norm": 0.018342243507504463,
      "learning_rate": 0.00013139467229136,
      "loss": 0.0038,
      "step": 550
    },
    {
      "epoch": 2.1132075471698113,
      "grad_norm": 0.023680932819843292,
      "learning_rate": 0.00012184254201795364,
      "loss": 0.0068,
      "step": 560
    },
    {
      "epoch": 2.150943396226415,
      "grad_norm": 0.026014801114797592,
      "learning_rate": 0.0001125377900869913,
      "loss": 0.0039,
      "step": 570
    },
    {
      "epoch": 2.188679245283019,
      "grad_norm": 0.021519076079130173,
      "learning_rate": 0.00010349837717080349,
      "loss": 0.0051,
      "step": 580
    },
    {
      "epoch": 2.2264150943396226,
      "grad_norm": 0.03753427788615227,
      "learning_rate": 9.474175176609956e-05,
      "loss": 0.0044,
      "step": 590
    },
    {
      "epoch": 2.2641509433962264,
      "grad_norm": 0.2352353036403656,
      "learning_rate": 8.628481651367875e-05,
      "loss": 0.0037,
      "step": 600
    },
    {
      "epoch": 2.30188679245283,
      "grad_norm": 0.03222792595624924,
      "learning_rate": 7.814389557179016e-05,
      "loss": 0.006,
      "step": 610
    },
    {
      "epoch": 2.339622641509434,
      "grad_norm": 0.14834769070148468,
      "learning_rate": 7.033470310611945e-05,
      "loss": 0.0049,
      "step": 620
    },
    {
      "epoch": 2.3773584905660377,
      "grad_norm": 0.30489882826805115,
      "learning_rate": 6.28723129572247e-05,
      "loss": 0.0048,
      "step": 630
    },
    {
      "epoch": 2.4150943396226414,
      "grad_norm": 0.02537594363093376,
      "learning_rate": 5.57711295439732e-05,
      "loss": 0.0036,
      "step": 640
    },
    {
      "epoch": 2.452830188679245,
      "grad_norm": 0.27831974625587463,
      "learning_rate": 4.904486005914027e-05,
      "loss": 0.004,
      "step": 650
    },
    {
      "epoch": 2.490566037735849,
      "grad_norm": 0.13825379312038422,
      "learning_rate": 4.270648801084295e-05,
      "loss": 0.0035,
      "step": 660
    },
    {
      "epoch": 2.5283018867924527,
      "grad_norm": 0.05355397239327431,
      "learning_rate": 3.676824816087978e-05,
      "loss": 0.0066,
      "step": 670
    },
    {
      "epoch": 2.5660377358490565,
      "grad_norm": 0.17392519116401672,
      "learning_rate": 3.1241602908351405e-05,
      "loss": 0.0049,
      "step": 680
    },
    {
      "epoch": 2.6037735849056602,
      "grad_norm": 0.07376006245613098,
      "learning_rate": 2.6137220164149435e-05,
      "loss": 0.0012,
      "step": 690
    },
    {
      "epoch": 2.641509433962264,
      "grad_norm": 0.03589046746492386,
      "learning_rate": 2.1464952759020855e-05,
      "loss": 0.0035,
      "step": 700
    },
    {
      "epoch": 2.6792452830188678,
      "grad_norm": 0.04995954409241676,
      "learning_rate": 1.723381942495625e-05,
      "loss": 0.0032,
      "step": 710
    },
    {
      "epoch": 2.7169811320754715,
      "grad_norm": 0.03070608340203762,
      "learning_rate": 1.3451987386612851e-05,
      "loss": 0.005,
      "step": 720
    },
    {
      "epoch": 2.7547169811320753,
      "grad_norm": 0.03877278044819832,
      "learning_rate": 1.0126756596375685e-05,
      "loss": 0.0029,
      "step": 730
    },
    {
      "epoch": 2.7924528301886795,
      "grad_norm": 0.0545748695731163,
      "learning_rate": 7.2645456434869975e-06,
      "loss": 0.0015,
      "step": 740
    },
    {
      "epoch": 2.830188679245283,
      "grad_norm": 0.2081933319568634,
      "learning_rate": 4.870879364444108e-06,
      "loss": 0.002,
      "step": 750
    },
    {
      "epoch": 2.867924528301887,
      "grad_norm": 0.030003244057297707,
      "learning_rate": 2.9503781785795713e-06,
      "loss": 0.0024,
      "step": 760
    },
    {
      "epoch": 2.9056603773584904,
      "grad_norm": 0.00949922390282154,
      "learning_rate": 1.5067491694100155e-06,
      "loss": 0.0082,
      "step": 770
    },
    {
      "epoch": 2.9433962264150946,
      "grad_norm": 0.03566662594676018,
      "learning_rate": 5.427789289685348e-07,
      "loss": 0.004,
      "step": 780
    },
    {
      "epoch": 2.981132075471698,
      "grad_norm": 0.00858328863978386,
      "learning_rate": 6.032817893297793e-08,
      "loss": 0.0012,
      "step": 790
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.02177736721932888,
      "eval_runtime": 220.2647,
      "eval_samples_per_second": 5.666,
      "eval_steps_per_second": 0.708,
      "step": 795
    },
    {
      "epoch": 3.0,
      "step": 795,
      "total_flos": 7.68312404212292e+18,
      "train_loss": 0.20509561853799618,
      "train_runtime": 27375.4469,
      "train_samples_per_second": 1.858,
      "train_steps_per_second": 0.029
    }
  ],
  "logging_steps": 10,
  "max_steps": 795,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.68312404212292e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
