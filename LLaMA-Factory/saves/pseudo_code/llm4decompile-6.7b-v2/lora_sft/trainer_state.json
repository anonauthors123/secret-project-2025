{
  "best_metric": 0.14406384527683258,
  "best_model_checkpoint": "saves/pseudo_code/llm4decompile/lora_sft/checkpoint-1059",
  "epoch": 2.9968164131588257,
  "eval_steps": 500,
  "global_step": 1059,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02829854969932791,
      "grad_norm": 3.496591567993164,
      "learning_rate": 9.433962264150944e-06,
      "loss": 6.2295,
      "step": 10
    },
    {
      "epoch": 0.05659709939865582,
      "grad_norm": 4.103250980377197,
      "learning_rate": 1.8867924528301888e-05,
      "loss": 5.9969,
      "step": 20
    },
    {
      "epoch": 0.08489564909798372,
      "grad_norm": 5.2010908126831055,
      "learning_rate": 2.830188679245283e-05,
      "loss": 5.6073,
      "step": 30
    },
    {
      "epoch": 0.11319419879731164,
      "grad_norm": 1.0495985746383667,
      "learning_rate": 3.7735849056603776e-05,
      "loss": 3.2447,
      "step": 40
    },
    {
      "epoch": 0.14149274849663954,
      "grad_norm": 2.1812121868133545,
      "learning_rate": 4.716981132075472e-05,
      "loss": 2.4222,
      "step": 50
    },
    {
      "epoch": 0.16979129819596744,
      "grad_norm": 2.1846559047698975,
      "learning_rate": 5.660377358490566e-05,
      "loss": 1.368,
      "step": 60
    },
    {
      "epoch": 0.19808984789529538,
      "grad_norm": 1.2548902034759521,
      "learning_rate": 6.60377358490566e-05,
      "loss": 0.4682,
      "step": 70
    },
    {
      "epoch": 0.2263883975946233,
      "grad_norm": 0.8853093981742859,
      "learning_rate": 7.547169811320755e-05,
      "loss": 0.3719,
      "step": 80
    },
    {
      "epoch": 0.2546869472939512,
      "grad_norm": 1.1551028490066528,
      "learning_rate": 8.49056603773585e-05,
      "loss": 0.3707,
      "step": 90
    },
    {
      "epoch": 0.2829854969932791,
      "grad_norm": 1.1209748983383179,
      "learning_rate": 9.433962264150944e-05,
      "loss": 0.367,
      "step": 100
    },
    {
      "epoch": 0.311284046692607,
      "grad_norm": 1.6635991334915161,
      "learning_rate": 9.999565322017444e-05,
      "loss": 0.3484,
      "step": 110
    },
    {
      "epoch": 0.3395825963919349,
      "grad_norm": 1.8892954587936401,
      "learning_rate": 9.994676062638023e-05,
      "loss": 0.3361,
      "step": 120
    },
    {
      "epoch": 0.3678811460912628,
      "grad_norm": 0.5323060154914856,
      "learning_rate": 9.984359526844107e-05,
      "loss": 0.307,
      "step": 130
    },
    {
      "epoch": 0.39617969579059076,
      "grad_norm": 0.4407983124256134,
      "learning_rate": 9.968626924710318e-05,
      "loss": 0.3223,
      "step": 140
    },
    {
      "epoch": 0.42447824548991864,
      "grad_norm": 0.4224424660205841,
      "learning_rate": 9.947495351475553e-05,
      "loss": 0.3267,
      "step": 150
    },
    {
      "epoch": 0.4527767951892466,
      "grad_norm": 1.5225871801376343,
      "learning_rate": 9.920987768967081e-05,
      "loss": 0.3181,
      "step": 160
    },
    {
      "epoch": 0.48107534488857445,
      "grad_norm": 0.8434536457061768,
      "learning_rate": 9.889132980649944e-05,
      "loss": 0.3163,
      "step": 170
    },
    {
      "epoch": 0.5093738945879024,
      "grad_norm": 1.2579766511917114,
      "learning_rate": 9.85196560032875e-05,
      "loss": 0.3052,
      "step": 180
    },
    {
      "epoch": 0.5376724442872303,
      "grad_norm": 0.5713843107223511,
      "learning_rate": 9.809526014535895e-05,
      "loss": 0.3059,
      "step": 190
    },
    {
      "epoch": 0.5659709939865581,
      "grad_norm": 1.7861450910568237,
      "learning_rate": 9.761860338647055e-05,
      "loss": 0.3167,
      "step": 200
    },
    {
      "epoch": 0.5942695436858861,
      "grad_norm": 0.5577696561813354,
      "learning_rate": 9.709020366771656e-05,
      "loss": 0.2995,
      "step": 210
    },
    {
      "epoch": 0.622568093385214,
      "grad_norm": 0.9849899411201477,
      "learning_rate": 9.651063515472754e-05,
      "loss": 0.3043,
      "step": 220
    },
    {
      "epoch": 0.6508666430845419,
      "grad_norm": 0.6367242932319641,
      "learning_rate": 9.588052761377497e-05,
      "loss": 0.3076,
      "step": 230
    },
    {
      "epoch": 0.6791651927838698,
      "grad_norm": 0.5923977494239807,
      "learning_rate": 9.520056572745944e-05,
      "loss": 0.2844,
      "step": 240
    },
    {
      "epoch": 0.7074637424831978,
      "grad_norm": 1.0427192449569702,
      "learning_rate": 9.447148835072608e-05,
      "loss": 0.2743,
      "step": 250
    },
    {
      "epoch": 0.7357622921825256,
      "grad_norm": 0.8081375956535339,
      "learning_rate": 9.369408770801578e-05,
      "loss": 0.3044,
      "step": 260
    },
    {
      "epoch": 0.7640608418818535,
      "grad_norm": 1.6771821975708008,
      "learning_rate": 9.286920853242433e-05,
      "loss": 0.2884,
      "step": 270
    },
    {
      "epoch": 0.7923593915811815,
      "grad_norm": 1.4470291137695312,
      "learning_rate": 9.199774714780503e-05,
      "loss": 0.2836,
      "step": 280
    },
    {
      "epoch": 0.8206579412805094,
      "grad_norm": 1.5566462278366089,
      "learning_rate": 9.10806504948122e-05,
      "loss": 0.2845,
      "step": 290
    },
    {
      "epoch": 0.8489564909798373,
      "grad_norm": 0.48147568106651306,
      "learning_rate": 9.011891510194381e-05,
      "loss": 0.2782,
      "step": 300
    },
    {
      "epoch": 0.8772550406791652,
      "grad_norm": 0.8376246690750122,
      "learning_rate": 8.911358600270141e-05,
      "loss": 0.2754,
      "step": 310
    },
    {
      "epoch": 0.9055535903784931,
      "grad_norm": 2.5547988414764404,
      "learning_rate": 8.80657556000438e-05,
      "loss": 0.269,
      "step": 320
    },
    {
      "epoch": 0.933852140077821,
      "grad_norm": 2.7817013263702393,
      "learning_rate": 8.697656247936859e-05,
      "loss": 0.287,
      "step": 330
    },
    {
      "epoch": 0.9621506897771489,
      "grad_norm": 0.6381778120994568,
      "learning_rate": 8.58471901713113e-05,
      "loss": 0.2709,
      "step": 340
    },
    {
      "epoch": 0.9904492394764768,
      "grad_norm": 0.7289522290229797,
      "learning_rate": 8.467886586570645e-05,
      "loss": 0.3026,
      "step": 350
    },
    {
      "epoch": 0.9989388043862752,
      "eval_loss": 0.28809553384780884,
      "eval_runtime": 195.7008,
      "eval_samples_per_second": 6.377,
      "eval_steps_per_second": 1.063,
      "step": 353
    },
    {
      "epoch": 1.0187477891758048,
      "grad_norm": 0.7379815578460693,
      "learning_rate": 8.347285907810793e-05,
      "loss": 0.2616,
      "step": 360
    },
    {
      "epoch": 1.0470463388751325,
      "grad_norm": 0.784494161605835,
      "learning_rate": 8.22304802703179e-05,
      "loss": 0.2503,
      "step": 370
    },
    {
      "epoch": 1.0753448885744605,
      "grad_norm": 2.122711181640625,
      "learning_rate": 8.095307942642276e-05,
      "loss": 0.2492,
      "step": 380
    },
    {
      "epoch": 1.1036434382737885,
      "grad_norm": 0.6046987771987915,
      "learning_rate": 7.964204458588393e-05,
      "loss": 0.2384,
      "step": 390
    },
    {
      "epoch": 1.1319419879731163,
      "grad_norm": 0.7892749905586243,
      "learning_rate": 7.829880033527708e-05,
      "loss": 0.2473,
      "step": 400
    },
    {
      "epoch": 1.1602405376724443,
      "grad_norm": 0.6504687070846558,
      "learning_rate": 7.692480626031881e-05,
      "loss": 0.2327,
      "step": 410
    },
    {
      "epoch": 1.1885390873717723,
      "grad_norm": 0.8888837695121765,
      "learning_rate": 7.5521555359863e-05,
      "loss": 0.2012,
      "step": 420
    },
    {
      "epoch": 1.2168376370711,
      "grad_norm": 1.0411226749420166,
      "learning_rate": 7.409057242358967e-05,
      "loss": 0.2233,
      "step": 430
    },
    {
      "epoch": 1.245136186770428,
      "grad_norm": 1.7665876150131226,
      "learning_rate": 7.263341237514997e-05,
      "loss": 0.2116,
      "step": 440
    },
    {
      "epoch": 1.2734347364697558,
      "grad_norm": 0.9455851316452026,
      "learning_rate": 7.115165858256698e-05,
      "loss": 0.2128,
      "step": 450
    },
    {
      "epoch": 1.3017332861690838,
      "grad_norm": 1.1775908470153809,
      "learning_rate": 6.964692113772846e-05,
      "loss": 0.2123,
      "step": 460
    },
    {
      "epoch": 1.3300318358684118,
      "grad_norm": 1.4497106075286865,
      "learning_rate": 6.812083510684128e-05,
      "loss": 0.1915,
      "step": 470
    },
    {
      "epoch": 1.3583303855677396,
      "grad_norm": 1.2221612930297852,
      "learning_rate": 6.657505875374844e-05,
      "loss": 0.2037,
      "step": 480
    },
    {
      "epoch": 1.3866289352670675,
      "grad_norm": 1.4318856000900269,
      "learning_rate": 6.501127173803904e-05,
      "loss": 0.2043,
      "step": 490
    },
    {
      "epoch": 1.4149274849663955,
      "grad_norm": 1.3545894622802734,
      "learning_rate": 6.343117328990967e-05,
      "loss": 0.199,
      "step": 500
    },
    {
      "epoch": 1.4432260346657233,
      "grad_norm": 0.8881020545959473,
      "learning_rate": 6.183648036375985e-05,
      "loss": 0.209,
      "step": 510
    },
    {
      "epoch": 1.4715245843650513,
      "grad_norm": 1.7393168210983276,
      "learning_rate": 6.022892577252838e-05,
      "loss": 0.1879,
      "step": 520
    },
    {
      "epoch": 1.4998231340643793,
      "grad_norm": 1.55023992061615,
      "learning_rate": 5.86102563047975e-05,
      "loss": 0.1768,
      "step": 530
    },
    {
      "epoch": 1.528121683763707,
      "grad_norm": 1.5755128860473633,
      "learning_rate": 5.6982230826710824e-05,
      "loss": 0.1933,
      "step": 540
    },
    {
      "epoch": 1.556420233463035,
      "grad_norm": 1.0445287227630615,
      "learning_rate": 5.534661837076792e-05,
      "loss": 0.1793,
      "step": 550
    },
    {
      "epoch": 1.584718783162363,
      "grad_norm": 1.5196712017059326,
      "learning_rate": 5.3705196213571685e-05,
      "loss": 0.1832,
      "step": 560
    },
    {
      "epoch": 1.6130173328616908,
      "grad_norm": 1.2741774320602417,
      "learning_rate": 5.2059747944617886e-05,
      "loss": 0.1864,
      "step": 570
    },
    {
      "epoch": 1.6413158825610188,
      "grad_norm": 0.878150463104248,
      "learning_rate": 5.041206152822482e-05,
      "loss": 0.1585,
      "step": 580
    },
    {
      "epoch": 1.6696144322603468,
      "grad_norm": 0.9652034044265747,
      "learning_rate": 4.876392736070927e-05,
      "loss": 0.1753,
      "step": 590
    },
    {
      "epoch": 1.6979129819596745,
      "grad_norm": 1.1951171159744263,
      "learning_rate": 4.711713632491993e-05,
      "loss": 0.1805,
      "step": 600
    },
    {
      "epoch": 1.7262115316590023,
      "grad_norm": 1.291228175163269,
      "learning_rate": 4.547347784424201e-05,
      "loss": 0.1601,
      "step": 610
    },
    {
      "epoch": 1.7545100813583305,
      "grad_norm": 1.6292266845703125,
      "learning_rate": 4.3834737938187865e-05,
      "loss": 0.1666,
      "step": 620
    },
    {
      "epoch": 1.7828086310576583,
      "grad_norm": 1.6336604356765747,
      "learning_rate": 4.2202697281686174e-05,
      "loss": 0.1656,
      "step": 630
    },
    {
      "epoch": 1.811107180756986,
      "grad_norm": 1.2105211019515991,
      "learning_rate": 4.057912927017869e-05,
      "loss": 0.1457,
      "step": 640
    },
    {
      "epoch": 1.839405730456314,
      "grad_norm": 1.2451980113983154,
      "learning_rate": 3.896579809262696e-05,
      "loss": 0.1417,
      "step": 650
    },
    {
      "epoch": 1.867704280155642,
      "grad_norm": 1.955437421798706,
      "learning_rate": 3.7364456814522885e-05,
      "loss": 0.1517,
      "step": 660
    },
    {
      "epoch": 1.8960028298549698,
      "grad_norm": 1.5438061952590942,
      "learning_rate": 3.577684547298626e-05,
      "loss": 0.1568,
      "step": 670
    },
    {
      "epoch": 1.9243013795542978,
      "grad_norm": 2.058133602142334,
      "learning_rate": 3.420468918601896e-05,
      "loss": 0.1377,
      "step": 680
    },
    {
      "epoch": 1.9525999292536258,
      "grad_norm": 1.2041176557540894,
      "learning_rate": 3.26496962779706e-05,
      "loss": 0.1416,
      "step": 690
    },
    {
      "epoch": 1.9808984789529536,
      "grad_norm": 1.21597158908844,
      "learning_rate": 3.111355642325222e-05,
      "loss": 0.1256,
      "step": 700
    },
    {
      "epoch": 1.9978776087725505,
      "eval_loss": 0.1782733052968979,
      "eval_runtime": 195.7673,
      "eval_samples_per_second": 6.375,
      "eval_steps_per_second": 1.062,
      "step": 706
    },
    {
      "epoch": 2.009197028652282,
      "grad_norm": 1.1608085632324219,
      "learning_rate": 2.959793881031536e-05,
      "loss": 0.1303,
      "step": 710
    },
    {
      "epoch": 2.0374955783516095,
      "grad_norm": 1.2709144353866577,
      "learning_rate": 2.810449032789134e-05,
      "loss": 0.0941,
      "step": 720
    },
    {
      "epoch": 2.0657941280509373,
      "grad_norm": 1.446293592453003,
      "learning_rate": 2.663483377546167e-05,
      "loss": 0.0859,
      "step": 730
    },
    {
      "epoch": 2.094092677750265,
      "grad_norm": 1.0306246280670166,
      "learning_rate": 2.51905660999043e-05,
      "loss": 0.1003,
      "step": 740
    },
    {
      "epoch": 2.1223912274495933,
      "grad_norm": 2.36857008934021,
      "learning_rate": 2.377325666023137e-05,
      "loss": 0.0981,
      "step": 750
    },
    {
      "epoch": 2.150689777148921,
      "grad_norm": 0.9667887091636658,
      "learning_rate": 2.2384445522304536e-05,
      "loss": 0.0798,
      "step": 760
    },
    {
      "epoch": 2.178988326848249,
      "grad_norm": 1.109593152999878,
      "learning_rate": 2.1025641785380373e-05,
      "loss": 0.0826,
      "step": 770
    },
    {
      "epoch": 2.207286876547577,
      "grad_norm": 2.4782564640045166,
      "learning_rate": 1.969832194230466e-05,
      "loss": 0.0887,
      "step": 780
    },
    {
      "epoch": 2.235585426246905,
      "grad_norm": 1.2808102369308472,
      "learning_rate": 1.8403928275136994e-05,
      "loss": 0.0868,
      "step": 790
    },
    {
      "epoch": 2.2638839759462326,
      "grad_norm": 2.2079217433929443,
      "learning_rate": 1.7143867287949487e-05,
      "loss": 0.0826,
      "step": 800
    },
    {
      "epoch": 2.292182525645561,
      "grad_norm": 1.2470046281814575,
      "learning_rate": 1.59195081785021e-05,
      "loss": 0.0884,
      "step": 810
    },
    {
      "epoch": 2.3204810753448886,
      "grad_norm": 1.6540852785110474,
      "learning_rate": 1.4732181350455471e-05,
      "loss": 0.0744,
      "step": 820
    },
    {
      "epoch": 2.3487796250442163,
      "grad_norm": 3.4593074321746826,
      "learning_rate": 1.3583176967738042e-05,
      "loss": 0.0881,
      "step": 830
    },
    {
      "epoch": 2.3770781747435445,
      "grad_norm": 1.1509160995483398,
      "learning_rate": 1.2473743552637973e-05,
      "loss": 0.0796,
      "step": 840
    },
    {
      "epoch": 2.4053767244428723,
      "grad_norm": 1.5842441320419312,
      "learning_rate": 1.140508662914358e-05,
      "loss": 0.071,
      "step": 850
    },
    {
      "epoch": 2.4336752741422,
      "grad_norm": 1.0835601091384888,
      "learning_rate": 1.0378367413006052e-05,
      "loss": 0.0733,
      "step": 860
    },
    {
      "epoch": 2.4619738238415283,
      "grad_norm": 2.0275895595550537,
      "learning_rate": 9.394701549948165e-06,
      "loss": 0.0596,
      "step": 870
    },
    {
      "epoch": 2.490272373540856,
      "grad_norm": 1.4071011543273926,
      "learning_rate": 8.455157903389994e-06,
      "loss": 0.0659,
      "step": 880
    },
    {
      "epoch": 2.518570923240184,
      "grad_norm": 2.575500726699829,
      "learning_rate": 7.5607573930086825e-06,
      "loss": 0.0813,
      "step": 890
    },
    {
      "epoch": 2.5468694729395116,
      "grad_norm": 1.4472798109054565,
      "learning_rate": 6.712471885394606e-06,
      "loss": 0.0625,
      "step": 900
    },
    {
      "epoch": 2.57516802263884,
      "grad_norm": 1.9220174551010132,
      "learning_rate": 5.911223138009225e-06,
      "loss": 0.0596,
      "step": 910
    },
    {
      "epoch": 2.6034665723381676,
      "grad_norm": 1.0046498775482178,
      "learning_rate": 5.157881797592057e-06,
      "loss": 0.0626,
      "step": 920
    },
    {
      "epoch": 2.6317651220374954,
      "grad_norm": 2.1662280559539795,
      "learning_rate": 4.453266454105198e-06,
      "loss": 0.0549,
      "step": 930
    },
    {
      "epoch": 2.6600636717368236,
      "grad_norm": 2.686269760131836,
      "learning_rate": 3.798142751243483e-06,
      "loss": 0.0703,
      "step": 940
    },
    {
      "epoch": 2.6883622214361513,
      "grad_norm": 2.358278751373291,
      "learning_rate": 3.1932225544765493e-06,
      "loss": 0.0829,
      "step": 950
    },
    {
      "epoch": 2.716660771135479,
      "grad_norm": 1.5609409809112549,
      "learning_rate": 2.639163177527154e-06,
      "loss": 0.0601,
      "step": 960
    },
    {
      "epoch": 2.7449593208348073,
      "grad_norm": 0.774074137210846,
      "learning_rate": 2.1365666681259e-06,
      "loss": 0.0774,
      "step": 970
    },
    {
      "epoch": 2.773257870534135,
      "grad_norm": 1.1439958810806274,
      "learning_rate": 1.685979153818873e-06,
      "loss": 0.0657,
      "step": 980
    },
    {
      "epoch": 2.801556420233463,
      "grad_norm": 2.0038788318634033,
      "learning_rate": 1.2878902485386534e-06,
      "loss": 0.0641,
      "step": 990
    },
    {
      "epoch": 2.829854969932791,
      "grad_norm": 1.6807363033294678,
      "learning_rate": 9.427325205838555e-07,
      "loss": 0.0651,
      "step": 1000
    },
    {
      "epoch": 2.858153519632119,
      "grad_norm": 1.2682033777236938,
      "learning_rate": 6.508810225850703e-07,
      "loss": 0.0636,
      "step": 1010
    },
    {
      "epoch": 2.8864520693314466,
      "grad_norm": 1.82035493850708,
      "learning_rate": 4.1265288396805104e-07,
      "loss": 0.0538,
      "step": 1020
    },
    {
      "epoch": 2.914750619030775,
      "grad_norm": 2.4593405723571777,
      "learning_rate": 2.2830696635701143e-07,
      "loss": 0.0661,
      "step": 1030
    },
    {
      "epoch": 2.9430491687301026,
      "grad_norm": 2.3379085063934326,
      "learning_rate": 9.804358229238974e-08,
      "loss": 0.0768,
      "step": 1040
    },
    {
      "epoch": 2.9713477184294304,
      "grad_norm": 2.0752522945404053,
      "learning_rate": 2.2004277568776766e-08,
      "loss": 0.0674,
      "step": 1050
    },
    {
      "epoch": 2.9968164131588257,
      "eval_loss": 0.14406384527683258,
      "eval_runtime": 195.7742,
      "eval_samples_per_second": 6.375,
      "eval_steps_per_second": 1.062,
      "step": 1059
    },
    {
      "epoch": 2.9968164131588257,
      "step": 1059,
      "total_flos": 5.853691383193272e+18,
      "train_loss": 0.4092459178848915,
      "train_runtime": 23707.2881,
      "train_samples_per_second": 2.146,
      "train_steps_per_second": 0.045
    }
  ],
  "logging_steps": 10,
  "max_steps": 1059,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.853691383193272e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
